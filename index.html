<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>


    <meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿." />



  <meta name="keywords" content="Hexo,next" />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta property="og:type" content="website">
<meta property="og:title" content="DannyLee">
<meta property="og:url" content="http://dannylee1991.github.io/index.html">
<meta property="og:site_name" content="DannyLee">
<meta property="og:description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DannyLee">
<meta name="twitter:description" content="一只在迈向机器学习道路上狂奔的程序猿.">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>

<!--baidu统计-->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2f967e5ec4f276411160d27aeace7722";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  <title> DannyLee </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">DannyLee</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            标签
          </a>
        </li>
      

      
      
        <li class="menu-item menu-item-search">
          <a href="#" class="st-search-show-outputs">
            <i class="menu-item-icon icon-next-search"></i> <br />
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'ss9-_Hsd4DyhyGw4m99P','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/26/【翻译】TextRank-对文本排序/" itemprop="url">
                【翻译】TextRank:对文本排序
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-26T22:12:58+08:00" content="2017-04-26">
            2017-04-26
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/26/【翻译】TextRank-对文本排序/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/26/【翻译】TextRank-对文本排序/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><blockquote>
<p>本文翻译自：<a href="http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="external">http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf</a></p>
</blockquote>
<h2 id="摘要">摘要</h2><p>本篇论文中，我们将介绍TextRank算法，这是一种针对于文本处理的基于图的排序模型算法，并且展示这个模型是如何能够被成功的应用在自然语言应用中。特别的，我们提出了两个创新的无监督方法用于关键词和句子提取，并且展示我们得到的测试结果与先前公布的基准结果的对比。</p>
<h2 id="1_介绍">1 介绍</h2><p>基于图的排序算法，像Kleinberg的HITS算法（Kleinberg，1999）或Google的PageRank算法（Brin和Page，1998）已成功应用于引文分析，社交网络和万维网链接结构分析。可以说，这些算法通过提供一种依靠Web架构师的集体知识而不是网页的单独内容分析的网页排名机制,可以作为网页搜索技术领域触发的范式转换的关键要素。简而言之，基于图的排序算法是通过考虑从整个图形递归计算的全局信息，而不是仅依赖于局部顶点特定信息来决定图中的顶点的重要性的一种方式。</p>
<p>对从自然语言文档中提取的词汇或语义图，使用类似的思路，可以得出一种基于图形的排名模型，这种模型可以应用于各种自然语言处理的应用程序中，其中从整个文本中获取的知识用于得出本地 排名/选择 的决策。 这种面向文本的排序方法，可以应用于关键短语的自动提取，摘要提取，以及词义消歧的任务（Mihalcea et等等，2004）。</p>
<p>在这篇论文中，我们会介绍基于从自然语言文本中提取的图形，来介绍TextRank图的排序模型。我们调查并评估了TextRank对于由无监督关键词和句子提取，这两种语言处理任务的应用，并展示使用TextRank获得的结果与在这些领域开发的最先进的系统进行比较。</p>
<h2 id="2_TextRank模型">2 TextRank模型</h2><p>基于图的排序算法本质上是基于从整个图形递归绘制的全局信息，来决定图中顶点的重要性的一种方式。基于图表的排名模式实现的基本思想是“投票”或“推荐”。当一个顶点链接到另一个顶点时，它主要是在为另一个顶点投票。顶点投射的投票数越多，顶点的重要性就越高。此外，顶点投票的重要性决定了投票本身的重要性，而这一信息也被排名模型考虑在内。因此，与顶点相关联的分数，取决于为其投的票，以及投射这些投票的顶点的分数来确定。</p>
<p>正式的，令集合$G=(V,E)$是具有顶点$V$和边$E$集合的有向图，其中$E$是$V×V$的子集。对于给定的顶点$V_i$，令$In(V_i)$是指向它的顶点集（前辈），并且令$Out(V_i)$是顶点$V_i$指向（后继）的顶点集合。顶点$V_i$的分数定义如下（Brin和Page，1998）：</p>
<p><img src="/img/17_04_26/001.png" alt=""></p>
<p>其中$d$是0和1之间的阻尼因子，它作用于将从给定顶点跳转到图中的另一个随机顶点的概率集成到模型中。在网页浏览的上下文中，这种基于图表的排名算法实现了“随机冲浪者模型”，其中用户以概率$d$随机点击链接，并以概率$1-d$跳转到一个全新的页面。因子$d$通常设置为0.85（Brin和Page，1998），这也是我们在具体实现中所使用的值。</p>
<p>从图中分配给每个节点的任意值开始，迭代计算直到达到低于给定的阈值。运行算法之后，得到一个与每个顶点相关联的分数，这表示图中顶点的“重要性”。请注意，TextRank运行到完成后获得的最终值，不受初始值的选择的影响，初始值的选择只会影响到收敛的迭代次数。</p>
<p>重要的是要注意，尽管本文中描述的TextRank应用程序依赖于从Google的PageRank（Brin和Page，1998）导出的算法，但是其他基于图表的排序算法，例如 HITS（Kleinberg，1999）或位置函数（Herings等，2001）也可以轻松地整合到TextRank模型中（Mihalcea，2004）。</p>
<h3 id="2-1_无向图">2.1 无向图</h3><p>虽然传统上应用于有向图，但是也可以将基于递归图的排序算法应用于无向图，在这种情况下，顶点的出度（out-degree）等于顶点的入度（in-degree）。对于松散连接的图形，随着边缘数量与顶点数量成比例，无向图趋向于具有更多的逐渐收敛曲线。</p>
<p>图1绘制了具有250个顶点和250个边缘的随机生成图的收敛曲线，收敛阈值为0.0001。随着图形的连通性增加（即较大数量的边缘），通常在较少迭代之后实现收敛，并且有向和无向图的收敛曲线实际上是重叠的。</p>
<p><img src="/img/17_04_26/002.png" alt=""></p>
<p>图1：基于图的收敛曲线排名：有向/无向，加权/未加权图，250个顶点，250个边。</p>
<h3 id="2-2_权重图">2.2 权重图</h3><p>在网页浏览的上下文中，页面中包含多个或部分链接到另一个页面是不寻常的，因此，基于图的原始PageRank定义是假设未加权的图。</p>
<p>然而，在我们的模型中的图是由自然语言文本构造的，并且也可以由包括从文本中提取的单元（顶点）之间的多个或部分链接构造。因此，可以在模型中指示并将两个顶点$V_i$和$V_j$之间的连接的“强度”作为加到连接两个顶点的对应边缘的权重$w_{ij}$来指示并合并到该模型中。因此，我们引入了一个新的基于图的排名公式，在计算与图中顶点相关的分数时考虑了边权重。请注意，可以定义类似的公式来整合顶点权重。</p>
<p><img src="/img/17_04_26/003.png" alt=""></p>
<p>图1绘制了2.1节中相同样本图的收敛曲线，其中对边进行了0到10的随机加权。尽管与未加权相比，最终顶点得分（因此排名）显着不同，但是对于加权和未加权图，收敛次数和收敛曲线的形状几乎相同。</p>
<h3 id="2-3_文本作为图">2.3 文本作为图</h3><p>为了使基于图的排序算法能够应用于自然语言文本，我们必须构建一个表示文本的图形，并将具有有意义关系的单词或其他文本实体进行互连。 根据手头的应用，各种尺寸和特征的文本单位可以作为图中的顶点添加，例如。 单词，搭配，整个句子或其他。 类似地，它是指示用于绘制任何两个这样的顶点之间的连接的关系的类型，例如。 词汇或语义关系，语境重叠等。</p>
<p>无论添加到图形中的元素的类型和特征如何，将基于图的排序算法应用于自然语言文本包括以下主要步骤：</p>
<ul>
<li>1.识别最佳定义手头任务的文本单位，并将其作为顶点添加到图形中。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/" itemprop="url">
                斯坦福机器学习课程 第八周 (1)聚类
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-20T22:32:58+08:00" content="2017-04-20">
            2017-04-20
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h2 id="无监督学习介绍">无监督学习介绍</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/czmip/unsupervised-learning-introduction" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>接下来，我将介绍<strong>聚类</strong>这一概念。保证精彩！因为这是我们第一个<strong>无监督学习算法</strong>。我们要从未标记的数据中进行学习, 而不是从已标记的数据。 </p>
</blockquote>
<p>什么是无监督学习算法呢？</p>
<p>之前，在本课程的开始阶段，我曾简短介绍过无监督学习算法。现在，我想将<strong>无监督学习算法</strong>与<strong>监督学习算法</strong>做个对照。</p>
<h3 id="无监督学习算法与监督学习算法对比">无监督学习算法与监督学习算法对比</h3><p>下面是一个监督学习的例子：</p>
<p><img src="/img/17_04_20/001.png" alt=""></p>
<p>$$<br>训练集：｛(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)}),…,(x^{(m)},y^{(m)})｝<br>$$</p>
<p>这是一组附有标记的训练数据集，我们想要找出一个决策边界，来将两者分开：</p>
<p><img src="/img/17_04_20/002.png" alt=""></p>
<p>在这种监督式学习中，我们针对一组标记的训练数据提出一个适当的假设。</p>
<hr>
<p>相比之下，在无监督学习案例中，我们面对的是一组<strong>无标记</strong>的训练数据，数据之间不具任何关联的标记。</p>
<p>所以我们得到的数据看起来是下面这样的：</p>
<p><img src="/img/17_04_20/003.png" alt=""></p>
<p>$$<br>训练集：｛x^{(1)},x^{(2)},x^{(3)},…,x^{(m)}｝<br>$$</p>
<p>所以，在无监督学习中，我们将这种未标记的训练数据送入特定的算法，然后我们要求算法替我们分析出数据的结构。</p>
<p>就此数据而言，其中一种可能的结构是所有的数据大致地划分成两个类（或组），这种划分的算法称为<strong>聚类算法()</strong>：</p>
<p><img src="/img/17_04_20/004.png" alt=""></p>
<p>除此之外，无监督学习还包含其他各式各样的算法，用以寻找其他类型的结构。我们下面将会一一介绍。目前，我们先介绍聚类。</p>
<h3 id="聚类">聚类</h3><p>稍早前，我已经提到几个应用实例：</p>
<p><img src="/img/17_04_20/005.png" alt=""></p>
<ul>
<li>图1是细分市场，将所有用户划分至不同的细分市场组，以便于营销或服务。</li>
<li>图2是社交分析体系，比如在社交网络中观察一群人，看他们和谁有电子邮件来往，或者查找一群相互有联系的人。</li>
<li>图3是用聚类来组织运算集群或组织数据中心，因为，如果你知道在集群中，哪些计算机的数据中心倾向于一起工作，你可以用它重新组织你的资源，网络的布局，以及数据中心和通信。</li>
<li>图4是使用聚类算法来试图理解星系的形成，和其中的天文细节。</li>
</ul>
<p>总之，聚类是我们学到的第一个无监督学习算法。在接下来的内容中，我将谈论聚类的具体实现方式。</p>
<h2 id="K-Means_算法">K-Means 算法</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/93VPG/k-means-algorithm" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在聚类问题中，我们有未加标签的数据。我们希望有一个算法能够自动的把这些数据分成<strong>有紧密关系的子集</strong>，或是<strong>簇</strong>。<strong>K均值 (K-means)算法</strong>是现在最为广泛使用的聚类方法。那么在这个视频中，我将会告诉你，什么是K均值算法以及它是怎么运作的。</p>
</blockquote>
<p>K均值算法最好用图来表达。如图所示：</p>
<p><img src="/img/17_04_20/006.png" alt=""></p>
<p>现在有一些<strong>没加标签</strong>的数据，而我想将这些数据分成两个<strong>簇</strong>。</p>
<p>现在我执行K均值算法 方法是这样的 </p>
<p>首先我随机选择两个点，这两个点叫做<strong>聚类中心 (cluster centroids) </strong>:</p>
<p><img src="/img/17_04_20/007.png" alt=""></p>
<p>为什么要两个点呢？因为我希望聚出两个类。</p>
<p>K均值是一个迭代方法，它要做两件事情：</p>
<ul>
<li>第一是<strong>簇分配</strong>。</li>
<li>第二个是<strong>移动聚类中心</strong>。</li>
</ul>
<p>接下来介绍这两个步骤具体是在做什么。</p>
<h3 id="K-Means_第一步：簇分配">K-Means 第一步：簇分配</h3><p>在K均值算法的每次循环中，第一步是要进行<strong>簇分配</strong>。这就是说，我要遍历所有的样本（就是图上所有的绿色的点），然后依据每一个点是更接近红色的这个中心、还是蓝色的这个中心，来将每个数据点分配到两个不同的聚类中心中。</p>
<p>具体来讲，就是对数据集中的所有点，依据他们更接近红色这个中心、还是蓝色这个中心，进行染色。染色之后的结果如图所示：</p>
<p><img src="/img/17_04_20/008.png" alt=""></p>
<p>以上就是簇分配的步骤。</p>
<h3 id="K-Means_第二步：移动聚类中心">K-Means 第二步：移动聚类中心</h3><p>K均值的另一部分，是要<strong>移动聚类中心</strong>。</p>
<p>具体的操作方法是这样的：我们将两个聚类中心（也就是红色的叉和蓝色的叉）移动到和它一样颜色的那堆点的均值处。</p>
<p>那么我们要做的是找出所有红色的点，计算出它们的均值位置，然后我们就把红色点的聚类中心移动到这里。对蓝色的点也同样计算平均位置，然后移动蓝色聚类中心到该平均位置处。</p>
<p><img src="/img/17_04_20/009.png" alt=""></p>
<h3 id="K-Means_第三步：重复执行上面两步">K-Means 第三步：重复执行上面两步</h3><p>然后我们就会进入下一个<strong>簇分配</strong>。我们重新检查所有没有标签的样本，依据它离红色中心还是蓝色中心更近一些，重新将它染成红色或是蓝色。</p>
<p><img src="/img/17_04_20/010.png" alt=""></p>
<p>然后我们再次<strong>移动聚类中心</strong>。计算蓝色点的均值，以及红色点的均值，然后移动两个聚类中心：</p>
<p><img src="/img/17_04_20/011.png" alt=""></p>
<p>然后再做一遍<strong>簇分配</strong>和<strong>移动聚类中心</strong>操作：</p>
<p><img src="/img/17_04_20/012.png" alt=""></p>
<p>实际上，如果你从这一步开始，一直迭代下去，聚类中心是不会变的；并且 那些点的颜色也不会变。在这时，我们就能说<strong>K均值方法已经收敛了</strong>。</p>
<h3 id="K-Means的规范化描述">K-Means的规范化描述</h3><p>我们来用更加规范的格式描述K均值算法。</p>
<p>K均值算法接受两个输入：</p>
<ul>
<li>第一个是参数$K$，表示你想从数据中聚类出的簇的个数。</li>
</ul>
<blockquote>
<p>稍后会讲到选择$K$的方法</p>
</blockquote>
<ul>
<li>第二个输入参数是训练集$｛x^{(1)},x^{(2)},…,x^{(m)}｝$</li>
</ul>
<blockquote>
<p>因为这是非监督学习，我们的数据集中不需要$y$，同时在非监督学习的 K均值算法里，我们约定$x^{(i)}$是一个$n$维向量，这就是“训练样本是$n$维而不是$n+1$维”的原因（按照惯例，排除$x_0=1$这一项）。</p>
</blockquote>
<p><strong>K均值算法：</strong></p>
<p><img src="/img/17_04_20/013.png" alt=""></p>
<ul>
<li><p>第一步：随机初始化$K$个<strong>聚类中心</strong>，记作$μ_1$,$μ_2$一直到$μ_K$。 </p>
</li>
<li><p>第二步：</p>
<ul>
<li><p>K均值内部循环执行以下步骤：</p>
<ul>
<li><p>簇分配</p>
<p> 首先对于每个训练样本，我们用变量$c^{(i)}$表示$K$个聚类中心中最接近$x^{(i)}$的那个中心的下标（具体的类别），这就是簇分配。</p>
<blockquote>
<p>大写的$K$表示所有聚类中心的个数，小写的$k$则表示某个聚类中心的下标。</p>
</blockquote>
<p>  我们希望的是：<strong>在所有K个中心中，找到一个$k$使得$x_i$到$μ_k$的距离是$x^{(i)}$到所有的聚类中心的距离中最小的那个</strong>，这就是计算$c_i$的方法。</p>
<p>  这里还有另外的表示$c_i$的方法：我用<strong>范数</strong>的形式$||x^{(i)}-μ_k||$来表示，这是第$i$个训练样本到聚类中心$μ_k$的距离。</p>
<p>  接下来我要做的是找出$k$的值，让这个式子$||x^{(i)}-μ_k||$最小，然后将 $c^{(i)}$ 赋值为$k$。</p>
<p>  出于惯例，人们更喜欢用距离的平方$||x^{(i)}-μ_k||^2$来表示$x^{(i)}$距聚类中心$μ_k$的距离。所以我们可以认为 $c^{(i)}$ 的类别是属于距样本$x^{(i)}$的距离的平方最小的那个聚类中心的。 当然使距离的平方最小或是距离最小，都能让我们得到相同的$c^{(i)}$，但是我们通常还是使用距离的平方，因为这是约定俗成的。</p>
</li>
<li><p>移动聚类中心</p>
<p>  对于每个聚类中心：$k$从1循环到$K$，将$μ_k$赋值为这个簇的均值。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>举个栗子：</strong></p>
<p>某一个聚类中心，比如说是$μ_2$被分配了一些训练样本：1,5,6,10 这个表明$c^{(1)}=2$，$c^{(5)}=2$，$c^{(6)}=2$，$c^{(10)}=2$。如果我们从<strong>簇分配</strong>那一步得到了这些结果，这表明，样本1,5,6,10被分配给了聚类中心2；然后在移动聚类中心这一步中，我们计算出这四个的平均值，即计算$x_{(1)}+x_{(5)}+x_{(6)}+x_{(10)}$，然后计算它们的平均值。这时$μ_2$就是一个$n$维的向量，因为$x^{(1)}$，$x^{(5)}$，$x^{(6)}$，$x^{(10)}$ 都是$n$维的向量。这样聚类中心$μ_2$的移动就结束了。</p>
<h3 id="异常情况">异常情况</h3><p>现在，我要问的问题是：</p>
<p>既然我们要让$μ_k$移动到分配给它的那些点的均值处，那么如果存在一个没有点分配给它的聚类中心，那怎么办? </p>
<p>通常在这种情况下，我们就直接移除那个聚类中心。如果这么做了，最终将会得到$K-1$个簇，而不是$K$个簇。</p>
<p>但如果你就是需要$K$个簇，尽管存在没有点分配给它的聚类中心，你所要做的是，重新随机找一个聚类中心。（但是直接移除那个中心，是更为常见的方法。不过在实际过程中，这个问题不会经常出现。）</p>
<hr>
<p>在这个视频结束之前，我还想告诉你<strong>K均值算法</strong>的另外一个常见应用：<strong>应对没有很好分开的簇(non-separated clusters)</strong>。</p>
<p>到目前为止，我们的K均值算法都是基于一些像图中所示的数据：</p>
<p><img src="/img/17_04_20/014.png" alt=""></p>
<p>有很好的隔离开来的三个簇，但是事实情况是，K均值经常会用于一些这样的数据：</p>
<p><img src="/img/17_04_20/015.png" alt=""></p>
<p>看起来并没有很好的分开几个簇。</p>
<p>这是一个关于T恤的大小的应用的例子。假设你是T恤制造商，你找到了一些人，想把T恤卖给他们，然后你搜集了一些这些人的身高和体重的数据。我猜，身高体重更重要一些。然后你可能收集到了上图中一些关于人们身高和体重的样本，然后你想确定一下T恤的大小。</p>
<p>假设我们要设计三种不同大小的t恤：小号、中号、和大号，那么小号应该是多大的?中号呢?大号呢?</p>
<p>使用K均值算法进行聚类，是一种解决这个问题的方法。就像我展示的那样，而且K均值可能将这些数据聚成三个簇：</p>
<p><img src="/img/17_04_20/016.png" alt=""></p>
<p>所以说，尽管这些数据原本看起来并没有三个分开的簇，但是从某种程度上讲，K均值仍然能将数据分成几个类。你能做的就是看这第一群人，然后查看他们的身高和体重，试着去设计对这群人来说比较合身的小号衣服；以及设计一个中号的衣服；设计一个大号的衣服。</p>
<p>这就是一种<strong>市场细分</strong>的例子。当你用K均值方法将你的市场分为三个不同的部分，你就能够区别对待你三类不同的顾客群体，从而更好的适应他们不同的需求。就像大、中、小，三种不同大小的衣服那样。</p>
<p><img src="/img/17_04_20/017.png" alt=""></p>
<p>这就是K均值算法，而且你现在应该已经知道如果去实现，K均值算法并且利用它解决一些问题。在下面的视频中，我想把K均值算法 研究的更深入一些，然后讨论一下如何能让K均值表现得更好一些的问题。</p>
<h2 id="优化目标">优化目标</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/G6QWt/optimization-objective" target="_blank" rel="external">视频地址</a></p>
<p>在大多数我们已经学到的<strong>监督学习</strong>算法中(例如线性回归，逻辑回归，以及更多的算法）都有一个优化目标函数，即需要通过算法进行最小化的代价函数。</p>
<p>事实上，<strong>K均值</strong>也有这样一个<strong>优化目标函数</strong>（或者说是代价函数）。</p>
<p>了解和使用这个<strong>K均值</strong>的优化目标函数有两方面的目的：</p>
<ul>
<li>首先这将能帮助我们调试学习算法，确保K均值算法是在正确运行中。</li>
<li>第二个也是最重要的一个目的是，<strong>K均值</strong>优化目标函数将帮助我们找到更好的簇，并且避免局部最优解。（后面会讲到）</li>
</ul>
<hr>
<p>另外顺便提一下，当K均值正在运行时，我们将对两组变量进行跟踪：</p>
<p>首先是$c^{(i)}$:</p>
<p>$$<br>c^{(i)}=<br>$$</p>
<p>它表示的是 当前的样本 x(i) 所归为<br>1:02<br>的那个簇的索引或者序号 另外一组变量 我们用 μk 来表示 第 k 个簇的  聚类中心 (cluster centroid) 顺便再提一句 K均值中我们用大写 K  来表示簇的总数 用小写 k 来表示 聚类中心的序号 因此 小写 k 的范围 就应该是1到大写K之间 除此以外  还有另一个符号 我们用 μc(i) 来表示 x(i) 所属的那个簇 的聚类中心 我再稍微多解释一下 这个符号 假如说 x(i) 被划为了 第5个簇<br>1:48<br>这是什么意思呢？ </p>
<p>1:50<br>这个意思是 x(i) 的序号 也就是 c(i) 等于5 因为 c(i) = 5 表示的就是<br>2:00<br>x(i) 这个样本 被分到了第五个簇 因此  μ 下标 c(i) 就等于 μ5  因为 c(i) 就是5<br>2:13<br>所以<br>2:15<br>这里的 μc(i) 就是第5个簇的聚类中心 而也正是我的样本 x(i) 所属的第5个簇 有了这样的符号表示 现在我们就能写出 K均值聚类算法的 优化目标了 以下便是 K均值算法需要 最小化的代价函数 J 参数是 c(1) 到 c(m) 以及 μ1 到 μk 随着算法的执行过程 这些参数将不断变化 右边给出了优化目标 也就是所有的 1/m 乘以 i = 1 到 m 个项的求和<br>2:50<br>这里我用红色框出了这部分 也即每个样本 x(i) 到 x(i) 所属的 聚类簇的中心 距离的平方值<br>3:01<br>下面<br>3:03<br>我来解释一下 这是训练样本 x(i) 的位置 这是 x(i) 这个样本被划分到的 聚类簇的中心的位置 我们在图上解释一下 如果这是 x1 x2 并且如果这个点 是我的第 i 个样本  x(i) 那么 也就是说这个值等于 x(i)<br>3:25<br>并且 x(i) 被分到了 某一个聚类中心 我用一个叉来表示这个聚类中心 所以 如果我们假设 这个聚类中心是 μ5  也就是说 假如 x(i) 被分到第五个聚类簇 那么这个距离平方值 也就是点 x(i) </p>
<p>3:43<br>和 x(i) 被分配到的聚类中心的 距离的平方值<br>3:49<br>那么 K均值算法 要做的事情就是 它将找到参数 c(i) 和 μi 也就是说 找到能够最小化 代价函数 J 的 c 和 μ 这个代价函数 在K均值算法中 有时候也叫做 失真代价函数(distortion cost function) 再解释详细点 这是K均值算法 这跟我们之前得到的 算法是一样的 这个算法的第一步 就是聚类中心的分配 在这一步中<br>4:27<br>我们要把每一个点 划分给各自所属的聚类中心 可以用数学证明 这个聚类簇的划分步骤 实际上就是在<br>4:40<br>对代价函数 J 进行最小化 关于参数 c(1) c(2)  等等 一直到 c(m) 而保持最近的聚类中心 μ1 到 μk 固定不变<br>4:58<br>因此 第一步要做的 其实不是改变 聚类中心的位置 而是选择 c(1) c(2) 一直到 c(m)<br>5:07<br>来最小化这个代价函数 或者说失真函数 J 不难从数学的角度证明 但我在这里就不做了 但应该还是比较容易理解 这个过程就是把这些点 划分到离它们最近的 那个聚类中心 因为这样才会使得 点到对应聚类中心的距离最短 然后 另一部分 K-均值算法的第二步 </p>
<p>5:33<br>这一部分的任务是 聚类中心的的移动 我依然不会证明这一步 但实际上是可以 在数学上来证明这一点 也就是说这一步 是选择了能够 最小化 J 的 μ 的值 也就是说 最小化代价函数 J 关于 这里的 wrt 表示 with respect to (关于) 因此是最小化 J 关于所有聚类中心的位置 μ1 到 μK 因此 K均值算法 实际上是把这两组变量 在这两部分中 分割开来考虑 分别最小化 J 首先是 c 作为变量 然后是 μ 作为变量 那么 K均值的工作就是 首先关于 c 求 J 的最小值 然后关于 μ  求 J 的最小值 然后反复循环<br>6:25<br>这就是 K均值算法<br>6:27<br>现在 我们已经理解了 K均值算法的原理 就是最小化代价函数 J 的过程 我们也可以用这个原理 来试着调试我们的学习算法 保证我们对 K均值算法的实现过程 是正确的<br>6:41<br>好的 这节课我们介绍了 K均值算法 其核心就是 对代价函数 J 的优化过程 代价函数 J 也被称为失真函数<br>6:50<br>我们可以用这个知识 来调试K均值算法 证明算法是否正在收敛 是否正在正常工作 在下一节视频中 我们将一起看看 如何帮助K均值找到更好的簇 同时避免局部最优解 </p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/" itemprop="url">
                斯坦福机器学习课程 第七周 (3)使用SVM
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-11T22:47:58+08:00" content="2017-04-11">
            2017-04-11
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h2 id="使用SVM">使用SVM</h2><blockquote>
<p>这段视频中，我们将介绍使用SVM时，我们实际上需要做些什么。</p>
</blockquote>
<p><strong>支持向量机</strong>是一个特定的优化问题，但是我不建议你自己去手动实现这一算法来求解参数$\theta$。就像如今只有很少的人，或者说根本没有人会考虑自己写代码，来实现对矩阵求逆，或求一个数的平方根等。我们只需要调用库函数来实现这些功能即可。</p>
<p>同样，可以用于解决SVM优化问题的软件很复杂，而且已经有专门研究数值优化很多年的学者在做这个，因此你需要使用好的软件库来做这个。我强烈建议使用一个高度优化的软件库，而不是尝试自己去实现它。</p>
<p>这里推荐两个我最常用到的库：liblinear和libsvm。</p>
<p>尽管你不需要自己去实现SVM，但你也需要做以下几件事：</p>
<ul>
<li>选择参数$C$</li>
<li>选择<strong>核函数</strong>（相似度函数）</li>
</ul>
<h3 id="核函数的选择">核函数的选择</h3><h4 id="线性核函数（无核函数）">线性核函数（无核函数）</h4><p>关于<strong>核函数</strong>其中一个选择是<strong>不用任何核函数</strong>（不用任何核函数也叫作<strong>线性核函数</strong>）:</p>
<p>即对于预测结果$y=1$，满足$\theta^Tx\ge0$。</p>
<blockquote>
<p>例如这种情况下当$\theta_0 + \theta_1x_1 + … + \theta_nx_n \ge 0$时，预测$y=1$。</p>
</blockquote>
<p>对<strong>线性核函数</strong>这个术语，你可以把它理解为这个版本的SVM。它只是给你一个标准的线性分类器，因此对某些问题来说，它是一个合理的选择：</p>
<p>具体来说，当你的特征数量$n$很大，但数据量$m$很小时，由于数据量不足，在这种情况下如果使用其他核函数，你可能会<strong>过拟合</strong>，因此，此时<strong>线性核函数</strong>是一个合理的选择。</p>
<h4 id="高斯核函数">高斯核函数</h4><p>$$<br>f_i=exp(-\frac{||x-l^{(i)}||^2}{2\sigma^2}),<br>$$</p>
<p>这是我们之前见过的高斯核函数。如果你选择这个核函数，那么你需要选择一个$$\sigma^2$$。</p>
<p>我们之前讨论如何权衡偏差、方差的时候谈论过：</p>
<ul>
<li>如果$\sigma^2$很大，那么你就有可能得到一个<strong>较高偏差较低方差</strong>的分类器。</li>
<li>如果$\sigma^2$很小，那么你就有可能得到一个<strong>较低偏差较高方差</strong>的分类器。</li>
</ul>
<p>那么，什么时候选择高斯核函数呢？</p>
<p>如果你原来的特征变量$x$是$n$维的，而且<strong>$n$很小，样本数量$m$很大时</strong>，高斯核函数会是一个不错的选择。</p>
<h5 id="如何使用高斯核函数">如何使用高斯核函数</h5><p>在很多SVM的软件包中，如果你需要使用SVM时，你需要提供一个核函数。</p>
<p>具体地说，如果你决定使用高斯核函数，那么你需要做的就是根据你所用的SVM软件包，来提供一个用于计算核函数的特定特征的方法:</p>
<p><img src="/img/17_04_11/001.png" alt=""></p>
<p>然后它将自动地生成所有特征变量。</p>
<blockquote>
<p><strong>注意</strong>：如果你有大小很不一样的特征变量，在使用高斯核函数之前，对它们进行<strong>归一化</strong>是很重要的。</p>
</blockquote>
<p>假设你在计算$x$和$l$之间的范数(就是高斯核函数的分子项)：</p>
<p>$||x-l||^2$</p>
<p>这个式子所表达的含义如下：</p>
<p>$$<br>v=x-l<br>$$</p>
<p>$$<br>\begin{align*}<br>||v||^2 &amp;= v_1^2 + v_2^2 + … + v_n^2 \\<br>&amp;= (x_1-l_1)^2 + (x_2-l_2)^2 + … + (x_n-l_n)^2<br>\end{align*}<br>$$</p>
<p>其中$v$、$x$、$l$都是向量，由于$x$是$n$维的，所以$v$也是$n$维的。</p>
<p>现在如果你的特征变量取值范围很不一样。例如房价预测中，$x_1$表示1000平方英尺，$x_2$表示卧室数量为2，那么$(x_1-l_1)$可能相较于$(x_2-l_2)$大很多。</p>
<p>因此，为了让SVM更好的工作，我们需要对特征变量进行<strong>归一化</strong>处理。这将会保证SVM能够同等地关注到所有不同的特征变量。</p>
<h4 id="选择其他核函数">选择其他核函数</h4><p>当你尝试使用SVM时，目前你能用到的核函数就是<strong>线性核函数</strong>和<strong>高斯核函数</strong>，这里有一个警告：</p>
<p>不是所有你可能提出来的相似度函数都是有效的核函数。线性核函数，高斯核函数，以及其他人有时会用到的其他的核函数，他们全部需要满足一个技术条件，这个条件叫做<strong>摩赛尔定理(Mercer`s Theorem)</strong>。</p>
<p>因为支持向量机算法的实现有许多巧妙的数值优化技巧，为了有效地求解参数$\theta$，在最初的设想里，有一个这样的决定，将我们的注意力仅仅限制在可以满足<strong>摩赛尔定理</strong>的核函数上，这个定义做的是：确保所有的SVM包能够使用大量的优化方法，并且快速地得到参数$\theta$。所以，大多数人最后要么使用线性核函数、要么使用高斯核函数。也有一些其他的核函数是满足<strong>摩赛尔定理</strong>的，而我个人是很少很少使用其他核函数的。</p>
<p>所以，我只是简单提及一下你可能会遇到的其他核函数，他们有：</p>
<ul>
<li><p><strong>多项式核函数（Polynomial kernel）</strong>：</p>
<ul>
<li><p>将$x$和$l$之间的相似度，定义为$(x^Tl)^2$：</p>
<p>$$<br>k(x,l)=(x^Tl)^2<br>$$</p>
<p>这就是一个$x$和$l$相似度的估量，如果$x$和$l$每一项很接近，那么这个内积就会很大。</p>
<p>这是一个有些不寻常的核函数，它并不常用，但你可能会见到有人使用它的变体形式，比如：</p>
<p>$$<br>k(x,l)=(x^Tl)^3<br>$$</p>
<p>$$<br>k(x,l)=(x^Tl + 1)^3<br>$$</p>
<p>$$<br>k(x,l)=(x^Tl + 5)^4<br>$$</p>
<p>这些都是多项式核函数的变形形式。</p>
<p>多项式核函数实际上有两个参数，一个是加在后面的常数项，如上面最后式子中的5；另一个是多项式的次数，如上面最后式子中的4。</p>
<p>因此，多项式核函数的更一般的形式是：</p>
<p>$$<br>k(x,l)=(x^Tl + constant)^{degree}<br>$$</p>
<p>这种核函数并不像高斯核函数那样频繁的使用，通常他只用在当$x$和$l$都是严格的非负数时。这样以确保内积值永远不会是负数。</p>
<p>这捕捉到了这样一个直观感觉：如果$x$和$l$之间非常相似，也许它们之间的内积会很大。</p>
<p>它们也有其他的一些性质，但是人们通常用得不多。</p>
</li>
</ul>
</li>
</ul>
<p>你也有可能会碰到其他一些更难懂的核函数，比如：</p>
<ul>
<li><strong>字符串核函数（String kernel）</strong>:<ul>
<li>如果你的输入数据是文本字符串，或者其他类型的字符串，有时会用到这个核函数。</li>
</ul>
</li>
<li><strong>卡方核函数（chi-square kernel）</strong></li>
<li><strong>直方图交叉核函数（histogram intersection kernel）</strong></li>
<li>…</li>
</ul>
<p>你可以用它们来度量不同对象之间的相似性。</p>
<p>例如，你在做一些文本分类问题，在这个问题中，输入变量$x$是一个字符串，我们想要通过字符串核函数来找到两个字符串间的相似度（但是我个人很少用这些更加难懂的核函数，我想我平生可能用过一次卡方核函数，可能用过一次或两次直方图交叉核函数，我甚至没用过字符串核函数）。</p>
<hr>
<h3 id="两个细节">两个细节</h3><p>我想要在这个视频里讨论最后两个细节。</p>
<h4 id="多类分类">多类分类</h4><p>在多类分类中，你有K个类别：</p>
<p>$$<br>y \in ｛1,2,3,…,K｝<br>$$</p>
<p>对应下图：</p>
<p><img src="/img/17_04_11/002.png" alt=""></p>
<p>很明显，这里$K=4$。</p>
<p>那么怎样让SVM输出下面这种各个类别间合适的判定边界呢？</p>
<p><img src="/img/17_04_11/003.png" alt=""></p>
<p>大部分SVM软件包已经内置了多类分类的函数了，因此，如果你用的是这种软件包，你可以直接使用内置函数。</p>
<p>另一种方式就是使用<strong>一对多(one-vs-all)方法</strong>。这个我们在讲逻辑回归的时候讨论过，所以，你要做的就是要训练$K$个SVM，每一个SVM把一个类同其他类区分开。这种操作会给你$K$个参数向量：</p>
<p>$$<br>\theta^{(1)},\theta^{(2)},…,\theta^{(K)}<br>$$</p>
<p>最后，这就与我们在逻辑回归中用到的一对多方法一样，选取使得$(\theta^{(i)})^Tx$最大的类$i$即可。</p>
<blockquote>
<p>其实大多数软件包都已经内置了多类分类的函数，因此你不必重新造轮子。</p>
</blockquote>
<h4 id="逻辑回归_vs_SVM">逻辑回归 vs SVM</h4><p>关于<strong>逻辑回归</strong>和<strong>SVM</strong>，我想讨论的是，你什么时候应该用哪个呢？</p>
<p>假设$n$是特征变量的个数，$m$是训练样本数：</p>
<ul>
<li>如果$n$(相对于$m$)大很多时，使用<strong>逻辑回归</strong>，或者使用<strong>无核函数的SVM（线性核函数）</strong>。<br>  比如你有一个文本分类的问题，特征数量$n=10000$，而且如果你的训练集大小为$m=10$，在这个问题中，你有10000个特征变量，对应10000个词，但是你只有10个训练样本。这种情况下就比较适合使用逻辑回归或者线性核函数的SVM了。</li>
<li>如果$n$较小，$m$是中等大小，（例如$n$为1到1000之间的值，$m$为10到10000之间的值）那么使用<strong>高斯核函数的SVM</strong>效果好一些。</li>
<li>如果$n$很小，$m$很大时（例如$n=1000$,$m=100000+$），那么高斯核函数的SVM运行起来会很慢，这种情况下，需要<strong>尝试手动地创建更多的特征变量，然后使用逻辑回归或者无核函数的SVM（线性核函数）</strong>。</li>
</ul>
<p>逻辑回归和不带核函数的SVM它们都是非常相似的算法，他们会做相似的事情，并且表现也相似，但是根据你实现的具体情况，其中一个可能会比另一个更加有效。</p>
<p>但是SVM的威力会随着你用不同的核函数而发挥出来。</p>
<h4 id="什么时候使用神经网络？">什么时候使用神经网络？</h4><p>最后，神经网络应该在什么时候使用呢？</p>
<p>对于上面所有的情况，一个设计得很好的神经网络也很可能会非常有效，它的一个缺点（或者说不使用神经网络的原因）是：神经网络训练起来可能会很慢。但是如果你有一个非常好的SVM实现包，它会运行得比较快，比神经网络快很多。</p>
<blockquote>
<p>SVM的优化问题，实际上是一个<strong>凸优化</strong>问题。因此好的SVM优化软件包总是会找到全局最小值，或者接近它的值。<br>对于SVM，你不需要担心局部最优。在实际应用中，局部最优对神经网络来说不是非常大，但是也不小。所以使用SVM，你不用考虑这部分问题。</p>
</blockquote>
<hr>
<h3 id="总结">总结</h3><p>最后，如果你觉得上面这些使用参考有一些模糊，在面临实际问题时，仍然不能完全确定具体使用哪个算法更好，这个其实很正常。</p>
<p>当我遇到机器学习问题时，有时确实不清楚具体使用哪个算法更好，但是正如你在之前的视频中看到的，算法确实很重要，但是通常更重要的是：<strong>你有多少数据</strong>，<strong>你有多熟练</strong>，<strong>是否擅长做误差分析和调试学习算法</strong>，<strong>想出如何设计新的特征变量</strong>，<strong>想出如何设计新的特征变量</strong>，以及<strong>找出应该输入给学习算法的其它特征变量</strong>等方面。通常这些方面会比你使用<strong>逻辑回归</strong>还是<strong>SVM</strong>更加重要。</p>
<p>但是<strong>SVM</strong>仍然被广泛认为是<strong>最强大的学习算法之一</strong>，最强大的学习算法之一，而且SVM在一个区间内是一个非常有效地学习复杂非线性函数的方法。因此，有了<strong>逻辑回归</strong>、<strong>神经网络</strong>、<strong>SVM</strong>这三个学习算法，我想你已经具备了在广泛的应用里构建最前沿的机器学习系统的能力。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/" itemprop="url">
                通过AspectJ代码注入来实现scheme跳转条件的检查判断
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-21T22:48:58+08:00" content="2017-03-21">
            2017-03-21
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/Android/" itemprop="url" rel="index">
                  <span itemprop="name">Android</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>scheme跳转是Android通过外部链接打开APP指定页面的一种常见的实现方式，如果只是简单的跳转，那么不需要做什么额外的判断就可以打开指定页面了，但我们的产品中有一个需求就是：在通过scheme跳转打开某一个页面的时候，需要判断一些前置条件，如果前置条件满足的情况下，才能执行跳转，如果前置条件不满足，那么需要缓存本次跳转，直到需要满足的条件被触发时，才去执行跳转。</p>
<p>简单说来就是下面这张图：</p>
<p><img src="/img/17_03_21/001.png" alt=""></p>
<p>一开始我想到的处理方式是通过在Activity的基类里的<code>onCreate()</code>方法之前做判断逻辑，如果符合条件，则正常执行，如果条件不满足，则执行<code>finish()</code>。</p>
<p>虽然可以满足需求，但这样的代码侵入性太高，逻辑必须侵入到Activity的基类中，容易与基类中其他逻辑产生耦合。</p>
<p>因此为了解决这个方式，我想到的解决方式就是使用AOP的方式，在<code>onCreate()</code>之前注入我们的判断逻辑的代码，最后的使用方式可以简化到仅仅使用一行注解来添加判断条件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@SchemeCheck</span>(conditions = &#123;Condition.LOGIN&#125;)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TargetActivityA</span> <span class="keyword">extends</span> <span class="title">Activity</span> </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">    &#125;</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这样一来，我们就不用考虑在Activity的基类中写这些可能产生冗余的逻辑了。</p>
<p>最终实现效果如下：</p>
<ul>
<li>判断<strong>登录</strong>条件</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/002.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断<strong>下载</strong>条件</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/003.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断<strong>登录并且下载</strong></li>
</ul>
<video width="300px" align="center" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/004.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断登录或者下载</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/005.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<p>接下来介绍一下我是如何实现的。</p>
<h2 id="如何实现">如何实现</h2><p>首先关于<strong>依赖注入</strong>以及<strong>AspectJ</strong>的相关使用，我参考了以下文章以及代码，具体使用方式我就不再赘述：</p>
<ul>
<li><a href="http://www.jianshu.com/p/0fa8073fd144" target="_blank" rel="external">【翻译】Android中的AOP编程</a>  这一篇对AOP概念进行了介绍，并且通过AspectJ仿照<a href="https://github.com/JakeWharton/hugo" target="_blank" rel="external">Hugo</a>实现了一个AOP的Demo。</li>
<li>JakeWharton大神的<a href="https://github.com/JakeWharton/hugo" target="_blank" rel="external">hugo</a> 项目，通过AspectJ实现的日志工具。</li>
<li><a href="http://blog.csdn.net/crazy__chen/article/details/52014672" target="_blank" rel="external">使用AspectJ在Android中实现Aop</a>这一篇文章是对上面的文章和hugo项目的总结。</li>
</ul>
<hr>
<p>下面是我的实现：</p>
<p>首先，定义注解：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="variable">@Retention</span>(RetentionPolicy.RUNTIME)</div><div class="line"><span class="variable">@Target</span>(&#123;ElementType.TYPE&#125;)</div><div class="line">public <span class="variable">@interface</span> SchemeCheck &#123;</div><div class="line">    Condition<span class="selector-attr">[]</span> <span class="selector-tag">conditions</span>();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>值得提醒的是，这里<code>@Retention</code>要定义为<code>RetentionPolicy.RUNTIME</code>，因为我们要在运行时检查注解的参数，来判断scheme的触发条件。如果你写成了<code>RetentionPolicy.CLASS</code>或者<code>RetentionPolicy.SOURCE</code>就检查不到了。</p>
<p><code>Condition</code>是我们定义的需要判断的条件枚举：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public <span class="class"><span class="keyword">enum</span> <span class="title">Condition</span> &#123;</span></div><div class="line">    NULL(null),</div><div class="line">    LOGIN(new LoginCondition()),</div><div class="line">    DOWNLOAD_BOOK(new BookDownloadCondition()),</div><div class="line">    LOGIN_OR_DOWNLOAD_BOOK(new LoginOrBookDownloadCondition());</div><div class="line"></div><div class="line">    BaseCondition condition;</div><div class="line">    Condition(BaseCondition condition) &#123;</div><div class="line">        this.condition = condition;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public BaseCondition getCondition() &#123;</div><div class="line">        <span class="keyword">return</span> condition;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>Condition</code>可以通过<code>getCondition()</code>来获取到具体的继承自<code>BaseCondition</code>的Condition对象：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseCondition</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isSatisfied</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title">unSatisfiedInfo</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由于是Demo，我们的登录条件暂时写死，到时候换成你具体的业务逻辑即可：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginCondition</span> <span class="keyword">extends</span> <span class="title">BaseCondition</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> isLogin = <span class="keyword">false</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSatisfied</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> isLogin;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">unSatisfiedInfo</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"请先登录"</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>有了这些，我们就可以写注入代码了：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Aspect</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SchemeCheckAspect</span> </span>&#123;</div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"within(@demo.com.aj.anno.SchemeCheck *)"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">withinAnnotatedClass</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(!synthetic * *(..)) &amp;&amp; withinAnnotatedClass()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">methodInsideAnnotatedType</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(@demo.com.aj.anno.SchemeCheck * *(..)) || methodInsideAnnotatedType()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Around</span>(<span class="string">"method()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function">Object <span class="title">weaveJoinPoint</span><span class="params">(ProceedingJoinPoint joinPoint)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">        Signature signature = joinPoint.getSignature();</div><div class="line">        String methodName = signature.getName();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (TextUtils.equals(methodName, <span class="string">"onCreate"</span>)) &#123;</div><div class="line">            SchemeCheck anno = (SchemeCheck) signature.getDeclaringType().getAnnotation(SchemeCheck.class);</div><div class="line">            <span class="keyword">if</span> (anno != <span class="keyword">null</span>) &#123;</div><div class="line">                Condition[] conditions = anno.conditions();</div><div class="line">                Object point = joinPoint.getThis();</div><div class="line">                <span class="keyword">if</span> (point != <span class="keyword">null</span> &amp;&amp; point <span class="keyword">instanceof</span> Activity) &#123;</div><div class="line">                    Activity activity = (Activity) point;</div><div class="line">                    handleScheme(activity, conditions);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">return</span> joinPoint.<span class="title">proceed</span><span class="params">()</span></span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 检查前置条件</div><div class="line">     *</div><div class="line">     * <span class="doctag">@return</span> 是否通过检查</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">checkCondition</span><span class="params">(Condition[] conditions)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (conditions != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">for</span> (Condition condition : conditions) &#123;</div><div class="line">                BaseCondition conditionObj = condition.getCondition();</div><div class="line">                <span class="keyword">if</span> (conditionObj != <span class="keyword">null</span></div><div class="line">                        &amp;&amp; !conditionObj.isSatisfied()) &#123;</div><div class="line">                    Toast.makeText(App.getContext(), conditionObj.unSatisfiedInfo(), Toast.LENGTH_SHORT).show();</div><div class="line">                    SchemeManager.Cache.save(condition);</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 通过验证</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">void</span> <span class="title">passSatisfy</span><span class="params">()</span> </span>&#123;</div><div class="line">        SchemeManager.Cache.clear();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 处理前置条件的检查结果</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> isPass 检查是否通过</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">void</span> <span class="title">handleCheck</span><span class="params">(Activity activity, <span class="keyword">boolean</span> isPass)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (isPass) &#123;</div><div class="line">            passSatisfy();</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">if</span> (activity != <span class="keyword">null</span>) &#123;</div><div class="line">                activity.finish();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     *</div><div class="line">     * 处理scheme相关的事情</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> activity</div><div class="line">     * <span class="doctag">@param</span> conditions</div><div class="line">     * <span class="doctag">@return</span> 是否通过验证</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">handleScheme</span><span class="params">(Activity activity, Condition[] conditions)</span> </span>&#123;</div><div class="line">        <span class="keyword">boolean</span> passCheck = <span class="keyword">true</span>;</div><div class="line">        <span class="keyword">if</span> (isStartByScheme(activity)) &#123;</div><div class="line">            passCheck = checkCondition(conditions);</div><div class="line">            handleCheck(activity, passCheck);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            passCheck = <span class="keyword">true</span>;</div><div class="line">            passSatisfy();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> passCheck;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 检查是否是由scheme开启</div><div class="line">     *</div><div class="line">     * <span class="doctag">@return</span></div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">isStartByScheme</span><span class="params">(Activity activity)</span> </span>&#123;</div><div class="line">        <span class="keyword">boolean</span> isScheme = <span class="keyword">false</span>;</div><div class="line">        <span class="keyword">if</span> (activity != <span class="keyword">null</span>) &#123;</div><div class="line">            Intent intent = activity.getIntent();</div><div class="line">            <span class="keyword">if</span> (intent != <span class="keyword">null</span>) &#123;</div><div class="line">                isScheme = intent.getBooleanExtra(KEY_IS_SCHEME, <span class="keyword">false</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> isScheme;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到，我们在<code>onCreate()</code>方法开始之前，我们注入了scheme的判断逻辑，当条件满足时，直接执行了后面的逻辑；当条件不满足时，将不满足的条件进行缓存，并且<code>finish()</code>当前Activity。当正常执行了scheme跳转之后，清空缓存。</p>
<p>其中<code>SchemeManager</code>的逻辑如下：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SchemeManager</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String KEY_IS_SCHEME = <span class="string">"isScheme"</span>;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Cache</span> </span>&#123;</div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> String next = <span class="string">""</span>;</div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Condition unSatisfiedCondition;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">save</span><span class="params">(Condition condition)</span> </span>&#123;</div><div class="line">            unSatisfiedCondition = condition;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span></span>&#123;</div><div class="line">            next = <span class="string">""</span>;</div><div class="line">            unSatisfiedCondition = <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">reExecuteScheme</span><span class="params">(Activity activity, Condition condition)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (Cache.unSatisfiedCondition != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="comment">// 当缓存的条件与当前重复执行时触发的条件一致时，再次执行scheme</span></div><div class="line">            <span class="keyword">if</span> (Cache.unSatisfiedCondition == condition) &#123;</div><div class="line">                String scheme = Cache.next;</div><div class="line">                executeScheme(activity, scheme);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">executeScheme</span><span class="params">(Activity activity, String schemeStr)</span> </span>&#123;</div><div class="line">        Cache.next = schemeStr;</div><div class="line">        Class&lt;? <span class="keyword">extends</span> Activity&gt; <span class="keyword">target</span> = <span class="keyword">null</span>;</div><div class="line">        <span class="keyword">switch</span> (schemeStr) &#123;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startA"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityA.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startB"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityB.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startC"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityC.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startD"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityD.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (<span class="keyword">target</span> != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="comment">// 如果当前页和目标页面是同一个页面  则清空缓存  防止递归调用产生死循环</span></div><div class="line">            <span class="keyword">if</span> (<span class="keyword">target</span>.equals(activity.getClass())) &#123;</div><div class="line">                Cache.clear();</div><div class="line">                <span class="keyword">return</span>;</div><div class="line">            &#125;</div><div class="line">            Intent intent = <span class="keyword">new</span> Intent(activity, <span class="keyword">target</span>);</div><div class="line">            intent.putExtra(KEY_IS_SCHEME, <span class="keyword">true</span>);</div><div class="line">            activity.startActivity(intent);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里包含有缓存管理的逻辑，以及<strong>执行scheme</strong>和<strong>重复执行scheme</strong>的逻辑。</p>
<p>其中，由于是Demo，执行scheme的逻辑用固定的字符串来代表scheme链接，这里需要你来替换为你自己的业务逻辑，因为你可能有解析scheme参数并且传递到目标Activity的逻辑。</p>
<p>scheme缓存保存了scheme链接和最后一次没有通过的条件枚举值，当下一次条件被触发时，通过<code>reExecuteScheme</code>来执行缓存中的scheme，达到继续跳转的效果。</p>
<p>例如，在登录成功的地方，可以执行:</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reExecuteScheme(<span class="keyword">this</span>, Condition.LOGIN);</div></pre></td></tr></table></figure>
<p>来达到登录成功时继续触发<strong>因未登录导致的scheme跳转失败的scheme跳转</strong>（好绕啊…）。</p>
<h2 id="愉快的调用">愉快的调用</h2><p>接下来我们在需要加入scheme跳转判断的Activity的类上加入注解判断即可，例如我们在下面的Activity上加入<strong>登录</strong>以及<strong>词书下载</strong>的条件判断：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="variable">@SchemeCheck</span>(conditions = &#123;Condition.LOGIN, Condition.DOWNLOAD_BOOK&#125;)</div><div class="line">public class TargetActivityC extends Activity &#123;</div><div class="line"></div><div class="line">    <span class="selector-tag">public</span> <span class="selector-tag">static</span> <span class="selector-tag">void</span> <span class="selector-tag">start</span>(Activity activity) &#123;</div><div class="line">        activity<span class="selector-class">.startActivity</span>(new Intent(activity, TargetActivityC.class));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="variable">@Override</span></div><div class="line">    protected void onCreate(Bundle savedInstanceState) &#123;</div><div class="line">        super<span class="selector-class">.onCreate</span>(savedInstanceState);</div><div class="line">        setContentView(R<span class="selector-class">.layout</span><span class="selector-class">.activity_c</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>是不是很简单呢？</p>
<h2 id="注意！这里有坑">注意！这里有坑</h2><p>目前发现的一个坑就是我们的加入scheme跳转判断的子类Activity中必须有<code>onCreate</code>方法才可以正常执行，因为<code>AspectJ</code>只能判断当前子类中所触发的子类的方法。也就是说如果即使你对Activity的基类的<code>onCreate</code>进行了一层封装，完成了<code>onCreate</code>的所有工作，子类也需要复写一下<code>onCreate</code>。就像这样：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line">   <span class="keyword">protected</span> <span class="function"><span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</div><div class="line">       <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>否则会crash。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/" itemprop="url">
                【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-09T00:07:58+08:00" content="2017-03-09">
            2017-03-09
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>在训练模型时，实时跟踪和评估进度通常很有价值。在本教程中，您将学习如何使用TensorFlow的日志记录功能和<code>Monitor</code> API来审计用于分类鸢尾花的神经网络分类器的正在进行中的训练。本教程基于在<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>中开发的代码，所以如果你还没有完成该教程，你可能想先探索它， 特别是如果你正在寻找一个tf.contrib.learn基础介绍/复习文章时。</p>
<h2 id="创建">创建</h2><p>在本教程中，你将在从<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>中的下面的代码来进行构建：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">from __future__ <span class="built_in">import</span> absolute_import</div><div class="line">from __future__ <span class="built_in">import</span> division</div><div class="line">from __future__ <span class="built_in">import</span> print_function</div><div class="line"></div><div class="line"><span class="built_in">import</span> os</div><div class="line"></div><div class="line"><span class="built_in">import</span> numpy as np</div><div class="line"><span class="built_in">import</span> tensorflow as tf</div><div class="line"></div><div class="line"><span class="comment"># Data sets</span></div><div class="line"><span class="attr">IRIS_TRAINING</span> = os.path.join(os.path.dirname(__file__), <span class="string">"iris_training.csv"</span>)</div><div class="line"><span class="attr">IRIS_TEST</span> = os.path.join(os.path.dirname(__file__), <span class="string">"iris_test.csv"</span>)</div><div class="line"></div><div class="line">def main(unused_argv):</div><div class="line">    <span class="comment"># Load datasets.</span></div><div class="line">    <span class="attr">training_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">        <span class="attr">filename=IRIS_TRAINING,</span> <span class="attr">target_dtype=np.int,</span> <span class="attr">features_dtype=np.float32)</span></div><div class="line">    <span class="attr">test_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">        <span class="attr">filename=IRIS_TEST,</span> <span class="attr">target_dtype=np.int,</span> <span class="attr">features_dtype=np.float32)</span></div><div class="line"></div><div class="line">    <span class="comment"># Specify that all features have real-value data</span></div><div class="line">    <span class="attr">feature_columns</span> = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, <span class="attr">dimension=4)]</span></div><div class="line"></div><div class="line">    <span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></div><div class="line">    <span class="attr">classifier</span> = tf.contrib.learn.DNNClassifier(<span class="attr">feature_columns=feature_columns,</span></div><div class="line">                                                <span class="attr">hidden_units=[10,</span> <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">                                                <span class="attr">n_classes=3,</span></div><div class="line">                                                <span class="attr">model_dir="/tmp/iris_model")</span></div><div class="line"></div><div class="line">    <span class="comment"># Fit model.</span></div><div class="line">    classifier.fit(<span class="attr">x=training_set.data,</span></div><div class="line">                   <span class="attr">y=training_set.target,</span></div><div class="line">                   <span class="attr">steps=2000)</span></div><div class="line"></div><div class="line">    <span class="comment"># Evaluate accuracy.</span></div><div class="line">    <span class="attr">accuracy_score</span> = classifier.evaluate(<span class="attr">x=test_set.data,</span></div><div class="line">                                         <span class="attr">y=test_set.target)["accuracy"]</span></div><div class="line">    print('Accuracy: &#123;<span class="number">0</span>:f&#125;'.format(accuracy_score))</div><div class="line"></div><div class="line">    <span class="comment"># Classify two new flower samples.</span></div><div class="line">    <span class="attr">new_samples</span> = np.array(</div><div class="line">        [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>], [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], <span class="attr">dtype=float)</span></div><div class="line">    <span class="attr">y</span> = list(classifier.predict(new_samples, <span class="attr">as_iterable=True))</span></div><div class="line">    print('Predictions: &#123;&#125;'.format(str(y)))</div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="attr">__name__</span> == <span class="string">"__main__"</span>:</div><div class="line">  tf.app.run()</div></pre></td></tr></table></figure>
<p>将上述代码复制到一个文件中，并将相应的<a href="http://download.tensorflow.org/data/iris_training.csv" target="_blank" rel="external">训练</a>和<a href="https://www.tensorflow.org/api_docs/python/tf/test" target="_blank" rel="external">tf.test</a>数据集下载到同一目录。</p>
<p>在以下部分中，您将逐步更新上述代码以添加日志记录和监视功能。包含所有更新的最终代码可在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/monitors/iris_monitors.py" target="_blank" rel="external">此处</a>下载。</p>
<h2 id="概述">概述</h2><p><a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>教程中通过如何实现一个神经网络分类器实现了将鸢尾花的样本分为三种类型之一。</p>
<p>但是，当运行本教程的<a href="https://www.tensorflow.org/get_started/monitors#setup" target="_blank" rel="external">代码</a>时，输​​出并不包含日志记录跟踪模型训练如何进行 - 仅包含打印语句的结果：</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">Accuracy:</span> <span class="number">0.933333</span></div><div class="line"><span class="symbol">Predictions:</span> [<span class="number">1</span> <span class="number">2</span>]</div></pre></td></tr></table></figure>
<p>没有任何日志记录，模型训练感觉就像一个黑盒子;你不能看到发生了什么，因此TensorFlow通过逐步的梯度下降，了解模型是否适当的收敛、或者确定是否可以提前停止训练是有必要的。</p>
<p>解决这个问题的一种方法是将模型训练分成具有较少步骤的多个<code>fit</code>(拟合)调用，以便逐步评估准确性。然而，这不是推荐的做法，因为它大大减慢了模型的训练过程。幸运的是，tf.contrib.learn提供了另一个解决方案：一个<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/monitors" target="_blank" rel="external">Monitor API</a>，旨在帮助您在训练正在进行时记录指标并评估模型。在以下部分中，您将学习如何在TensorFlow中启用日志记录，设置ValidationMonitor进行流评估，以及使用TensorBoard可视化您的度量。</p>
<h2 id="启用TensorFlow的日志记录">启用TensorFlow的日志记录</h2><p>TensorFlow对日志消息使用五个不同的级别。按照严重性递增的顺序，它们是<code>DEBUG</code>，<code>INFO</code>，<code>WARN</code>，<code>ERROR</code>和<code>FATAL</code>。当您在配置任何这些级别的日志记录时，TensorFlow将输出与该级别以及所有严重性级别高于该级别的相对应的所有日志消息。例如，如果您设置为<code>ERROR</code>的日志级别，您将获得包含<code>ERROR</code>和<code>FATAL</code>消息的日志输出，如果设置为<code>DEBUG</code>级别，则将获取所有五个级别的日志消息。</p>
<p>默认情况下，TensorFlow的日志级别为<code>WARN</code>，但是在跟踪模型训练时，您需要将级别调整为<code>INFO</code>，这将在适配操作正在进行时提供其他反馈。</p>
<p>将以下行添加到代码的开头（在<code>import</code>之后）：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf<span class="selector-class">.logging</span><span class="selector-class">.set_verbosity</span>(tf<span class="selector-class">.logging</span><span class="selector-class">.INFO</span>)</div></pre></td></tr></table></figure>
<p>现在当你运行代码，你会看到额外的日志输出，如下所示：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">1.18812</span>, step = <span class="number">1</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">0.210323</span>, step = <span class="number">101</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">0.109025</span>, step = <span class="number">201</span></div></pre></td></tr></table></figure>
<p>使用<code>INFO</code>级别日志记录，tf.contrib.learn每100步后自动向标准错误（stderr）输出<a href="https://en.wikipedia.org/wiki/Loss_function" target="_blank" rel="external">训练损失指标</a>。</p>
<h2 id="为流式处理评估配置验证监视器">为流式处理评估配置验证监视器</h2><p>记录训练损失有助于了解您的模型是否收敛，但如果您想进一步了解训练期间发生的情况怎么办？tf.contrib.learn提供了几个高级监视器，您可以附加到您的合适的操作中，以进一步在模型训练期间跟踪指标和/或调试较低级别的TensorFlow操作，包括：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Monitor</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>CaptureVariable</code></td>
<td style="text-align:left">在训练的每n个步骤中将指定变量的值保存到集合中</td>
</tr>
<tr>
<td style="text-align:left"><code>PrintTensor</code></td>
<td style="text-align:left">在训练的每n个步骤记录指定的tensor的值</td>
</tr>
<tr>
<td style="text-align:left"><code>SummarySaver</code></td>
<td style="text-align:left">在每n个训练步骤使用<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>保存给定tensor的<a href="https://www.tensorflow.org/api_docs/python/tf/Summary" target="_blank" rel="external"><code>tf.Summary</code></a><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="external">protocol buffers</a></td>
</tr>
<tr>
<td style="text-align:left"><code>ValidationMonitor</code></td>
<td style="text-align:left">在训练的每n个步骤记录指定的一组评估度量，并且如果需要，可以在某些条件下实现提前停止训练</td>
</tr>
</tbody>
</table>
<h3 id="评估每N个步骤">评估每N个步骤</h3><p>对于鸢尾花神经网络分类器，在记录训练损失时，您可能还需要同时评估测试数据，以了解模型的泛化程度。您可以通过使用测试数据（<code>test_set.data</code>和<code>test_set.target</code>）配置一个<code>ValidationMonitor</code>并设置使用<code>every_n_steps</code>进行求值的频率来实现此目的。<code>every_n_steps</code>的默认值为<code>100</code>;这里，设置<code>every_n_steps</code>为<code>50</code>，以评估后每50步的模型训练：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>)</div></pre></td></tr></table></figure>
<p>将此代码放置在实例化<code>classifier</code>的行之前。</p>
<p><code>ValidationMonitor</code>依赖于保存的检查点来执行评估操作，因此您需要通过修改分类器的实例化，来添加包含<code>save_checkpoints_secs</code>的来指定在训练运行期间每个checkpoint之间消耗了多少秒的<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig" target="_blank" rel="external"><code>tf.contrib.learn.RunConfig</code></a>。由于鸢尾花数据集非常小，因此可以快速进行训练，将<code>save_checkpoints_secs</code>设置为1（每秒保存一个检查点）以确保有足够数量的检查点：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">classifier = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.DNNClassifier</span>(</div><div class="line">    feature_columns=feature_columns,</div><div class="line">    hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">    n_classes=<span class="number">3</span>,</div><div class="line">    model_dir=<span class="string">"/tmp/iris_model"</span>,</div><div class="line">    config=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.RunConfig</span>(save_checkpoints_secs=<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>注意：<code>model_dir</code>参数为要存储的模型数据指定显式目录（<code>/tmp/iris_model</code>）;此目录路径将比后面自动生成的路径更容易引用。每次运行代码时，在<code>/tmp/iris_model</code>目录下的任何的数据都会被加载，并且模型训练将会在上次停止的位置继续进行（例如，连续运行两次2000步<code>fit</code>操作的脚本将在训练期间执行4000步操作）。如果想要从头开始模型训练，那么需要在执行训练前删除<code>/tmp/iris_model</code>目录。</p>
<p>最后，为了附加您的<code>validation_monitor</code>，更新<code>fit</code>调用，来包含一个包含在模型训练期间运行的所有监视器的列表的监视器参数：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">x=training_set.data,</span></div><div class="line">               <span class="attr">y=training_set.target,</span></div><div class="line">               <span class="attr">steps=2000,</span></div><div class="line">               <span class="attr">monitors=[validation_monitor])</span></div></pre></td></tr></table></figure>
<p>现在，当您重新运行代码时，您应该会在日志输出中看到验证指标，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">INFO:tensorflow:Validation (step <span class="number">50</span>): <span class="attr">loss</span> = <span class="number">1.71139</span>, <span class="attr">global_step</span> = <span class="number">0</span>, <span class="attr">accuracy</span> = <span class="number">0.266667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">300</span>): <span class="attr">loss</span> = <span class="number">0.0714158</span>, <span class="attr">global_step</span> = <span class="number">268</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1750</span>): <span class="attr">loss</span> = <span class="number">0.0574449</span>, <span class="attr">global_step</span> = <span class="number">1729</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div></pre></td></tr></table></figure>
<h3 id="使用MetricSpec自定义评估指标">使用MetricSpec自定义评估指标</h3><p>默认情况下，如果未指定评估指标，<code>ValidationMonitor</code>将同时记录loss和accuracy精确度，但您可以自定义将每隔50个步骤运行的指标列表。要指定要在每个评估传递中运行的确切指标，您可以向<code>ValidationMonitor</code>构造函数添加一个<code>metrics</code>参数。<code>metrics</code>接受一个key/value的字典，其中字典的每个键是您要为该指标记录的名称，对应的值是<a href="https://www.tensorflow.org/code/tensorflow/contrib/learn/python/learn/metric_spec.py" target="_blank" rel="external"><code>MetricSpec</code></a>对象。</p>
<p><code>MetricSpec</code>构造函数接受四个参数：</p>
<ul>
<li><p><code>metric_fn</code> 计算和返回指标值的函数。这可以是<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics" target="_blank" rel="external">tf.contrib.metrics</a>模块中可用的预定义函数，例如<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_precision" target="_blank" rel="external">tf.contrib.metrics.streaming_precision</a>或<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_recall" target="_blank" rel="external">tf.contrib.metrics.streaming_recall</a>。或者，您可以定义自己的自定义指标函数，必须将<code>predictions</code>和<code>labels</code>tensor作为参数(还可以可选地提供<code>weights</code>参数)。函数必须以以下两种格式之一返回度量的值：</p>
<ul>
<li>单个的tensor </li>
<li>一对操作(<code>value_op</code>, <code>update_op</code>)，其中<code>value_op</code>返回度量值，<code>update_op</code>执行相应的操作以更新内部模型状态。</li>
</ul>
</li>
<li><p><code>prediction_key</code> 包含模型返回的预测的tensor的key。如果模型返回单个tensor或带有单个条目的字典，则可以省略此参数。对于<code>DNNClassifier</code>模型，类别预测将在带有关键字<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/PredictionKey#CLASSES" target="_blank" rel="external"><code>tf.contrib.learn.PredictionKey.CLASSES</code></a>的tensor中返回。</p>
</li>
<li><code>label_key</code> tensor的键包含模型返回的标签，由模型的<a href="https://www.tensorflow.org/get_started/input_fn" target="_blank" rel="external"><code>input_fn</code></a>指定。与<code>prediction_key</code>一样，如果<code>input_fn</code>返回单个tensor或具有单个条目的字典，则可以省略此参数。在本教程的鸢尾花样本中，<code>DNNClassifier</code>没有<code>input_fn</code>（<code>x</code>，<code>y</code>数据直接传递给<code>fit</code>），因此没有必要提供<code>label_key</code>。</li>
<li><code>weights_key</code> 可选参数。tensor的键（由<a href="https://www.tensorflow.org/get_started/input_fn" target="_blank" rel="external"><code>input_fn</code></a>返回），包含<code>metric_fn</code>的权重输入。</li>
</ul>
<p>以下代码创建了一个<code>validation_metrics</code>字典，它定义了在模型评估期间要记录的三个指标：</p>
<ul>
<li><code>&quot;accuracy&quot;(准确性)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_accuracy" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_accuracy</code></a>作为<code>metric_fn</code>。</li>
<li><code>&quot;precision&quot;(精确)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_precision" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_precision</code></a>作为<code>metric_fn</code>。</li>
<li><code>&quot;recall&quot;(召回)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_recall" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_recall</code></a>作为<code>metric_fn</code>。</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">validation_metrics = &#123;</div><div class="line">    <span class="string">"accuracy"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_accuracy</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES),</div><div class="line">    <span class="string">"precision"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_precision</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES),</div><div class="line">    <span class="string">"recall"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_recall</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在<code>ValidationMonitor</code>构造函数之前添加上面的代码。然后按如下所示修改<code>ValidationMonitor</code>构造函数，以添加度量参数以记录<code>validation_metrics</code>中指定的accuracy，precision和recall指标（loss是始终被记录的，不需要显示的设定）：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>,</div><div class="line">    metrics=validation_metrics)</div></pre></td></tr></table></figure>
<p>重新运行代码，您应该会在日志输出中看到precision和recall，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">INFO:tensorflow:Validation (step <span class="number">50</span>): <span class="attr">recall</span> = <span class="number">0.0</span>, <span class="attr">loss</span> = <span class="number">1.20626</span>, <span class="attr">global_step</span> = <span class="number">1</span>, <span class="attr">precision</span> = <span class="number">0.0</span>, <span class="attr">accuracy</span> = <span class="number">0.266667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">600</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.0530696</span>, <span class="attr">global_step</span> = <span class="number">571</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1500</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.0617403</span>, <span class="attr">global_step</span> = <span class="number">1452</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div></pre></td></tr></table></figure>
<h3 id="通过ValidationMonitor来提前停止">通过ValidationMonitor来提前停止</h3><p>注意，在上述日志输出中，通过600步训练，模型已经实现了1.0的精确度和召回率。这体现出了一个问题，即模型训练是否可以从<a href="https://en.wikipedia.org/wiki/Early_stopping" target="_blank" rel="external">提前停止</a>中受益。</p>
<p>除了记录eval指标外，<code>ValidationMonitor</code>还可以通过三个参数轻松实现提前停止：</p>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>early_stopping_metric</code></td>
<td style="text-align:left">在<code>early_stopping_rounds</code>和<code>early_stopping_metric_minimize</code>中指定的条件下触发提前停止的指标（例如，loss或accuracy）。默认为“loss”。</td>
</tr>
<tr>
<td style="text-align:left"><code>early_stopping_metric_minimize</code></td>
<td style="text-align:left">如果期望的模型行为是最小化<code>early_stopping_metric</code>的值，则为<code>True</code>;如果期望的模型行为是最大化<code>early_stopping_metric</code>的值，则为<code>False</code>。默认值是<code>True</code></td>
</tr>
<tr>
<td style="text-align:left"><code>early_stopping_rounds</code></td>
<td style="text-align:left">设置如果<code>early_stopping_metric</code>不减小（如果<code>early_stopping_metric_minimize</code>为<code>True</code>）或增加（如果<code>early_stopping_metric_minimize</code>为<code>False</code>）的步骤数，训练将会停止。默认值为<code>None</code>，这意味着永远不会发生提前停止。</td>
</tr>
</tbody>
</table>
<p>对<code>ValidationMonitor</code>的构造函数进行以下修改，其指定如果在200个步骤（<code>early_stopping_rounds = 200</code>）的时段内loss（<code>early_stopping_metric =“loss”</code>）不减小（<code>early_stopping_metric_minimize = True</code>），模型训练将在该点立即停止，并且不会完成<code>fit</code>中指定的2000步训练：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>,</div><div class="line">    metrics=validation_metrics,</div><div class="line">    early_stopping_metric=<span class="string">"loss"</span>,</div><div class="line">    early_stopping_metric_minimize=True,</div><div class="line">    early_stopping_rounds=<span class="number">200</span>)</div></pre></td></tr></table></figure>
<p>重新运行代码以查看模型训练是否提前停止：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1150</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.056436</span>, <span class="attr">global_step</span> = <span class="number">1119</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">INFO:tensorflow:Stopping. Best step: <span class="number">800</span> <span class="keyword">with</span> <span class="attr">loss</span> = <span class="number">0.048313818872</span>.</div></pre></td></tr></table></figure>
<p>实际上，这里的训练在第1150步时停止，这说明对于过去的200步，损失没有减少，并且总体上，第800步针对测试数据集产生最小损失值。这表明通过减少步数来额外校准超参数可以进一步改善模型。</p>
<h2 id="使用TensorBoard可视化日志数据">使用TensorBoard可视化日志数据</h2><p>通过<code>ValidationMonitor</code>生成的日志读取提供了大量关于模型在训练期间的性能的原始数据，这也对数据可视化以进一步了解趋势是有帮助的 - 例如，精确度是如何随着步数变化而变化的。您可以使用TensorBoard（与TensorFlow一起打包的单独程序）通过将<code>logdir</code>命令行参数设置为保存模型训练数据的目录（此处为<code>/tmp/iris_model</code>）来绘制这样的图。在命令行上运行以下命令：</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ tensorboard <span class="comment">--logdir=/tmp/iris_model/</span></div><div class="line">Starting TensorBoard <span class="number">39</span> <span class="keyword">on</span> port <span class="number">6006</span></div></pre></td></tr></table></figure>
<p>然后在你的浏览器中打开<code>http://0.0.0.0:&lt;port_number&gt;</code>，<code>&lt;port_number&gt;</code>是在命令行输出中指定的端口（此处为<code>6006</code>）。</p>
<p>如果单击accuracy(准确度)字段，您将看到类似以下的图像，其中显示了针对步数的精确度：</p>
<p><img src="/img/17_03_07/031.png" alt=""></p>
<p>有关使用TensorBoard的更多信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard:可视化学习</a>和<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-图的可视化/">TensorBoard:图的可视化</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:图的可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T22:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>TensorFlow计算图是强大而复杂的。图形可视化可以帮助您理解和调试它们。这里有一个可视化工作的例子。</p>
<p><img src="/img/17_03_07/007.gif" alt=""></p>
<p><em>TensorFlow图的可视化。</em></p>
<p>如有想查看你的图，你需要运行TensorBoard并将其指向你的作业的日志目录，单击顶部窗格上的图形选项卡，然后使用左上角的菜单选择适当的运行。有关如何运行TensorBoard并确保您记录所有必要信息的深入信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard：可视化学习</a>。</p>
<h2 id="名称作用域和节点">名称作用域和节点</h2><p>典型的TensorFlow图可以有成千上万的节点 - 这个展示量太大了，以至于即使使用标准图工具来布局也太大了。为了简化显示，我们通过变量名指定其对应的作用域，通过使用这些信息来定义图中节点图层的可视化。默认情况下，只显示此层次结构的顶部部分。下面是一个使用<a href="https://www.tensorflow.org/api_docs/python/tf/name_scope" target="_blank" rel="external"><code>tf.name_scope</code></a>在隐藏名称范围下定义三个操作的示例：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'hidden'</span>) <span class="keyword">as</span> scope:</div><div class="line">  <span class="keyword">a</span> = <span class="keyword">tf</span>.constant(<span class="number">5</span>, name=<span class="string">'alpha'</span>)</div><div class="line">  W = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.random_uniform([<span class="number">1</span>, <span class="number">2</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>), name=<span class="string">'weights'</span>)</div><div class="line">  <span class="keyword">b</span> = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.zeros([<span class="number">1</span>]), name=<span class="string">'biases'</span>)</div></pre></td></tr></table></figure>
<p>这将产生以下三个操作名称：</p>
<ul>
<li><code>hidden/alpha</code></li>
<li><code>hidden/weights</code></li>
<li><code>hidden/biases</code></li>
</ul>
<p>默认情况下，可视化将这三个操作压缩到标记为<code>hidden</code>的节点中。额外的细节不会丢失。您可以双击或单击右上角的橙色<code>+</code>号来展开节点，然后您将看到三个子节点的<code>alpha</code>，<code>weights</code>和<code>biases</code>。</p>
<p>这是一个在初始化和展开状态更复杂的真实例子：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/008.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/009.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">顶层名称作用域<strong>pool_1</strong>的初始化视图。单击右上角的橙色<code>+</code>按钮或双击节点本身将会展开它。</td>
<td style="text-align:left"><strong>pool_1</strong>名称作用域的展开视图。单击右上角的橙色按钮或双击节点本身将折叠名称作用域。</td>
</tr>
</tbody>
</table>
<p>按名称范围对节点分组对于创建清晰的图表至关重要。如果您正在构建模型，名称作用域可以控制生成的可视化。<strong>你的名字的作用域越好，可视化效果越好。</strong></p>
<p>上图说明了可视化的第二个方面。TensorFlow图有两种连接：数据依赖和控制依赖。数据依赖显示了两个操作之间的tensor流，并且示为实箭头，而控制依赖使用虚线。在扩展视图（上图右侧）中，所有连接都是数据依赖关系，但连接<code>CheckNumerics</code>和<code>control_dependency</code>的虚线除外。</p>
<p>还有第二种简化布局的小技巧。大多数TensorFlow图都存在几个与其他节点有很多连接的节点。例如，许多节点可能对初始化步骤具有控制依赖性。绘制<code>init</code>节点以及其依赖项之间的所有边将创建一个非常混乱的视图。</p>
<p>为了减少杂乱程度，可视化将所有高度节点分离到右侧的辅助区域，并且不绘制代表它们边缘的线。相对于用线来表示边缘来讲，这里我们绘制小节点图标以指示连接关系。分离出辅助节点通常不会移除关键信息，因为这些节点通常与记录方法相关。有关如何在主图和辅助区域之间移动节点，请参阅<a href="#交互">交互</a>部分。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/010.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/011.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点<strong>conv_1</strong>已被连接到<strong>save</strong>。注意它右边的小<strong>save</strong>节点图标。</td>
<td style="text-align:left"><strong>save</strong>有高度，并且将作为辅助节点出现。与<strong>conv_1</strong>的连接在其左侧显示为节点图标。为了进一步减少杂乱程度，由于<strong>save</strong>有很多连接，我们显示到第5个，其他缩写为<strong>… 12 more</strong>。</td>
</tr>
</tbody>
</table>
<p>最后一个结构简化是series collapsing(系列折叠)。有顺序的图案 - 也就是说，其名称与末尾的数字不同并且具有相同构结构的节点被折叠为单个节点堆叠，如下所示。对于具有长序列的网络，这极大地简化了视图的显示。与分层节点一样，双击也可以展开。有关如何为特定节点集禁用/启用系列折叠，请参阅<a href="#交互">交互</a>。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/012.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/013.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点序列的折叠视图。</td>
<td style="text-align:left">双击后的一个小块的展开视图。</td>
</tr>
</tbody>
</table>
<p>最后，作为可读性的最后一个辅助部分，可视化对常量和摘要节点使用一些特定的图标来。下面是一个节点符号对照表：</p>
<table>
<thead>
<tr>
<th style="text-align:left">符号</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/014.png" alt=""></td>
<td style="text-align:left">高级节点，代表名称作用域。双击展开高级节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/015.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们彼此没有连接</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/016.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们是彼此连接的</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/017.png" alt=""></td>
<td style="text-align:left">单个操作节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/018.png" alt=""></td>
<td style="text-align:left">常数</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/019.png" alt=""></td>
<td style="text-align:left">摘要节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/020.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的数据流。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/021.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的控制依赖性。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/022.png" alt=""></td>
<td style="text-align:left">表示输出操作节点可以变为输入张量的参考边。</td>
</tr>
</tbody>
</table>
<h2 id="交互">交互</h2><p>通过平移和缩放导航图。点击并拖动即可平移，并使用滚动手势进行缩放。双击一个节点，或单击其<code>+</code>按钮，可以展开一个表示一组操作的名称作用域。为了在缩放和平移时轻松跟踪当前视点，右下角有一个小地图。</p>
<p>要关闭打开的节点，请再次双击它，或单击它的 <code>-</code> 按钮。您也可以单击来选择某个节点。它将变成更暗的颜色，并且它的详细信息和它连接的节点将出现在可视化界面的右上角的信息卡中。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/023.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/024.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">显示<strong>conv2</strong>名称作用域的详细信息的信息卡。输入和输出从名称作用域内的操作节点的输入和输出组合。对于名称作用域，不显示属性。</td>
<td style="text-align:left">显示<code>DecodeRaw</code>操作节点的详细信息的信息卡。除了输入和输出之外，它还显示了设备和与当前操作相关的属性。</td>
</tr>
</tbody>
</table>
<p>TensorBoard提供了几种方法来更改图形的视觉布局。这些方法不改变图的计算语义，但它可以为网络的结构带来一些清晰度。通过右键单击节点或按下该节点信息卡底部的按钮，可以对其布局进行以下更改：</p>
<ul>
<li>节点可以在主图和辅助区域之间移动。</li>
<li>一系列节点可以取消分组，以便系列中的节点不会显示在一起。未分组的系列同样可以重新分组。</li>
</ul>
<p>选择也有助于理解高度节点。选择任何高级节点，并选择其他连接的相应节点图标。这使得某些操作变得很容易，例如，看到哪些节点被保存，哪些没有被保存。</p>
<p>单击信息卡中的节点名称将选择它。如果需要，视点将自动平移，以便节点可见。</p>
<p>最后，您可以使用图例上方的颜色菜单为图形选择两种颜色方案。默认结构视图显示结构：当两个高级节点具有相同的结构时，它们以彩虹的相同颜色显示。唯一结构化的节点是灰色的。还有一个显示了运行不同操作的设备第二个视图。名称作用域的颜色与其内部操作的设备分数成比例。</p>
<p>下面的图片给出了一幅实际场景中的插图。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/025.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/026.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">结构视图：灰色节点具有独特的结构。橙色<strong>conv1</strong>和<strong>conv2</strong>节点具有相同的结构，并且类似地用于具有其它颜色的节点。</td>
<td style="text-align:left">设备视图：名称范围与其中的操作节点的设备分数成比例地着色。这里，紫色表示GPU，绿色表示CPU。</td>
</tr>
</tbody>
</table>
<h2 id="Tensor形状信息">Tensor形状信息</h2><p>当序列化<code>GraphDef</code>引入tensor形状时，图形可视化器标记具有tensor维度的边缘，并且边缘厚度反映总张量大小。在<code>GraphDef</code>中引入tensor形状，将序列化图形时的实际图形对象（如<code>sess.graph</code>中所示）传递给<code>SummaryWriter</code>。下图显示了带有张量形状信息的CIFAR-10模型：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/027.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CIFAR-10模型与张量形状信息。</td>
</tr>
</tbody>
</table>
<h2 id="运行时统计">运行时统计</h2><p>通常，收集运行的运行时元数据是有用的，例如节点的总内存使用，总计算时间和tensor形状。下面的代码示例是来自<a href="/2017/02/22/【Tensorflow%20r1.0%20文档翻译】机器学习的HelloWorld%20--%20MNIST手写数字识别/">简单MNIST教程</a>中的经过修改的训练和测试部分的代码片段，其中我们记录了摘要和运行时统计信息。有关如何记录摘要的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">摘要教程</a>。全部源代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:  <span class="comment"># Record execution stats</span></div><div class="line">      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)</div><div class="line">      run_metadata = tf.RunMetadata()</div><div class="line">      summary, _ = sess.run([merged, train_step],</div><div class="line">                            feed_dict=feed_dict(<span class="keyword">True</span>),</div><div class="line">                            options=run_options,</div><div class="line">                            run_metadata=run_metadata)</div><div class="line">      train_writer.add_run_metadata(run_metadata, <span class="string">'step%d'</span> % i)</div><div class="line">      train_writer.add_summary(summary, i)</div><div class="line">      print(<span class="string">'Adding run metadata for'</span>, i)</div><div class="line">    <span class="keyword">else</span>:  <span class="comment"># Record a summary</span></div><div class="line">      summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">      train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>此代码将从步骤99开始每隔100步发出运行时统计信息。</p>
<p>当您启动tensorboard并转到图表选项卡，您现在将看到“Session runs”下的选项对应于添加运行元数据的步骤。选择其中一个运行将显示该步骤的网络快照，淡出未使用的节点。在左侧的控件中，您可以按总内存或总计算时间对节点进行着色。此外，单击节点将显示确切的总内存，计算时间和张量输出大小。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/028.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/029.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/030.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:嵌入可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T21:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>嵌入在机器学习中无处不在，出现在推荐系统，NLP和许多其他应用程序中。事实上，在TensorFlow的上下文中，将tensor（或tensor切片）视为空间中的点是自然的，因此几乎任何TensorFlow系统将自然地产生各种嵌入。</p>
<p>要了解有关嵌入和如何训练它们的更多信息，请参阅<a href="https://www.tensorflow.org/tutorials/word2vec" target="_blank" rel="external">单词向量表示教程</a>。如果你对图像的嵌入感兴趣，请查看<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>，了解MNIST图像的有趣的可视化。另一方面，如果你对单词嵌入感兴趣，那么<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>会给你一个很好的介绍。</p>
<p>TensorBoard有一个内置的可视化工具，称为嵌入投影仪，用于交互式可视化和分析高维数据，例如嵌入。这意味着对开发人员和研究人员同样有用。它从保存tensorflow变量的检查点文件读取。虽然它对嵌入最有用，它将加载任何2D tensor，可能包括您的训练权重。</p>
<video height="363" width="710" id="video" controls preload="none" poster="/img/17_03_07/002.png"><br>    <source id="mp4" src="/img/17_03_07/001.mp4" type="video/mp4"><br>    <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<p>默认情况下，嵌入投影仪执行三维<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="external">主成分分析</a>，这意味着它接受你的高维数据，并试图找到一个结构保留投影到三维空间。基本上，它通过旋转你的数据，使前三个维度显示尽可能多的数据方差。<a href="http://setosa.io/ev/principal-component-analysis/" target="_blank" rel="external">这里</a>有一个很好的视觉解释。另一个非常有用的投影是<a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" target="_blank" rel="external">t-SNE</a>。我们稍后在教程中讨论更多的t-SNE。</p>
<p>如果您使用嵌入，您可能需要将标签/图像附加到数据点，以告诉可视化器每个数据点对应的标签/图像。您可以通过生成元数据文件，使用我们的Python API将其附加到tensor，或将其上传到已经运行的TensorBoard来完成。</p>
<h2 id="构建">构建</h2><p>有关如何运行TensorBoard并确保您记录所有必要的信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard-可视化学习/</a>。</p>
<p>要可视化您的嵌入，您需要做3件事：</p>
<p>1）设置一个二维tensor变量来保存你的嵌入。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">embedding_var</span> = tf.Variable(....)</div></pre></td></tr></table></figure>
<p>2）定期将您的嵌入保存在<code>LOG_DIR</code>中。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</div><div class="line">saver.save(session, os<span class="selector-class">.path</span><span class="selector-class">.join</span>(LOG_DIR, <span class="string">"model.ckpt"</span>), step)</div></pre></td></tr></table></figure>
<p>以下步骤不是必要的，但是如果您有与嵌入相关联的任何元数据（标签，图像），则需要将它们链接到tensor上，以便TensorBoard知道它。</p>
<p>3）将元数据与嵌入关联。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">from tensorflow.contrib.tensorboard.plugins <span class="built_in">import</span> projector</div><div class="line"><span class="comment"># Use the same LOG_DIR where you stored your checkpoint.</span></div><div class="line"><span class="attr">summary_writer</span> = tf.train.SummaryWriter(LOG_DIR)</div><div class="line"></div><div class="line"><span class="comment"># Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto</span></div><div class="line"><span class="attr">config</span> = projector.ProjectorConfig()</div><div class="line"></div><div class="line"><span class="comment"># You can add multiple embeddings. Here we add only one.</span></div><div class="line"><span class="attr">embedding</span> = config.embeddings.add()</div><div class="line">embedding.<span class="attr">tensor_name</span> = embedding_var.name</div><div class="line"><span class="comment"># Link this tensor to its metadata file (e.g. labels).</span></div><div class="line">embedding.<span class="attr">metadata_path</span> = os.path.join(LOG_DIR, 'metadata.tsv')</div><div class="line"></div><div class="line"><span class="comment"># Saves a configuration file that TensorBoard will read during startup.</span></div><div class="line">projector.visualize_embeddings(summary_writer, config)</div></pre></td></tr></table></figure>
<p>运行模型并训练嵌入后，运行TensorBoard并将其指向job的<code>LOG_DIR</code>。</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard <span class="comment">--logdir=LOG_DIR</span></div></pre></td></tr></table></figure>
<p>然后单击顶部窗格上的<em>Embeddings</em>选项卡，并选择适当的运行（如果有多个运行）。</p>
<h2 id="元数据（可选）">元数据（可选）</h2><p>通常嵌入具有与其相关联的元数据（例如，标签，图像）。元数据应存储在模型检查点之外的单独文件中，因为元数据不是模型的可训练参数。格式应为TSV文件，第一行包含列标题，后续行包含元数据值。这里有一个例子：</p>
<figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Name<span class="symbol">\t</span>Type<span class="symbol">\n</span></div><div class="line">Caterpie<span class="symbol">\t</span>Bug<span class="symbol">\n</span></div><div class="line">Charmeleon<span class="symbol">\t</span>Fire<span class="symbol">\n</span></div><div class="line">…</div></pre></td></tr></table></figure>
<p>没有与主数据文件共享的显式键;相反，假设元数据文件中的顺序与嵌入tensor中的顺序匹配。换句话说，第一行是头信息，元数据文件中的第(i+1)行对应于存储在检查点中的嵌入tensor的第i行。</p>
<blockquote>
<p><strong>注意：</strong>如果TSV元数据文件只有一个列，那么我们不需要一个标题行，并且假设每一行都是嵌入的标签。我们包含此异常，因为它匹配常用的“词汇文件”格式。</p>
</blockquote>
<h3 id="图">图</h3><p>如果您有与嵌入关联的图像，则需要生成包含每个数据点的小缩略图的单个图像。这被称为<a href="https://www.google.com/webhp#q=what+is+a+sprite+image" target="_blank" rel="external">精灵图像（sprite image）</a>。精灵应具有相同数目的行和列，缩略图按行首先顺序存储：第一个数据点放置在左上角，最后一个数据点在右下角：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">7</td>
</tr>
</tbody>
</table>
<p>请注意，在上面的示例中，最后一行不必填写。对于精灵的一个具体示例，请看这个<a href="https://www.tensorflow.org/images/mnist_10k_sprite.png" target="_blank" rel="external">精灵图像</a>的10,000 MNIST数字（100x100）。</p>
<blockquote>
<p><strong>注意：</strong>我们目前支持高达8192px X 8192px.的精灵。</p>
</blockquote>
<p>构造精灵后，您需要告诉嵌入投影机在哪里可以找到它：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">embedding.sprite.image_path = PATH_TO_SPRITE_IMAGE</div><div class="line"><span class="comment"># Specify the width and height of a single thumbnail.</span></div><div class="line">embedding.sprite.single_image_dim.<span class="keyword">extend</span>([w, h])</div></pre></td></tr></table></figure>
<h2 id="相互作用">相互作用</h2><p>嵌入式投影机有三个面板</p>
<ul>
<li>1.位于左上方的数据面板，你可以选择你指定的运行、嵌入tensor和数据列来着色和标记点。</li>
<li>2.位于左下方的预测面板，用于选择投影类型（例如PCA，t-SNE）。</li>
<li>3.位于右侧的监视面板，在那里你可以搜索特定的点，并查看最近的邻居列表。</li>
</ul>
<h3 id="预测">预测</h3><p>嵌入投影仪具有减少数据集的维度的三种方法：两个线性的和一个非线性的。每个方法可用于创建二维或三维视图。</p>
<p><strong>主成分分析（Principal Component Analysis）</strong>减少维度的主要技术是主成分分析（PCA）。嵌入投影仪计算前10个主要元素。该菜单允许您将这些元素投影到两个或三个任意组合。PCA是一个线性投影，通常用于检查全局几何。</p>
<p><strong>t-SNE</strong>一种流行的非线性降维技术是T-SNE。嵌入投影机提供二维和三维t-SNE视图。布局是在客户端对算法的每一步执行动画。因为t-SNE经常保留一些局部结构，所以它对于探索局部邻域和找到簇是有用的。虽然对于可视化高维数据非常有用，但t-SNE图有时可能会产生迷惑或者误导的作用。想要了解如何有效地使用t-SNE，可以看看这篇<a href="http://distill.pub/2016/misread-tsne/" target="_blank" rel="external">很棒的文章</a>。</p>
<p><strong>自定义（Custom）</strong>您还可以基于文本搜索来构造专门的线性投影，以在空间中找到有意义的方向。要定义投影轴，请输入两个搜索字符串或正则表达式。程序计算出其标签与这些搜索匹配的点集合的质心，并使用质心之间的差向量作为投影轴。</p>
<h3 id="导航">导航</h3><p>要探索数据集，您可以在2D或3D模式中浏览视图，使用自然的点击和拖动手势进行缩放，旋转和平移。单击一个点会使右窗格显示最近邻居的显式文本列表，以及到当前点的距离。最近邻点本身在投影上突出显示。</p>
<p>放大集群会提供一些信息，但有时更有帮助的是将视图限制为点的子集，并仅对这些点执行投影。为此，您可以通过多种方式选择点：</p>
<ul>
<li>1.点击一个点后，也选择其最近的邻居。</li>
<li>2.搜索后，选择与查询匹配的点。</li>
<li>3.启用选择，单击点并拖动定义选择球体。</li>
</ul>
<p>选择一组点后，您可以使用右侧“检查器”窗格中的“隔离点”按钮单独隔离这些点以进行进一步分析。</p>
<p><img src="/img/17_03_07/003.png" alt=""></p>
<p><em>在词嵌入数据集中选择“重要”的最近邻。</em></p>
<p>过滤与自定义投影的组合的功能是非常强大的。下面，我们过滤了“politics”的100个最接近的邻居，并将它们投影到“best” - “worst”向量作为x轴。 y轴是随机的。</p>
<p>你可以看到，在右边我们有“ideas”，“science”，“perspective”，“journalism”，而在左边我们有“crisis”，“violence”和“conflict”。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/006.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/004.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">自定义投影控件。</td>
<td style="text-align:left">将“politics”的邻居定义为“best” - “worst”向量。</td>
</tr>
</tbody>
</table>
<h3 id="共同特征">共同特征</h3><p>如果你想要分享您的发现，您可以使用右下角的书签面板，并将当前状态（包括任何投影的计算坐标）保存为小文件。投影仪可以同时打开并展示一个或多个这些小文件。这样一来，其他用户就可以浏览这些书签了。</p>
<p><img src="/img/17_03_07/005.png" alt=""></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:可视化学习
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T18:26:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>你使用TensorFlow来进行的某些大规模深度神经网络，可能是很复杂，并且令人困惑的。为了使它更容易被理解、调试、并且优化TensorFlow程序，我们引入了一套可视化工具，它就是TensorBoard。你可以使用TensorBoard来可视化你的TensorFlow计算图，绘制关于图形执行的定量指标，以及显示其他数据的图像。</p>
<p>当TensorBoard完全配置好时，它看起来是这样的：</p>
<p><img src="/img/17_03_07/001.png" alt=""></p>
<p>本教程旨在帮助您学习TensorBoard的基本使用方式。当然，还有其他介绍资源！<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>有大量关于TensorBoard的信息，包括提示和技巧和调试信息。</p>
<h2 id="序列化数据">序列化数据</h2><p>TensorBoard通过读取TensorFlow事件文件进行操作，这些文件包含运行TensorFlow时可以生成的摘要数据。下面是TensorBoard中摘要数据的一般生命周期。</p>
<p>首先，创建要从其中收集摘要数据的TensorFlow图，并决定要使用<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">summary operations</a>注释哪些节点。</p>
<p>例如，假设你正在训练一个卷积神经网络来识别MNIST数字。你想记录学习速率随时间的变化，以及目标函数如何变化。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar" target="_blank" rel="external"><code>tf.summary.scalar</code></a>操作分别附加到输出学习速率和损失的节点来收集这些信息。然后，给每个<code>scalar_summary</code>赋予有意义的<code>tag</code>，如<code>learning rate</code>或<code>loss function</code>。</p>
<p>也许你也想要可视化来自特定层的激活的分布，或梯度或权重的分布。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/histogram" target="_blank" rel="external"><code>tf.summary.histogram</code></a>操作附加到梯度输出和分别保存您的权重的变量来收集此数据。</p>
<p>有关所有可用摘要操作的详细信息，请查看<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">摘要操作的文档</a>。</p>
<p>在您运行TensorFlow中的操作之前，它们都不会被运行，依赖于它们的输出的操作也不会被执行。我们刚刚创建的汇总节点是图形的外设：您当前运行的任何操作都不依赖于它们。因此，要生成摘要，我们需要运行所有这些摘要节点。手动管理它们将是一项乏味的工作，因此我们使用<a href="https://www.tensorflow.org/api_docs/python/tf/summary/merge_all" target="_blank" rel="external"><code>tf.summary.merge_all</code></a>将它们组合到一个单独的操作中，生成所有的摘要数据。</p>
<p>然后，您可以运行合并的摘要操作，这将生成一个包含有所有给定步骤的摘要数据的序列化的<code>Summary</code>（摘要）protobuf对象。最后，要将此摘要数据写入磁盘，将摘要protobuf传递给<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>。</p>
<p><code>FileWriter</code>在它的构造函数中接受一个logdir - 这个logdir是非常重要的，它是所有事件将被写出的目标目录。此外，<code>FileWriter</code>可以选择在其构造函数中接受一个<code>Graph</code>。如果它接收到一个<code>Graph</code>对象，那么TensorBoard将与Tensor形状信息一起显示到界面上。这将使您更好地了解通过图形流动的信息：请参阅<a href="https://www.tensorflow.org/get_started/graph_viz#tensor_shape_information" target="_blank" rel="external">Tensor shape信息</a>。</p>
<p>现在，你已经修改好了你的图，并且有了一个<code>FileWriter</code>，并且做好了开始运行网络的准备!如果需要，您可以每一步运行一次摘要合并，并记录大量的训练数据。这可能会产生很多你不需要的数据。所以换一种方式，请考虑每n个步骤运行一次摘要合并操作。</p>
<p>下面的代码示例是一个<a href="https://www.tensorflow.org/get_started/mnist/beginners" target="_blank" rel="external">简单的MNIST教程</a>的修改，其中我们添加了一些摘要操作，并且每十步运行它们一次。如果你运行这个代码，然后启动<code>tensorboard --logdir=/tmp/mnist_logs</code>，你将能够可视化统计，例如权重或精度在训练期间如何变化。下面是部分代码，全部源码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line">def variable_summaries(var):</div><div class="line">  <span class="string">""</span><span class="string">"Attach a lot of summaries to a Tensor (for TensorBoard visualization)."</span><span class="string">""</span></div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'summaries'</span>):</div><div class="line">    mean = <span class="keyword">tf</span>.reduce_mean(var)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'mean'</span>, mean)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'stddev'</span>):</div><div class="line">      stddev = <span class="keyword">tf</span>.<span class="built_in">sqrt</span>(<span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.square(var - mean)))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'stddev'</span>, stddev)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'max'</span>, <span class="keyword">tf</span>.reduce_max(var))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'min'</span>, <span class="keyword">tf</span>.reduce_min(var))</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'histogram'</span>, var)</div><div class="line"></div><div class="line">def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=<span class="keyword">tf</span>.<span class="keyword">nn</span>.relu):</div><div class="line">  <span class="string">""</span><span class="comment">"Reusable code for making a simple neural net layer.</span></div><div class="line"></div><div class="line">  It does <span class="keyword">a</span> matrix multiply, bias <span class="built_in">add</span>, <span class="built_in">and</span> then uses relu <span class="keyword">to</span> nonlinearize.</div><div class="line">  It also sets <span class="keyword">up</span> name scoping <span class="keyword">so</span> that the resultant graph <span class="keyword">is</span> easy <span class="keyword">to</span> <span class="keyword">read</span>,</div><div class="line">  <span class="built_in">and</span> adds <span class="keyword">a</span> <span class="keyword">number</span> of summary ops.</div><div class="line">  <span class="string">""</span><span class="comment">"</span></div><div class="line">  # Adding <span class="keyword">a</span> name scope ensures logical grouping of the layers in the graph.</div><div class="line">  with <span class="keyword">tf</span>.name_scope(layer_name):</div><div class="line">    # This Variable will hold the state of the weights <span class="keyword">for</span> the layer</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'weights'</span>):</div><div class="line">      weights = weight_variable([input_dim, output_dim])</div><div class="line">      variable_summaries(weights)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'biases'</span>):</div><div class="line">      biases = bias_variable([output_dim])</div><div class="line">      variable_summaries(biases)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'Wx_plus_b'</span>):</div><div class="line">      preactivate = <span class="keyword">tf</span>.matmul(input_tensor, weights) + biases</div><div class="line">      <span class="keyword">tf</span>.summary.histogram(<span class="string">'pre_activations'</span>, preactivate)</div><div class="line">    activations = act(preactivate, name=<span class="string">'activation'</span>)</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'activations'</span>, activations)</div><div class="line">    <span class="keyword">return</span> activations</div><div class="line"></div><div class="line">hidden1 = nn_layer(<span class="keyword">x</span>, <span class="number">784</span>, <span class="number">500</span>, <span class="string">'layer1'</span>)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'dropout'</span>):</div><div class="line">  keep_prob = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.float32)</div><div class="line">  <span class="keyword">tf</span>.summary.scalar(<span class="string">'dropout_keep_probability'</span>, keep_prob)</div><div class="line">  dropped = <span class="keyword">tf</span>.<span class="keyword">nn</span>.dropout(hidden1, keep_prob)</div><div class="line"></div><div class="line"># Do not apply softmax activation yet, see below.</div><div class="line"><span class="keyword">y</span> = nn_layer(dropped, <span class="number">500</span>, <span class="number">10</span>, <span class="string">'layer2'</span>, act=<span class="keyword">tf</span>.identity)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'cross_entropy'</span>):</div><div class="line">  # The raw formulation of cross-entropy,</div><div class="line">  #</div><div class="line">  # <span class="keyword">tf</span>.reduce_mean(-<span class="keyword">tf</span>.reduce_sum(y_ * <span class="keyword">tf</span>.<span class="built_in">log</span>(<span class="keyword">tf</span>.softmax(<span class="keyword">y</span>)),</div><div class="line">  #                               reduction_indices=[<span class="number">1</span>]))</div><div class="line">  #</div><div class="line">  # can <span class="keyword">be</span> numerically unstable.</div><div class="line">  #</div><div class="line">  # So here we use <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits <span class="keyword">on</span> the</div><div class="line">  # raw outputs of the nn_layer above, <span class="built_in">and</span> then average across</div><div class="line">  # the batch.</div><div class="line">  diff = <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits(targets=y_, logits=<span class="keyword">y</span>)</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'total'</span>):</div><div class="line">    cross_entropy = <span class="keyword">tf</span>.reduce_mean(diff)</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'cross_entropy'</span>, cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'train'</span>):</div><div class="line">  train_step = <span class="keyword">tf</span>.train.AdamOptimizer(FLAGS.learning_rate).minimize(</div><div class="line">      cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'correct_prediction'</span>):</div><div class="line">    correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(<span class="keyword">y</span>, <span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_, <span class="number">1</span>))</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">    accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div><div class="line"></div><div class="line"># Merge <span class="keyword">all</span> the summaries <span class="built_in">and</span> <span class="keyword">write</span> them out <span class="keyword">to</span> /tmp/mnist_logs (by default)</div><div class="line">merged = <span class="keyword">tf</span>.summary.merge_all()</div><div class="line">train_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/train'</span>,</div><div class="line">                                      sess.graph)</div><div class="line">test_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/test'</span>)</div><div class="line"><span class="keyword">tf</span>.global_variables_initializer().run()</div></pre></td></tr></table></figure>
<p>在我们初始化<code>FileWriter</code>之后，我们在训练和测试模型时，必须向<code>FileWriter</code>添加摘要。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">    train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>现在，你就可以通过TensorBoard来可视化数据了。</p>
<h2 id="启动TensorBoard">启动TensorBoard</h2><p>要运行TensorBoard，请使用以下命令（或者<code>python -m tensorflow.tensorboard</code>）:</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir=path/<span class="keyword">to</span>/<span class="built_in">log</span>-directory</div></pre></td></tr></table></figure>
<p>其中<code>logdir</code>指向<code>FileWriter</code>将其数据序列化的目录。如果此logdir目录包含包含单独运行的序列化数据的子目录，则TensorBoard将可视化所有这些运行的数据。TensorBoard开始运行之后，就可以打开您的Web浏览器到<code>localhost:6006</code>来查看TensorBoard了。</p>
<p>当你看着TensorBoard，你会看到在右上角的导航选项卡。每个选项卡表示可以可视化的一组序列化数据。</p>
<p>有关如何使用图形选项卡可视化图形的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-图的可视化/">TensorBoard：图形可视化</a>。</p>
<p>有关TensorBoard的更多使用信息，请参阅<a href="https://www.tensorflow.org/code/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="url">
                【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-06T22:24:58+08:00" content="2017-03-06">
            2017-03-06
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>本教程将介绍如何在tf.contrib.learn中创建输入函数。您将对如何构造一个用于预处理并将数据反馈到你的模型的<code>input_fn</code>操作有一个大致的了解。然后，您将实现一个<code>input_fn</code>，它将训练，评估和预测数据提供给神经网络回归，并用于预测房屋数据的中位数值。</p>
<h2 id="使用input_fn的自定义输入管道">使用input_fn的自定义输入管道</h2><p>当通过使用tf.contrib.learn来训练一个神经网络时，可以将您的特征和目标数据直接传递到你的<code>fit</code>(拟合)、<code>evaluate</code>(评估)或<code>predict</code>(预测)操作中。下面是从<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门教程</a>中获取的示例：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">training_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TRAINING, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">test_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TEST, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">...</div><div class="line"></div><div class="line">classifier.fit(x=training_set<span class="selector-class">.data</span>,</div><div class="line">               y=training_set<span class="selector-class">.target</span>,</div><div class="line">               steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>这种数据量不大的情况下，我们即使不处理数据源，也可好获得良好的效果。但是在需要更多特征工程的情况下，<code>tf.contrib.learn</code>支持使用自定义输入函数（<code>input_fn</code>），它可以将预处理和管道数据的逻辑封装到模型中。</p>
<h3 id="input_fn的剖析">input_fn的剖析</h3><p>以下代码说明了输入函数的基本框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_fn</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># Preprocess your data here...</span></div><div class="line"></div><div class="line">    <span class="comment"># ...then return 1) a mapping of feature columns to Tensors with</span></div><div class="line">    <span class="comment"># the corresponding feature data, and 2) a Tensor containing labels</span></div><div class="line">    <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>输入函数的主体包含用于预处理输入数据的特定逻辑，例如<strong>擦除不良样本</strong>或<strong><a href="https://en.wikipedia.org/wiki/Feature_scaling" target="_blank" rel="external">特征缩放</a></strong>。</p>
<p>输入函数必须返回以下两个值，这两个值包含要输入到模型中的最终特征和标签数据（如上面的代码框架中所示）：</p>
<p><code>feature_cols</code></p>
<pre><code>包含将特征列名称映射到包含相应特征数据的<span class="escape">`T</span>ensor<span class="escape">`（</span>或<span class="escape">`S</span>parseTensor<span class="escape">`）</span>的键/值对的字典。
</code></pre><p><code>labels</code></p>
<pre><code>包含您的标签（目标）值的<span class="escape">`T</span>ensor<span class="escape">`：</span>你的模型的值的目的是用于预测。
</code></pre><h3 id="将特征数据转换为Tensor">将特征数据转换为Tensor</h3><p>如果你的特征/标签数据储存在<a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a>数据帧中或<a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a>数组中，那么你需要将其转换为<code>Tensor</code>，然后从您的<code>input_fn</code>中返回它。</p>
<p>对于连续数据，可以使用<code>tf.constant</code>创建和填充<code>Tensor</code>：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_column_data = [<span class="number">1</span>, <span class="number">2.4</span>, <span class="number">0</span>, <span class="number">9.9</span>, <span class="number">3</span>, <span class="number">120</span>]</div><div class="line">feature_tensor = tf.constant(feature_column_data)</div></pre></td></tr></table></figure>
<p>对于<a href="https://en.wikipedia.org/wiki/Sparse_matrix" target="_blank" rel="external">稀疏分类数据</a>（大多数值为0的数据），您应该替换为填充一个<code>SparseTensor</code>，它使用三个参数来实例化：</p>
<p><code>dense_shape</code></p>
<pre><code>tensor的形状。获取一个列表，指示每个维度中元素的数量。例如：`dense_shape=[<span class="number">3</span>,<span class="number">6</span>]`指定了一个二维的<span class="number">3</span>x6的tensor，`dense_shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]`指定了一个三维的<span class="number">2</span>x3x4的tensor，`dense_shape=[<span class="number">9</span>]`指定了一个拥有<span class="number">9</span>个元素的一维tensor。
</code></pre><p><code>indices</code></p>
<pre><code>您的tensor中包含非零元素的索引。值为一个列表，其中每一项本身是包含非零元素的索引的列表。（元素是零索引的 - 即，`[<span class="number">0</span>,<span class="number">0</span>]`是二维张量中第一行的第一列中的元素的索引值）。例如：`indices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]`指定了索引为`[<span class="number">1</span>,<span class="number">3</span>]`和`[<span class="number">2</span>,<span class="number">4</span>]`的元素具有非零值。
</code></pre><p><code>values</code></p>
<pre><code>值为一维tensor。<span class="escape">`v</span>alues<span class="escape">`的</span>项<span class="escape">`i</span><span class="escape">`对</span>应于<span class="escape">`i</span>ndices<span class="escape">`中</span>的项<span class="escape">`i</span><span class="escape">`，</span>并且指定了它的值。例如，给定了<span class="escape">`i</span>ndices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]<span class="escape">`，</span>那么参数<span class="escape">`v</span>alues=[<span class="number">18</span>, <span class="number">3.6</span>]<span class="escape">`就</span>指定了tensor的元素<span class="escape">`[</span><span class="number">1</span>,<span class="number">3</span>]<span class="escape">`的</span>值为<span class="number">18</span>，元素<span class="escape">`[</span><span class="number">2</span>,<span class="number">4</span>]<span class="escape">`的</span>值为<span class="number">3.6</span>。
</code></pre><p>以下代码定义了一个具有3行和5列的二维<code>SparseTensor</code>。具有索引<code>[0,1]</code>的元素的值为6，并且索引为<code>[2,4]</code>的元素值为0.5（所有其他值为0）：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sparse_tensor = tf.SparseTensor(indices=[[<span class="number">0</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">4</span>]],</div><div class="line">                                values=[<span class="number">6</span>, <span class="number">0.5</span>],</div><div class="line">                                dense_shape=[<span class="number">3</span>, <span class="number">5</span>])</div></pre></td></tr></table></figure>
<p>这对应了下面的稠密tensor(dense tensor)：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[[<span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.5</span>]]</div></pre></td></tr></table></figure>
<p>更多关于<code>SparseTensor</code>的内容，请见<a href="https://www.tensorflow.org/api_docs/python/tf/SparseTensor" target="_blank" rel="external"><code>tf.SparseTensor</code></a></p>
<h3 id="将input_fn数据传递给您的模型">将input_fn数据传递给您的模型</h3><p>要将数据馈送到您的模型进行训练，您只需将创建的输入函数作为<code>input_fn</code>参数的值传递到<code>fit</code>运算即可，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn,</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>请注意，<code>input_fn</code>负责将特征和标签数据提供给模型，并在<code>fit</code>(拟合)中替换<code>x</code>和<code>y</code>参数。如果为<code>fit</code>提供了一个不为空的<code>input_fn</code>值与不为<code>None</code>的<code>x</code>或<code>y</code>结合，它将抛出一个<code>ValueError</code>。</p>
<p>还要注意一点，<code>input_fn</code>参数必须接收一个函数对象（例如<code>input_fn = my_input_fn</code>），而不是函数调用的返回值（<code>input_fn = my_input_fn()</code>）。这意味着，如果您尝试在<code>fit</code>的调用中按照下面的方式，将参数传递给输入函数，则会导致TypeError：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn(training_set),</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>但是，如果你想要参数化你的输入函数，有一些其他的方法可以做到。您可以使用不带参数的包装函数作为<code>input_fn</code>，并使用它来调用具有所需参数的输入函数。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_function_training_set</span><span class="params">()</span>:</span></div><div class="line">  <span class="keyword">return</span> my_input_function(training_set)</div><div class="line"></div><div class="line">classifier.fit(input_fn=my_input_fn_training_set, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>或者，你可以使用Python的<a href="https://docs.python.org/2/library/functools.html#functools.partial" target="_blank" rel="external"><code>functools.partial</code></a>方法来构造一个新的所有参数值固定的方法对象：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">classifier.fit(input_fn=functools.partial(my_input_<span class="keyword">function</span>,</div><div class="line">                                          data_<span class="built_in">set</span>=training_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>第三种方式是将<code>input_fn</code>调用包装在<a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" target="_blank" rel="external"><code>lambda</code></a>中，并将其传递给<code>input_fn</code>参数：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: my_input_fn(training_set), steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>构建您的输入管道的一个很大的优势如上所示 – 可以接受数据集的参数 – 是你只需修改数据集的参数，就可以传递相同的<code>input_fn</code>到<code>evaluate</code>和<code>predict</code>操作上。例如：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.evaluate(input_fn=lambda: my_input_fn(<span class="built_in">test</span>_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>这种方法增强了代码的可维护性：不需要针对每种类型的操作捕获单独变量（例如，<code>x_train</code>，<code>x_test</code>，<code>y_train</code>，<code>y_test</code>）中的<code>x</code>和<code>y</code>值。</p>
<h3 id="一个用于波士顿房屋数据的神经网络">一个用于波士顿房屋数据的神经网络</h3><p>在本教程的剩余部分，您将编写一个输入函数，用于预处理从<a href="https://archive.ics.uci.edu/ml/datasets/Housing" target="_blank" rel="external">UCI住宅数据集</a>中提取的一组波士顿房屋数据，并使用它来将数据馈送到神经网络回归器，以预测房屋中值。</p>
<p>您将用于训练神经网络的<a href="https://www.tensorflow.org/get_started/input_fn#setup" target="_blank" rel="external">波士顿CSV数据集</a>包含以下波士顿郊区的<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names" target="_blank" rel="external">特征数据</a>：</p>
<table>
<thead>
<tr>
<th style="text-align:left">特征</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CRIM</td>
<td style="text-align:left">人均犯罪率</td>
</tr>
<tr>
<td style="text-align:left">ZN</td>
<td style="text-align:left">超过25,000+平方呎地段的住宅用地的部分</td>
</tr>
<tr>
<td style="text-align:left">INDUS</td>
<td style="text-align:left">非零售业的土地部分</td>
</tr>
<tr>
<td style="text-align:left">NOX</td>
<td style="text-align:left">一氧化氮浓度 以百万分之一为单位</td>
</tr>
<tr>
<td style="text-align:left">RM</td>
<td style="text-align:left">每个住宅平均房间数</td>
</tr>
<tr>
<td style="text-align:left">AGE</td>
<td style="text-align:left">在1940年之前建造的自用住宅的部分</td>
</tr>
<tr>
<td style="text-align:left">DIS</td>
<td style="text-align:left">到波士顿地区就业中心的距离</td>
</tr>
<tr>
<td style="text-align:left">TAX</td>
<td style="text-align:left">每$10,000的房产税税率</td>
</tr>
<tr>
<td style="text-align:left">PTRATIO</td>
<td style="text-align:left">学生 - 教师比例</td>
</tr>
</tbody>
</table>
<p>你的模型预测的标签是MEDV，自用住宅的价格中值，以千美元计。</p>
<h2 id="构建">构建</h2><p>下载以下数据集：<a href="http://download.tensorflow.org/data/boston_train.csv" target="_blank" rel="external">boston_train.csv</a>, <a href="http://download.tensorflow.org/data/boston_test.csv" target="_blank" rel="external">boston_test.csv</a>, 和 <a href="http://download.tensorflow.org/data/boston_predict.csv" target="_blank" rel="external">boston_predict.csv</a>。</p>
<p>以下部分提供了如何创建输入函数的手把手的步骤，将这些数据集送入神经网络回归，训练和评估模型，并进行房屋价值预测。完整的最终代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/input_fn/boston.py" target="_blank" rel="external">这里</a>。</p>
<h3 id="输入房屋数据">输入房屋数据</h3><p>要开始，请设置导入所需的库（包括<code>pandas</code>和<code>tensorflow</code>），并将<a href="https://www.tensorflow.org/get_started/monitors#enabling_logging_with_tensorflow" target="_blank" rel="external">日志级别设置</a>为<code>INFO</code>以获取更详细的日志输出：</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="title">tf</span>.logging.set_verbosity(tf.logging.<span class="type">INFO</span>)</div></pre></td></tr></table></figure>
<p>在<code>COLUMNS</code>中定义数据集的列名称。要区分特征和标签，还需要定义<code>FEATURES</code>和<code>LABEL</code>。然后将三个CSV（<code>tf.train</code>，<code>tf.test</code>和<code>predict</code>）读入pandas <code>DataFrame</code>s：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="attr">COLUMNS</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>, <span class="string">"age"</span>,</div><div class="line">           <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>, <span class="string">"medv"</span>]</div><div class="line"><span class="attr">FEATURES</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>,</div><div class="line">            <span class="string">"age"</span>, <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>]</div><div class="line"><span class="attr">LABEL</span> = <span class="string">"medv"</span></div><div class="line"></div><div class="line"><span class="attr">training_set</span> = pd.read_csv(<span class="string">"boston_train.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                           <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">test_set</span> = pd.read_csv(<span class="string">"boston_test.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                       <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">prediction_set</span> = pd.read_csv(<span class="string">"boston_predict.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                             <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div></pre></td></tr></table></figure>
<h3 id="定义特征列并创建回归">定义特征列并创建回归</h3><p>接下来，为输入数据创建<code>FeatureColumn</code>list，正式指定要用于训练的特征集。由于房屋数据集中的所有特征都包含连续的值，因此可以使用<code>tf.contrib.layers.real_valued_column()</code>函数创建其<code>FeatureColumn</code>s：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_cols = [tf<span class="selector-class">.contrib</span><span class="selector-class">.layers</span><span class="selector-class">.real_valued_column</span>(k)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</div></pre></td></tr></table></figure>
<p>注意：有关特征列的更深入的内容，请参阅此<a href="https://www.tensorflow.org/tutorials/linear#feature_columns_and_transformations" target="_blank" rel="external">简介</a>，以及说明如何为分类数据定义<code>FeatureColumns</code>的示例，请参阅线<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">性模型教程</a>。</p>
<p>现在，为神经网络回归模型实例化一个<code>DNNRegressor</code>。这里你需要提供两个参数：<code>hidden_units</code>，指定每个隐藏层中的节点数量的超参数(hyperparameter)（这里，有两个隐藏层，每个隐藏层都具有10个节点），以及<code>feature_columns</code>，包含您刚定义的<code>FeatureColumns</code>list：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">regressor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.DNNRegressor</span>(feature_columns=feature_cols,</div><div class="line">                                          hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</div><div class="line">                                          model_dir=<span class="string">"/tmp/boston_model"</span>)</div></pre></td></tr></table></figure>
<h3 id="构建input_fn">构建input_fn</h3><p>要将输入数据传递到<code>regressor</code>，请创建一个输入函数，它将接受一个pandas <code>Dataframe</code>并返回特征列和标签值作为<code>Tensor</code>s：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_set)</span>:</span></div><div class="line">  feature_cols = &#123;k: tf.constant(data_set[k].values)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;</div><div class="line">  labels = tf.constant(data_set[LABEL].values)</div><div class="line">  <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>请注意，输入数据被传递到<code>data_set</code>参数中的<code>input_fn</code>中，这意味着该函数可以处理您导入的任何<code>DataFrames</code>：<code>training_set</code>，<code>test_set</code>和<code>prediction_set</code>。</p>
<h3 id="训练回归">训练回归</h3><p>要训​​练神经网络回归，运行指定了包含有<code>training_set</code>的<code>input_fn</code>的<code>fit</code>函数，如下：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">regressor<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: input_fn(training_set), steps=<span class="number">5000</span>)</div></pre></td></tr></table></figure>
<p>您应该能看到类似于以下内容的日志输出，它会报告每100步的训练loss值：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1</span>: loss = <span class="number">483.179</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">101</span>: loss = <span class="number">81.2072</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">201</span>: loss = <span class="number">72.4354</span></div><div class="line">...</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1801</span>: loss = <span class="number">33.4454</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1901</span>: loss = <span class="number">32.3397</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">2001</span>: loss = <span class="number">32.0053</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4801</span>: loss = <span class="number">27.2791</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4901</span>: loss = <span class="number">27.2251</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving checkpoints <span class="keyword">for</span> <span class="number">5000</span> into <span class="regexp">/tmp/</span>boston_model/model.ckpt.</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Loss <span class="keyword">for</span> <span class="keyword">final</span> <span class="string">step:</span> <span class="number">27.1674</span>.</div></pre></td></tr></table></figure>
<h3 id="评估模型">评估模型</h3><p>接下来，看看训练模型如何针对测试数据集执行。运行<code>evaluate</code>，这次将<code>test_set</code>传递给<code>input_fn</code>：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">ev</span> = regressor.evaluate(<span class="attr">input_fn=lambda:</span> input_fn(test_set), <span class="attr">steps=1)</span></div></pre></td></tr></table></figure>
<p>从<code>ev</code>的结果中检索损失并将其打印到输出：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">loss_score = ev[<span class="string">"loss"</span>]</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"Loss: &#123;0:f&#125;"</span>.format(loss_score)</span></span>)</div></pre></td></tr></table></figure>
<p>您应该会看到类似以下的结果：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Eval steps [<span class="number">0</span>,<span class="number">1</span>) <span class="keyword">for</span> training step <span class="number">5000.</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving evaluation summary <span class="keyword">for</span> <span class="number">5000</span> <span class="string">step:</span> loss = <span class="number">11.9221</span></div><div class="line"><span class="string">Loss:</span> <span class="number">11.922098</span></div></pre></td></tr></table></figure>
<h3 id="进行预测">进行预测</h3><p>最后，您可以使用模型预测<code>prediction_set</code>中的房屋中值，其中包含特征数据，但没有六个样本的标签：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">y = regressor.<span class="keyword">predict</span>(input_fn=lambda: input_fn(prediction_set))</div><div class="line"># .<span class="keyword">predict</span>() returns <span class="keyword">an</span> iterator; convert to a <span class="keyword">list</span> and <span class="keyword">print</span> predictions</div><div class="line">predictions = <span class="keyword">list</span>(itertools.islice(y, 6))</div><div class="line"><span class="keyword">print</span> (<span class="string">"Predictions: &#123;&#125;"</span>.<span class="keyword">format</span>(str(predictions)))</div></pre></td></tr></table></figure>
<p>您的结果应包含以 $1000 计的六次房价预测，例如：</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Predictions: [ <span class="number">33.30348587</span>  <span class="number">17.04452896</span>  <span class="number">22.56370163</span>  <span class="number">34.74345398</span>  <span class="number">14.55953979</span></div><div class="line">  <span class="number">19.58005714</span>]</div></pre></td></tr></table></figure>
<h2 id="其他资源">其他资源</h2><p>本教程专注于为神经网络回归创建一个<code>input_fn</code>。要了解更多有关对其他类型模型使用<code>input_fn</code>的信息，请查看以下资源：</p>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="external">TensorFlow的大尺寸线性模型</a>：这种对TensorFlow中的线性模型的介绍提供了用于变换输入数据的特征列和技术的高级概述。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>：本教程包括为线性分类模型创建<code>FeatureColumn</code>s和<code>input_fn</code>，该模型根据人口普查数据预测收入范围。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="external">TensorFlow宽＆深学习教程</a>：基于<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>，本教程涵盖了使用<code>DNNLinearCombinedClassifier</code>组合线性模型和神经网络的“宽和深”模型的<code>FeatureColumn</code>和<code>input_fn</code>创建。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/05/关于机器学习的一些思考/" itemprop="url">
                关于机器学习的一些思考
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-05T16:40:58+08:00" content="2017-03-05">
            2017-03-05
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/05/关于机器学习的一些思考/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/05/关于机器学习的一些思考/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>我大概是在两年前开始正式关注机器学习领域的，当时一心想做一个基于机器学习的五子棋程序，希望能达到机器自动理解五子棋游戏规则的效果，但没能成功，于是我开始找一些机器学习领域的课程和书籍开始啃。</p>
<p>当时机器学习在国内还是一个很少听到的名词，但当我学习这方面的东西的时候，我深深的感受到这个领域的东西和我之前学到的技术不是一个维度的东西，并且它将深远的影响未来的发展。直到后来AlphaGo的出现，以及Google开源了TensorFlow，这一系列的大事件的发生，悄然在业内刮起了一股人工智能风。</p>
<p>TensorFlow在开源之初，国内的<strong>极客学院</strong>发起了文档的翻译工作，还记的在其翻译文档的首页这样写到：</p>
<blockquote>
<p>你正在阅读的项目可能会比 Android 系统更加深远地影响着世界！</p>
</blockquote>
<p>不管这句话说得是否过于夸大，但TensorFlow在github上开源一个月之内就收到了10000+的star，这是github上机器学习领域也是python领域star增长最快的项目了。截止目前，TensorFlow的star为49227，已经超过了linux的42490。可见，机器学习的发展速度之迅猛，是不容小视的。</p>
<p>本文是我对机器学习领域的一些见解和思考，主要涉及<strong>机器学习的定义</strong>，<strong>机器学习的学习方式</strong>以及<strong>相关概念的理解</strong>。你会看到很多教科书上看不到的解读，虽然不是很严谨，但有助于你对一些概念建立起直觉上的理解，从而帮助你更好的了解这一领域的知识。</p>
<h2 id="思考1：机器学习是什么">思考1：机器学习是什么</h2><h3 id="机器学习定义">机器学习定义</h3><blockquote>
<p>机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。</p>
</blockquote>
<p>这是百度百科给出的定义，更加通俗的解释一下，机器学习是人工智能领域下的子领域，通过对大量现有数据的分析运算来对未知数据进行预测的一种学科。（虽然说法不严谨，但这种解释有助于理解）</p>
<p>将机器学习的通用模型类比于养一个小孩：</p>
<ul>
<li>训练过程就像是养一个小孩子</li>
<li>如果小孩子小的时候接触到了正确的教育（这里正确的教育就是<strong>训练数据集</strong>）</li>
<li>如果小孩子本身的悟性很高（悟性很高类比于有很好的<strong>学习算法</strong>）</li>
<li>那么这个孩子经过一段时间的成长学习后（类比于机器学习的<strong>训练</strong>阶段）</li>
<li>会成为一个有用之才（得到和很好的<strong>假设函数</strong>，即训练模型）</li>
<li>当他遇到新的人和事的时候（接受<strong>测试数据</strong>）</li>
<li>就能够处理的很好（<strong>预测结果</strong>）</li>
</ul>
<p>这就是机器学习的通用模型，虽然不是严谨的学术定义，但相信这能使你建立一种直觉上的认识。</p>
<h3 id="这是一项新技术吗？">这是一项新技术吗？</h3><p>机器学习目前处于学术界迈向工业界的一个过程，其核心算法几十年前就有了，理念也绝非新鲜事物，达到工业级别是一个时间问题，而现在<strong>我们就处在这一学术界迈向工业界的关键阶段</strong>。</p>
<p>其实，机器学习的核心概念早在第一台计算机制造之前就已经产生了。这里也不做过多介绍，大家可以自行去搜索。</p>
<h2 id="思考2：如何学习机器学习">思考2：如何学习机器学习</h2><h3 id="学习框架_or_学习算法?">学习框架 or 学习算法?</h3><p>完全没有学过这一领域的东西，是否应该直接上手TensorFlow之类的框架呢？</p>
<p>框架只是工具，不管是TensorFlow还是Caffe还是Torch，都是对算法的封装，很多之前做其他方面开发的程序员，在接触一个框架或者工具时，都倾向于追求能达到“直接去调用一下就得到结果”这样的效果，但机器学习领域的框架并不是如此，它要求你对机器学习领域的算法有一定了解，要明白自己在做什么。</p>
<p>所以先对这个领域的算法知识有个掌握之后，再去学习和使用框架来实践操作可能是效率更高的一种学习模式。相反，直接上手来学习框架，期望直接调用一些API就得出结果的想法会让你有种寸步难行的感觉。</p>
<p>这里安利一下<a href="https://www.coursera.org/" target="_blank" rel="external">coursera</a>上的吴恩达老师的<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">机器学习</a>课程（可能会需要翻墙才能访问，自行购买vpn）。这门课深入浅出的讲解了机器学习领域的流行的算法的实现原理。</p>
<blockquote>
<p>介绍一下吴恩达老师，在最强大脑第四季开播之前，可能知道他的人很少。吴恩达是华裔美国人，是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任，是Coursera的联合创始人。之前是google负责google大脑项目，后来在14年5月16日加入百度，担任百度首席科学家，负责百度研究院的领导工作，尤其是Baidu Brain计划。这是中国互联网公司迄今为止引进的最重量级人物。</p>
</blockquote>
<h3 id="深入底层_or_关注上层？">深入底层 or 关注上层？</h3><p>在技术领域一直流传着这样一种理念：底层的就是牛X的。上层技术变化无常，但底层技术万变不离其宗。再加上底层技术的学习成本远高于上层技术，而且吃透了底层技术能够对上层技术有更深刻的理解，导致程序员对底层技术有一种神圣的向往情节。</p>
<p>技术领域，专注细节不是坏事，但对于机器学习这个领域呢？恐怕我们需要重新考量一下这种思维模式了。</p>
<p>其实在机器学习领域，也是提倡对底层实现算法有一定的了解的，但并不代表我们要去亲自实现一些算法，比如神经网络中的反向传播算法的实现，很多框架都已经写的很完善了，而且都是数值计算领域的专家来实现的高质量高性能的代码，我们没必要花时间和精力来重新造轮子，也没必要去研究他们是如何造的这个轮子。我们更应该把宝贵的时间留在理解这些算法的原理上，以及学会使用这些算法来应用到实际中的问题，这才是把好钢用到了刀刃上。</p>
<p>实际上，正确的学习方式是，首先学习并理解算法原理，在直觉层面建立起对算法的认识，然后快速动手实践，将学到的算法应用到小项目里，不用太过在意写的东西是不是很挫，重要的是开始写！然后再不断的完善你的项目。带着一些问题去继续学习，你会有更多的收获。</p>
<h3 id="不要想太多有的没的">不要想太多有的没的</h3><p>可能很多人跟我一样，刚开始了解这一领域的东西的时候，很是兴奋，感觉造出一个通用人工智能指日可待了。再加上近些年随着人工智能概念的兴起，出来了一批相关影视作品和科幻小说，更让我们对人工智能产生了一系列不切实际的想法。</p>
<p>对于这一点，我想说明的是，不要过分执迷于AI能创建出智能大脑的想法，除非你是业内出类拔萃的专家。科幻小说与电影只是一种艺术表现手法，并不代表着未来。通常，人们看不懂看不透的地方就容易形成骗局，通用智能虽然是人工智能一直以来在追求的一个目标，但目前主流学术发展方向并没有朝着这方面走。机器学习、深度学习的确在飞速的进步，未来也会波及到很多行业，但这个学科归根结底还是一门基于数据的学科，并没有达到拥有情感、独立思考等这方面的能力，实际上，绝大多数业内专家对这方面的想法是持有厌恶态度的，倒是相关的社科类软文在这个时代被吹上了天。</p>
<p>因此，与其花时间想这些有的没的，还不如花时间脚踏实地的去学习一下算法、写写代码，除非你想成为一个科幻小说作家。</p>
<h2 id="思考3：机器学习中一些概念的解读">思考3：机器学习中一些概念的解读</h2><p>机器学习领域中有很多很有趣、很耐人寻味的原理值得细细品味，下面是我对其中部分概念的直觉上的理解，可能你在教科书或者教学视频上看不到这种解读，但这些概念所折射出来的现象也许就是我所描述的那样。当然，如果你没有看过这个领域，甚至没有写过代码也没关系，我保证能让你能读得懂。</p>
<h3 id="神经网络">神经网络</h3><p><strong>神经网络</strong>是机器学习领域出镜率很高的一个词汇，很多人对它的理解一直是停留在“<strong>很牛X，很复杂</strong>”的状态。下面用一个例子来解释神经网络的使用原理：</p>
<p>假设你有一个下周六是否要去电影院看电影的决定。这个决定的结果无非只有两种：<strong>去</strong>或者<strong>不去</strong>。</p>
<p>影响你去或不去的因素有很多：</p>
<ul>
<li>是否有人陪</li>
<li>是否有想看的电影</li>
<li>是否有时间</li>
<li>天气是否足够好</li>
<li>…</li>
</ul>
<p>我相信你可以列出足够多的理由来拒绝周末去看电影，但为了方便描述起见，我们先用三个条件：<strong>是否有人陪</strong>、<strong>是否有想看的电影</strong>、<strong>是否有时间</strong>。</p>
<p>好，现在我们来用三个圈来表示这三个条件。</p>
<p><img src="/img/17_03_05/002.png" alt=""></p>
<p>圆圈中间的数值代表对做出去看电影的决策的影响程度，可以看到这里<strong>是否有时间</strong>的影响程度是最大的（这里的每个小圈，其实就是神经网络中的<strong>神经元</strong>，上面的数值就是<strong>权值</strong>）。</p>
<p>我们接下来把我们的神经网络补充完整：</p>
<p><img src="/img/17_03_05/003.png" alt=""></p>
<p>我们又加了两个圈和一些箭头。好，对应图中，如果我们现在<strong>有想看的电影，可是没有人陪，但有时间</strong>，那么我们的计算方式就是:</p>
<p><img src="/img/17_03_05/004.png" alt=""></p>
<p>$$<br>(-1)×0.3 + 1×0.6 + 1×1.0 = 1.3<br>$$</p>
<p>输出结果是一个大于0的值：1.3，代表我们会做出去看电影的决定。</p>
<p>类似的，假如我们<strong>有人陪，有想看的电影，但是没时间</strong>：</p>
<p>$$<br>1×0.3 + 1×0.6 + (-1)×1.0 = -0.1<br>$$</p>
<p>是一个负数，代表我们不会去看电影。</p>
<p>这就是一个训练好的神经网络的使用方式，这幅图就是一个典型的三层神经网络，从左到右依次是<strong>输出层</strong>、<strong>隐藏层</strong>、<strong>输出层</strong>，其中0.3，0.6，1.0是通过<strong>训练</strong>得出的<strong>权值</strong>。</p>
<p><img src="/img/17_03_05/005.png" alt=""></p>
<p>我相信你对神经网络还是有很多疑问，比如0.3，0.6和1.0是怎么得来的（实际上是通过<strong>反向传播算法</strong>得来的），但神经网络运作的大体模式就是这样，希望你能对它产生一种宏观层面的认识。</p>
<h3 id="偏拟合_和_过拟合">偏拟合 和 过拟合</h3><p><strong>偏拟合</strong>和<strong>过拟合</strong>具体是什么意思呢？不要被陌生的名词吓到。</p>
<p>首先要说明的是，这两个词都不是褒义词，都是我们不想看到的一种状态。</p>
<p>其实所谓<strong>偏拟合</strong>就是相当于某一领域经验不足的人，由于经历的事情太少，容易做出一些错误的判断，这种现象就是<strong>偏拟合</strong>。</p>
<p>所谓<strong>过拟合</strong>，恰恰相反，是指某一领域经验非常丰富的人，由于经历的事情太多，反而容易对新的事物产生偏见（因为既往的经验会告诉他这是不对的），从而产生错误的决定。</p>
<p>教科书上不会这么解释<strong>偏拟合</strong>和<strong>过拟合</strong>的概念，但事实上这个概念描述的就是这样的现象。是不是我们身边随处可见这两种现象呢？</p>
<h3 id="查准率_和_召回率">查准率 和 召回率</h3><p>假设我们现在写了个用于预测病人是否患有肺癌的程序，我们出入了100个病人的体征数据，然后来告知这一批病人有谁不幸得了肺癌。</p>
<p>假设我们的预测准确率为98%，这个结果乍一看是不是很高呢？但我告诉你另一个事实，那就是我们只有两个病人是真正患有肺癌的，然而我们的算法正确的识别了两者中的一位，并且还错误的认为在98名没有患有肺癌的患者里有一位癌症患者。那这还是一个好结果吗？</p>
<p>很明显，100个人里只有两个人患有癌症，其中一个还预测错误，这是一个很差的结果，但我们的准确率为98%，因为我们预测对了100个人中的98个人，所以从准确率上来看并不差，但实际结果却很差。</p>
<p>这就是典型的<strong>偏斜类</strong>问题。</p>
<p>也许有人会说，这表明了数据会说谎，但实际情况是，数据并没有说谎，只不过我们看待数据的方式不够科学。</p>
<p>科学的方式就是引入<strong>查准率</strong>和<strong>召回率</strong>。</p>
<p>在这里:</p>
<p>$$<br>查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量}<br>$$</p>
<p>$$<br>召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量}<br>$$</p>
<p>可见，<strong>查准率</strong>和<strong>召回率</strong>都是越高越好的。</p>
<p>那么我们的例子中<strong>查准率</strong>和<strong>召回率</strong>的真实值分别为：</p>
<p>$$<br>查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量} = \frac{1} {2} = 0.5<br>$$</p>
<p>$$<br>召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量} = \frac{1} {2} = 0.5<br>$$</p>
<p>我们的查准率和召回率都很低。所以换个角度来看待数据，会有新的发现。</p>
<p>查准率和召回率是两个维度的数据，有的时候我们为了追求高查准率，会得到一个低召回率的结果；有的时候我们为了追求高召回率，却会得到一个低查准率的结果。这种顾此失彼的状态，也不是我们想要。</p>
<p>所以我们引入了一个叫做<strong>Fscore</strong>的方法来对两种进行一个整体的衡量，其表达式为：</p>
<p>$$<br>Fscore = \frac{查准率×召回率} {查准率+召回率}<br>$$</p>
<p>这里我们的$Fscore=0.25$。</p>
<p>我们生活中也处处充满着<strong>准确率高但查准率和召回率低的例子</strong>：</p>
<p>我们往往会有这种体验，一些成功的名人说的话似乎都很有道理，但其实他们说的有道理的话似乎都比较“大”；而有些人，专注于某一特定领域的专家，在发表一些观点的时候，用词都非常谨慎，因为他们在描述一件具体的事物。</p>
<p>所以，我们会发现，<strong>越“大”的话，越容易获得较高的准确率；越“专”的话，越不容易获得较高的准确率</strong>。</p>
<p>所以带着这种角度，我们去审视一下：</p>
<ul>
<li>失败是成功之母。</li>
<li>天才是99%的汗水加1%的灵感。</li>
<li>…</li>
</ul>
<p>类似这类的<strong>鸡汤名言</strong>，我们会有新的思考。我们会发现，真正的牛人说的话，不仅仅准确率高，而且查准率和召回率也很高。</p>
<h3 id="无监督学习">无监督学习</h3><p><strong>无监督学习</strong>是相对于<strong>监督学习</strong>而言的。那么什么是<strong>监督学习</strong>呢？</p>
<p><strong>监督学习</strong>通俗的将就是我们告诉机器一堆格式为：</p>
<p><strong>bulabulabula的东西，是xxx</strong></p>
<p>来预测未知类别的数据：</p>
<p><strong>bulabulabula的东西，是？</strong></p>
<p>例如通过体征来预测性别：</p>
<p>已有100个数据：</p>
<ul>
<li>身高175cm，短发，70kg的人是男性</li>
<li>身高165cm，长发，48kg的人是女性</li>
<li>…</li>
</ul>
<p>那么：</p>
<ul>
<li>身高170cm，长发，55kg的人是？</li>
</ul>
<p>这种预测类别已知的机器学习，就是<strong>监督学习</strong>。典型的<strong>监督学习</strong>的案例有<strong>语音识别</strong>、<strong>图像识别</strong>、<strong>人脸识别</strong>等等。</p>
<p>所谓<strong>无监督学习</strong>就是我们并不能知道数据所属的类别，通过算法使数据自动地按照相似的类别聚合起来，即所谓的<strong>聚类算法</strong>。</p>
<p>我们俗话所说的<strong>物以类聚，人以群分</strong>就是无监督学习的体现。</p>
<p>其实，仔细想想，人类社会的发展演化过程，是不是就是一个大型的<strong>无监督学习</strong>的过程呢？我们都是这个学习过程中的一环，是这个大型的神经网络中的一个神经元，我们社会的发展形态和目标在各个阶段都是不一样的，即使我们无法过远地预测到未来进化的方向，但我们一直在自我学习的过程中不断进化。也许这正是生命的本质。</p>
<hr>
<p>以上观点可能不是很严谨，也不是正统的机器学习理论，是本人对机器学习的一些思考。如有概念上的错误，欢迎斧正。也欢迎在评论区和我一起讨论<strong>机器学习</strong>的相关问题。</p>
<p>非常感谢您能读完我的文章，最后安利一下我的一个实验项目<a href="http://118.190.96.169:3389/iw/help/" target="_blank" rel="external">智能背词算法</a>，目前处于数据采集阶段，具体使用方式见帮助页面。谢谢~</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/">&raquo;</a>
  </nav>

 </div>

        

        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="http://dannylee1991.github.io/images/avatar.jpg" alt="DannyLee佳楠" itemprop="image"/>
          <p class="site-author-name" itemprop="name">DannyLee佳楠</p>
        </div>
        <p class="site-description motion-element" itemprop="description">一只在迈向机器学习道路上狂奔的程序猿.</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">106</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">19</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DannyLee1991" target="_blank">GitHub</a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DannyLee佳楠</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"dannylee1991"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>
    
     
  	<script src="/js/ua-parser.min.js"></script>
  	<script src="/js/hook-duoshuo.js"></script>
  

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
