<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>


    <meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿." />



  <meta name="keywords" content="Hexo,next" />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta property="og:type" content="website">
<meta property="og:title" content="DannyLee">
<meta property="og:url" content="http://dannylee1991.github.io/index.html">
<meta property="og:site_name" content="DannyLee">
<meta property="og:description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DannyLee">
<meta name="twitter:description" content="一只在迈向机器学习道路上狂奔的程序猿.">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>

<!--baidu统计-->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2f967e5ec4f276411160d27aeace7722";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  <title> DannyLee </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">DannyLee</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            标签
          </a>
        </li>
      

      
      
        <li class="menu-item menu-item-search">
          <a href="#" class="st-search-show-outputs">
            <i class="menu-item-icon icon-next-search"></i> <br />
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'ss9-_Hsd4DyhyGw4m99P','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:图的可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T22:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>TensorFlow计算图是强大而复杂的。图形可视化可以帮助您理解和调试它们。这里有一个可视化工作的例子。</p>
<p><img src="/img/17_03_07/007.gif" alt=""></p>
<p><em>TensorFlow图的可视化。</em></p>
<p>如有想查看你的图，你需要运行TensorBoard并将其指向你的作业的日志目录，单击顶部窗格上的图形选项卡，然后使用左上角的菜单选择适当的运行。有关如何运行TensorBoard并确保您记录所有必要信息的深入信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard：可视化学习</a>。</p>
<h2 id="名称作用域和节点">名称作用域和节点</h2><p>典型的TensorFlow图可以有成千上万的节点 - 这个展示量太大了，以至于即使使用标准图工具来布局也太大了。为了简化显示，我们通过变量名指定其对应的作用域，通过使用这些信息来定义图中节点图层的可视化。默认情况下，只显示此层次结构的顶部部分。下面是一个使用<a href="https://www.tensorflow.org/api_docs/python/tf/name_scope" target="_blank" rel="external"><code>tf.name_scope</code></a>在隐藏名称范围下定义三个操作的示例：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'hidden'</span>) <span class="keyword">as</span> scope:</div><div class="line">  <span class="keyword">a</span> = <span class="keyword">tf</span>.constant(<span class="number">5</span>, name=<span class="string">'alpha'</span>)</div><div class="line">  W = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.random_uniform([<span class="number">1</span>, <span class="number">2</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>), name=<span class="string">'weights'</span>)</div><div class="line">  <span class="keyword">b</span> = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.zeros([<span class="number">1</span>]), name=<span class="string">'biases'</span>)</div></pre></td></tr></table></figure>
<p>这将产生以下三个操作名称：</p>
<ul>
<li><code>hidden/alpha</code></li>
<li><code>hidden/weights</code></li>
<li><code>hidden/biases</code></li>
</ul>
<p>默认情况下，可视化将这三个操作压缩到标记为<code>hidden</code>的节点中。额外的细节不会丢失。您可以双击或单击右上角的橙色<code>+</code>号来展开节点，然后您将看到三个子节点的<code>alpha</code>，<code>weights</code>和<code>biases</code>。</p>
<p>这是一个在初始化和展开状态更复杂的真实例子：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/008.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/009.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">顶层名称作用域<strong>pool_1</strong>的初始化视图。单击右上角的橙色<code>+</code>按钮或双击节点本身将会展开它。</td>
<td style="text-align:left"><strong>pool_1</strong>名称作用域的展开视图。单击右上角的橙色按钮或双击节点本身将折叠名称作用域。</td>
</tr>
</tbody>
</table>
<p>按名称范围对节点分组对于创建清晰的图表至关重要。如果您正在构建模型，名称作用域可以控制生成的可视化。<strong>你的名字的作用域越好，可视化效果越好。</strong></p>
<p>上图说明了可视化的第二个方面。TensorFlow图有两种连接：数据依赖和控制依赖。数据依赖显示了两个操作之间的tensor流，并且示为实箭头，而控制依赖使用虚线。在扩展视图（上图右侧）中，所有连接都是数据依赖关系，但连接<code>CheckNumerics</code>和<code>control_dependency</code>的虚线除外。</p>
<p>还有第二种简化布局的小技巧。大多数TensorFlow图都存在几个与其他节点有很多连接的节点。例如，许多节点可能对初始化步骤具有控制依赖性。绘制<code>init</code>节点以及其依赖项之间的所有边将创建一个非常混乱的视图。</p>
<p>为了减少杂乱程度，可视化将所有高度节点分离到右侧的辅助区域，并且不绘制代表它们边缘的线。相对于用线来表示边缘来讲，这里我们绘制小节点图标以指示连接关系。分离出辅助节点通常不会移除关键信息，因为这些节点通常与记录方法相关。有关如何在主图和辅助区域之间移动节点，请参阅<a href="#交互">交互</a>部分。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/010.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/011.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点<strong>conv_1</strong>已被连接到<strong>save</strong>。注意它右边的小<strong>save</strong>节点图标。</td>
<td style="text-align:left"><strong>save</strong>有高度，并且将作为辅助节点出现。与<strong>conv_1</strong>的连接在其左侧显示为节点图标。为了进一步减少杂乱程度，由于<strong>save</strong>有很多连接，我们显示到第5个，其他缩写为<strong>… 12 more</strong>。</td>
</tr>
</tbody>
</table>
<p>最后一个结构简化是series collapsing(系列折叠)。有顺序的图案 - 也就是说，其名称与末尾的数字不同并且具有相同构结构的节点被折叠为单个节点堆叠，如下所示。对于具有长序列的网络，这极大地简化了视图的显示。与分层节点一样，双击也可以展开。有关如何为特定节点集禁用/启用系列折叠，请参阅<a href="#交互">交互</a>。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/012.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/013.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点序列的折叠视图。</td>
<td style="text-align:left">双击后的一个小块的展开视图。</td>
</tr>
</tbody>
</table>
<p>最后，作为可读性的最后一个辅助部分，可视化对常量和摘要节点使用一些特定的图标来。下面是一个节点符号对照表：</p>
<table>
<thead>
<tr>
<th style="text-align:left">符号</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/014.png" alt=""></td>
<td style="text-align:left">高级节点，代表名称作用域。双击展开高级节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/015.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们彼此没有连接</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/016.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们是彼此连接的</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/017.png" alt=""></td>
<td style="text-align:left">单个操作节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/018.png" alt=""></td>
<td style="text-align:left">常数</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/019.png" alt=""></td>
<td style="text-align:left">摘要节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/020.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的数据流。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/021.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的控制依赖性。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/022.png" alt=""></td>
<td style="text-align:left">表示输出操作节点可以变为输入张量的参考边。</td>
</tr>
</tbody>
</table>
<h2 id="交互">交互</h2><p>通过平移和缩放导航图。点击并拖动即可平移，并使用滚动手势进行缩放。双击一个节点，或单击其<code>+</code>按钮，可以展开一个表示一组操作的名称作用域。为了在缩放和平移时轻松跟踪当前视点，右下角有一个小地图。</p>
<p>要关闭打开的节点，请再次双击它，或单击它的 <code>-</code> 按钮。您也可以单击来选择某个节点。它将变成更暗的颜色，并且它的详细信息和它连接的节点将出现在可视化界面的右上角的信息卡中。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/023.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/024.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">显示<strong>conv2</strong>名称作用域的详细信息的信息卡。输入和输出从名称作用域内的操作节点的输入和输出组合。对于名称作用域，不显示属性。</td>
<td style="text-align:left">显示<code>DecodeRaw</code>操作节点的详细信息的信息卡。除了输入和输出之外，它还显示了设备和与当前操作相关的属性。</td>
</tr>
</tbody>
</table>
<p>TensorBoard提供了几种方法来更改图形的视觉布局。这些方法不改变图的计算语义，但它可以为网络的结构带来一些清晰度。通过右键单击节点或按下该节点信息卡底部的按钮，可以对其布局进行以下更改：</p>
<ul>
<li>节点可以在主图和辅助区域之间移动。</li>
<li>一系列节点可以取消分组，以便系列中的节点不会显示在一起。未分组的系列同样可以重新分组。</li>
</ul>
<p>选择也有助于理解高度节点。选择任何高级节点，并选择其他连接的相应节点图标。这使得某些操作变得很容易，例如，看到哪些节点被保存，哪些没有被保存。</p>
<p>单击信息卡中的节点名称将选择它。如果需要，视点将自动平移，以便节点可见。</p>
<p>最后，您可以使用图例上方的颜色菜单为图形选择两种颜色方案。默认结构视图显示结构：当两个高级节点具有相同的结构时，它们以彩虹的相同颜色显示。唯一结构化的节点是灰色的。还有一个显示了运行不同操作的设备第二个视图。名称作用域的颜色与其内部操作的设备分数成比例。</p>
<p>下面的图片给出了一幅实际场景中的插图。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/025.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/026.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">结构视图：灰色节点具有独特的结构。橙色<strong>conv1</strong>和<strong>conv2</strong>节点具有相同的结构，并且类似地用于具有其它颜色的节点。</td>
<td style="text-align:left">设备视图：名称范围与其中的操作节点的设备分数成比例地着色。这里，紫色表示GPU，绿色表示CPU。</td>
</tr>
</tbody>
</table>
<h2 id="Tensor形状信息">Tensor形状信息</h2><p>当序列化<code>GraphDef</code>引入tensor形状时，图形可视化器标记具有tensor维度的边缘，并且边缘厚度反映总张量大小。在<code>GraphDef</code>中引入tensor形状，将序列化图形时的实际图形对象（如<code>sess.graph</code>中所示）传递给<code>SummaryWriter</code>。下图显示了带有张量形状信息的CIFAR-10模型：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/027.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CIFAR-10模型与张量形状信息。</td>
</tr>
</tbody>
</table>
<h2 id="运行时统计">运行时统计</h2><p>通常，收集运行的运行时元数据是有用的，例如节点的总内存使用，总计算时间和tensor形状。下面的代码示例是来自<a href="/2017/02/22/【Tensorflow%20r1.0%20文档翻译】机器学习的HelloWorld%20--%20MNIST手写数字识别/">简单MNIST教程</a>中的经过修改的训练和测试部分的代码片段，其中我们记录了摘要和运行时统计信息。有关如何记录摘要的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">摘要教程</a>。全部源代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:  <span class="comment"># Record execution stats</span></div><div class="line">      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)</div><div class="line">      run_metadata = tf.RunMetadata()</div><div class="line">      summary, _ = sess.run([merged, train_step],</div><div class="line">                            feed_dict=feed_dict(<span class="keyword">True</span>),</div><div class="line">                            options=run_options,</div><div class="line">                            run_metadata=run_metadata)</div><div class="line">      train_writer.add_run_metadata(run_metadata, <span class="string">'step%d'</span> % i)</div><div class="line">      train_writer.add_summary(summary, i)</div><div class="line">      print(<span class="string">'Adding run metadata for'</span>, i)</div><div class="line">    <span class="keyword">else</span>:  <span class="comment"># Record a summary</span></div><div class="line">      summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">      train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>此代码将从步骤99开始每隔100步发出运行时统计信息。</p>
<p>当您启动tensorboard并转到图表选项卡，您现在将看到“Session runs”下的选项对应于添加运行元数据的步骤。选择其中一个运行将显示该步骤的网络快照，淡出未使用的节点。在左侧的控件中，您可以按总内存或总计算时间对节点进行着色。此外，单击节点将显示确切的总内存，计算时间和张量输出大小。</p>
<p><img src="/img/17_03_07/028.png" alt=""></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:嵌入可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T21:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>嵌入在机器学习中无处不在，出现在推荐系统，NLP和许多其他应用程序中。事实上，在TensorFlow的上下文中，将tensor（或tensor切片）视为空间中的点是自然的，因此几乎任何TensorFlow系统将自然地产生各种嵌入。</p>
<p>要了解有关嵌入和如何训练它们的更多信息，请参阅<a href="https://www.tensorflow.org/tutorials/word2vec" target="_blank" rel="external">单词向量表示教程</a>。如果你对图像的嵌入感兴趣，请查看<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>，了解MNIST图像的有趣的可视化。另一方面，如果你对单词嵌入感兴趣，那么<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>会给你一个很好的介绍。</p>
<p>TensorBoard有一个内置的可视化工具，称为嵌入投影仪，用于交互式可视化和分析高维数据，例如嵌入。这意味着对开发人员和研究人员同样有用。它从保存tensorflow变量的检查点文件读取。虽然它对嵌入最有用，它将加载任何2D tensor，可能包括您的训练权重。</p>
<video height="363" width="710" id="video" controls preload="none" poster="/img/17_03_07/002.png"><br>    <source id="mp4" src="/img/17_03_07/001.mp4" type="video/mp4"><br>    <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<p>默认情况下，嵌入投影仪执行三维<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="external">主成分分析</a>，这意味着它接受你的高维数据，并试图找到一个结构保留投影到三维空间。基本上，它通过旋转你的数据，使前三个维度显示尽可能多的数据方差。<a href="http://setosa.io/ev/principal-component-analysis/" target="_blank" rel="external">这里</a>有一个很好的视觉解释。另一个非常有用的投影是<a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" target="_blank" rel="external">t-SNE</a>。我们稍后在教程中讨论更多的t-SNE。</p>
<p>如果您使用嵌入，您可能需要将标签/图像附加到数据点，以告诉可视化器每个数据点对应的标签/图像。您可以通过生成元数据文件，使用我们的Python API将其附加到tensor，或将其上传到已经运行的TensorBoard来完成。</p>
<h2 id="构建">构建</h2><p>有关如何运行TensorBoard并确保您记录所有必要的信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard-可视化学习/</a>。</p>
<p>要可视化您的嵌入，您需要做3件事：</p>
<p>1）设置一个二维tensor变量来保存你的嵌入。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">embedding_var</span> = tf.Variable(....)</div></pre></td></tr></table></figure>
<p>2）定期将您的嵌入保存在<code>LOG_DIR</code>中。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</div><div class="line">saver.save(session, os<span class="selector-class">.path</span><span class="selector-class">.join</span>(LOG_DIR, <span class="string">"model.ckpt"</span>), step)</div></pre></td></tr></table></figure>
<p>以下步骤不是必要的，但是如果您有与嵌入相关联的任何元数据（标签，图像），则需要将它们链接到tensor上，以便TensorBoard知道它。</p>
<p>3）将元数据与嵌入关联。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">from tensorflow.contrib.tensorboard.plugins <span class="built_in">import</span> projector</div><div class="line"><span class="comment"># Use the same LOG_DIR where you stored your checkpoint.</span></div><div class="line"><span class="attr">summary_writer</span> = tf.train.SummaryWriter(LOG_DIR)</div><div class="line"></div><div class="line"><span class="comment"># Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto</span></div><div class="line"><span class="attr">config</span> = projector.ProjectorConfig()</div><div class="line"></div><div class="line"><span class="comment"># You can add multiple embeddings. Here we add only one.</span></div><div class="line"><span class="attr">embedding</span> = config.embeddings.add()</div><div class="line">embedding.<span class="attr">tensor_name</span> = embedding_var.name</div><div class="line"><span class="comment"># Link this tensor to its metadata file (e.g. labels).</span></div><div class="line">embedding.<span class="attr">metadata_path</span> = os.path.join(LOG_DIR, 'metadata.tsv')</div><div class="line"></div><div class="line"><span class="comment"># Saves a configuration file that TensorBoard will read during startup.</span></div><div class="line">projector.visualize_embeddings(summary_writer, config)</div></pre></td></tr></table></figure>
<p>运行模型并训练嵌入后，运行TensorBoard并将其指向job的<code>LOG_DIR</code>。</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard <span class="comment">--logdir=LOG_DIR</span></div></pre></td></tr></table></figure>
<p>然后单击顶部窗格上的<em>Embeddings</em>选项卡，并选择适当的运行（如果有多个运行）。</p>
<h2 id="元数据（可选）">元数据（可选）</h2><p>通常嵌入具有与其相关联的元数据（例如，标签，图像）。元数据应存储在模型检查点之外的单独文件中，因为元数据不是模型的可训练参数。格式应为TSV文件，第一行包含列标题，后续行包含元数据值。这里有一个例子：</p>
<figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Name<span class="symbol">\t</span>Type<span class="symbol">\n</span></div><div class="line">Caterpie<span class="symbol">\t</span>Bug<span class="symbol">\n</span></div><div class="line">Charmeleon<span class="symbol">\t</span>Fire<span class="symbol">\n</span></div><div class="line">…</div></pre></td></tr></table></figure>
<p>没有与主数据文件共享的显式键;相反，假设元数据文件中的顺序与嵌入tensor中的顺序匹配。换句话说，第一行是头信息，元数据文件中的第(i+1)行对应于存储在检查点中的嵌入tensor的第i行。</p>
<blockquote>
<p><strong>注意：</strong>如果TSV元数据文件只有一个列，那么我们不需要一个标题行，并且假设每一行都是嵌入的标签。我们包含此异常，因为它匹配常用的“词汇文件”格式。</p>
</blockquote>
<h3 id="图">图</h3><p>如果您有与嵌入关联的图像，则需要生成包含每个数据点的小缩略图的单个图像。这被称为<a href="https://www.google.com/webhp#q=what+is+a+sprite+image" target="_blank" rel="external">精灵图像（sprite image）</a>。精灵应具有相同数目的行和列，缩略图按行首先顺序存储：第一个数据点放置在左上角，最后一个数据点在右下角：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">7</td>
</tr>
</tbody>
</table>
<p>请注意，在上面的示例中，最后一行不必填写。对于精灵的一个具体示例，请看这个<a href="https://www.tensorflow.org/images/mnist_10k_sprite.png" target="_blank" rel="external">精灵图像</a>的10,000 MNIST数字（100x100）。</p>
<blockquote>
<p><strong>注意：</strong>我们目前支持高达8192px X 8192px.的精灵。</p>
</blockquote>
<p>构造精灵后，您需要告诉嵌入投影机在哪里可以找到它：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">embedding.sprite.image_path = PATH_TO_SPRITE_IMAGE</div><div class="line"><span class="comment"># Specify the width and height of a single thumbnail.</span></div><div class="line">embedding.sprite.single_image_dim.<span class="keyword">extend</span>([w, h])</div></pre></td></tr></table></figure>
<h2 id="相互作用">相互作用</h2><p>嵌入式投影机有三个面板</p>
<ul>
<li>1.位于左上方的数据面板，你可以选择你指定的运行、嵌入tensor和数据列来着色和标记点。</li>
<li>2.位于左下方的预测面板，用于选择投影类型（例如PCA，t-SNE）。</li>
<li>3.位于右侧的监视面板，在那里你可以搜索特定的点，并查看最近的邻居列表。</li>
</ul>
<h3 id="预测">预测</h3><p>嵌入投影仪具有减少数据集的维度的三种方法：两个线性的和一个非线性的。每个方法可用于创建二维或三维视图。</p>
<p><strong>主成分分析（Principal Component Analysis）</strong>减少维度的主要技术是主成分分析（PCA）。嵌入投影仪计算前10个主要元素。该菜单允许您将这些元素投影到两个或三个任意组合。PCA是一个线性投影，通常用于检查全局几何。</p>
<p><strong>t-SNE</strong>一种流行的非线性降维技术是T-SNE。嵌入投影机提供二维和三维t-SNE视图。布局是在客户端对算法的每一步执行动画。因为t-SNE经常保留一些局部结构，所以它对于探索局部邻域和找到簇是有用的。虽然对于可视化高维数据非常有用，但t-SNE图有时可能会产生迷惑或者误导的作用。想要了解如何有效地使用t-SNE，可以看看这篇<a href="http://distill.pub/2016/misread-tsne/" target="_blank" rel="external">很棒的文章</a>。</p>
<p><strong>自定义（Custom）</strong>您还可以基于文本搜索来构造专门的线性投影，以在空间中找到有意义的方向。要定义投影轴，请输入两个搜索字符串或正则表达式。程序计算出其标签与这些搜索匹配的点集合的质心，并使用质心之间的差向量作为投影轴。</p>
<h3 id="导航">导航</h3><p>要探索数据集，您可以在2D或3D模式中浏览视图，使用自然的点击和拖动手势进行缩放，旋转和平移。单击一个点会使右窗格显示最近邻居的显式文本列表，以及到当前点的距离。最近邻点本身在投影上突出显示。</p>
<p>放大集群会提供一些信息，但有时更有帮助的是将视图限制为点的子集，并仅对这些点执行投影。为此，您可以通过多种方式选择点：</p>
<ul>
<li>1.点击一个点后，也选择其最近的邻居。</li>
<li>2.搜索后，选择与查询匹配的点。</li>
<li>3.启用选择，单击点并拖动定义选择球体。</li>
</ul>
<p>选择一组点后，您可以使用右侧“检查器”窗格中的“隔离点”按钮单独隔离这些点以进行进一步分析。</p>
<p><img src="/img/17_03_07/003.png" alt=""></p>
<p><em>在词嵌入数据集中选择“重要”的最近邻。</em></p>
<p>过滤与自定义投影的组合的功能是非常强大的。下面，我们过滤了“politics”的100个最接近的邻居，并将它们投影到“best” - “worst”向量作为x轴。 y轴是随机的。</p>
<p>你可以看到，在右边我们有“ideas”，“science”，“perspective”，“journalism”，而在左边我们有“crisis”，“violence”和“conflict”。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/006.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/004.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">自定义投影控件。</td>
<td style="text-align:left">将“politics”的邻居定义为“best” - “worst”向量。</td>
</tr>
</tbody>
</table>
<h3 id="共同特征">共同特征</h3><p>如果你想要分享您的发现，您可以使用右下角的书签面板，并将当前状态（包括任何投影的计算坐标）保存为小文件。投影仪可以同时打开并展示一个或多个这些小文件。这样一来，其他用户就可以浏览这些书签了。</p>
<p><img src="/img/17_03_07/005.png" alt=""></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:可视化学习
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T18:26:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>你使用TensorFlow来进行的某些大规模深度神经网络，可能是很复杂，并且令人困惑的。为了使它更容易被理解、调试、并且优化TensorFlow程序，我们引入了一套可视化工具，它就是TensorBoard。你可以使用TensorBoard来可视化你的TensorFlow计算图，绘制关于图形执行的定量指标，以及显示其他数据的图像。</p>
<p>当TensorBoard完全配置好时，它看起来是这样的：</p>
<p><img src="/img/17_03_07/001.png" alt=""></p>
<p>本教程旨在帮助您学习TensorBoard的基本使用方式。当然，还有其他介绍资源！<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>有大量关于TensorBoard的信息，包括提示和技巧和调试信息。</p>
<h2 id="序列化数据">序列化数据</h2><p>TensorBoard通过读取TensorFlow事件文件进行操作，这些文件包含运行TensorFlow时可以生成的摘要数据。下面是TensorBoard中摘要数据的一般生命周期。</p>
<p>首先，创建要从其中收集摘要数据的TensorFlow图，并决定要使用<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">summary operations</a>注释哪些节点。</p>
<p>例如，假设你正在训练一个卷积神经网络来识别MNIST数字。你想记录学习速率随时间的变化，以及目标函数如何变化。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar" target="_blank" rel="external"><code>tf.summary.scalar</code></a>操作分别附加到输出学习速率和损失的节点来收集这些信息。然后，给每个<code>scalar_summary</code>赋予有意义的<code>tag</code>，如<code>learning rate</code>或<code>loss function</code>。</p>
<p>也许你也想要可视化来自特定层的激活的分布，或梯度或权重的分布。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/histogram" target="_blank" rel="external"><code>tf.summary.histogram</code></a>操作附加到梯度输出和分别保存您的权重的变量来收集此数据。</p>
<p>有关所有可用摘要操作的详细信息，请查看<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">摘要操作的文档</a>。</p>
<p>在您运行TensorFlow中的操作之前，它们都不会被运行，依赖于它们的输出的操作也不会被执行。我们刚刚创建的汇总节点是图形的外设：您当前运行的任何操作都不依赖于它们。因此，要生成摘要，我们需要运行所有这些摘要节点。手动管理它们将是一项乏味的工作，因此我们使用<a href="https://www.tensorflow.org/api_docs/python/tf/summary/merge_all" target="_blank" rel="external"><code>tf.summary.merge_all</code></a>将它们组合到一个单独的操作中，生成所有的摘要数据。</p>
<p>然后，您可以运行合并的摘要操作，这将生成一个包含有所有给定步骤的摘要数据的序列化的<code>Summary</code>（摘要）protobuf对象。最后，要将此摘要数据写入磁盘，将摘要protobuf传递给<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>。</p>
<p><code>FileWriter</code>在它的构造函数中接受一个logdir - 这个logdir是非常重要的，它是所有事件将被写出的目标目录。此外，<code>FileWriter</code>可以选择在其构造函数中接受一个<code>Graph</code>。如果它接收到一个<code>Graph</code>对象，那么TensorBoard将与Tensor形状信息一起显示到界面上。这将使您更好地了解通过图形流动的信息：请参阅<a href="https://www.tensorflow.org/get_started/graph_viz#tensor_shape_information" target="_blank" rel="external">Tensor shape信息</a>。</p>
<p>现在，你已经修改好了你的图，并且有了一个<code>FileWriter</code>，并且做好了开始运行网络的准备!如果需要，您可以每一步运行一次摘要合并，并记录大量的训练数据。这可能会产生很多你不需要的数据。所以换一种方式，请考虑每n个步骤运行一次摘要合并操作。</p>
<p>下面的代码示例是一个<a href="https://www.tensorflow.org/get_started/mnist/beginners" target="_blank" rel="external">简单的MNIST教程</a>的修改，其中我们添加了一些摘要操作，并且每十步运行它们一次。如果你运行这个代码，然后启动<code>tensorboard --logdir=/tmp/mnist_logs</code>，你将能够可视化统计，例如权重或精度在训练期间如何变化。下面是部分代码，全部源码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line">def variable_summaries(var):</div><div class="line">  <span class="string">""</span><span class="string">"Attach a lot of summaries to a Tensor (for TensorBoard visualization)."</span><span class="string">""</span></div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'summaries'</span>):</div><div class="line">    mean = <span class="keyword">tf</span>.reduce_mean(var)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'mean'</span>, mean)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'stddev'</span>):</div><div class="line">      stddev = <span class="keyword">tf</span>.<span class="built_in">sqrt</span>(<span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.square(var - mean)))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'stddev'</span>, stddev)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'max'</span>, <span class="keyword">tf</span>.reduce_max(var))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'min'</span>, <span class="keyword">tf</span>.reduce_min(var))</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'histogram'</span>, var)</div><div class="line"></div><div class="line">def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=<span class="keyword">tf</span>.<span class="keyword">nn</span>.relu):</div><div class="line">  <span class="string">""</span><span class="comment">"Reusable code for making a simple neural net layer.</span></div><div class="line"></div><div class="line">  It does <span class="keyword">a</span> matrix multiply, bias <span class="built_in">add</span>, <span class="built_in">and</span> then uses relu <span class="keyword">to</span> nonlinearize.</div><div class="line">  It also sets <span class="keyword">up</span> name scoping <span class="keyword">so</span> that the resultant graph <span class="keyword">is</span> easy <span class="keyword">to</span> <span class="keyword">read</span>,</div><div class="line">  <span class="built_in">and</span> adds <span class="keyword">a</span> <span class="keyword">number</span> of summary ops.</div><div class="line">  <span class="string">""</span><span class="comment">"</span></div><div class="line">  # Adding <span class="keyword">a</span> name scope ensures logical grouping of the layers in the graph.</div><div class="line">  with <span class="keyword">tf</span>.name_scope(layer_name):</div><div class="line">    # This Variable will hold the state of the weights <span class="keyword">for</span> the layer</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'weights'</span>):</div><div class="line">      weights = weight_variable([input_dim, output_dim])</div><div class="line">      variable_summaries(weights)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'biases'</span>):</div><div class="line">      biases = bias_variable([output_dim])</div><div class="line">      variable_summaries(biases)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'Wx_plus_b'</span>):</div><div class="line">      preactivate = <span class="keyword">tf</span>.matmul(input_tensor, weights) + biases</div><div class="line">      <span class="keyword">tf</span>.summary.histogram(<span class="string">'pre_activations'</span>, preactivate)</div><div class="line">    activations = act(preactivate, name=<span class="string">'activation'</span>)</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'activations'</span>, activations)</div><div class="line">    <span class="keyword">return</span> activations</div><div class="line"></div><div class="line">hidden1 = nn_layer(<span class="keyword">x</span>, <span class="number">784</span>, <span class="number">500</span>, <span class="string">'layer1'</span>)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'dropout'</span>):</div><div class="line">  keep_prob = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.float32)</div><div class="line">  <span class="keyword">tf</span>.summary.scalar(<span class="string">'dropout_keep_probability'</span>, keep_prob)</div><div class="line">  dropped = <span class="keyword">tf</span>.<span class="keyword">nn</span>.dropout(hidden1, keep_prob)</div><div class="line"></div><div class="line"># Do not apply softmax activation yet, see below.</div><div class="line"><span class="keyword">y</span> = nn_layer(dropped, <span class="number">500</span>, <span class="number">10</span>, <span class="string">'layer2'</span>, act=<span class="keyword">tf</span>.identity)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'cross_entropy'</span>):</div><div class="line">  # The raw formulation of cross-entropy,</div><div class="line">  #</div><div class="line">  # <span class="keyword">tf</span>.reduce_mean(-<span class="keyword">tf</span>.reduce_sum(y_ * <span class="keyword">tf</span>.<span class="built_in">log</span>(<span class="keyword">tf</span>.softmax(<span class="keyword">y</span>)),</div><div class="line">  #                               reduction_indices=[<span class="number">1</span>]))</div><div class="line">  #</div><div class="line">  # can <span class="keyword">be</span> numerically unstable.</div><div class="line">  #</div><div class="line">  # So here we use <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits <span class="keyword">on</span> the</div><div class="line">  # raw outputs of the nn_layer above, <span class="built_in">and</span> then average across</div><div class="line">  # the batch.</div><div class="line">  diff = <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits(targets=y_, logits=<span class="keyword">y</span>)</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'total'</span>):</div><div class="line">    cross_entropy = <span class="keyword">tf</span>.reduce_mean(diff)</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'cross_entropy'</span>, cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'train'</span>):</div><div class="line">  train_step = <span class="keyword">tf</span>.train.AdamOptimizer(FLAGS.learning_rate).minimize(</div><div class="line">      cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'correct_prediction'</span>):</div><div class="line">    correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(<span class="keyword">y</span>, <span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_, <span class="number">1</span>))</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">    accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div><div class="line"></div><div class="line"># Merge <span class="keyword">all</span> the summaries <span class="built_in">and</span> <span class="keyword">write</span> them out <span class="keyword">to</span> /tmp/mnist_logs (by default)</div><div class="line">merged = <span class="keyword">tf</span>.summary.merge_all()</div><div class="line">train_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/train'</span>,</div><div class="line">                                      sess.graph)</div><div class="line">test_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/test'</span>)</div><div class="line"><span class="keyword">tf</span>.global_variables_initializer().run()</div></pre></td></tr></table></figure>
<p>在我们初始化<code>FileWriter</code>之后，我们在训练和测试模型时，必须向<code>FileWriter</code>添加摘要。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">    train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>现在，你就可以通过TensorBoard来可视化数据了。</p>
<h2 id="启动TensorBoard">启动TensorBoard</h2><p>要运行TensorBoard，请使用以下命令（或者<code>python -m tensorflow.tensorboard</code>）:</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir=path/<span class="keyword">to</span>/<span class="built_in">log</span>-directory</div></pre></td></tr></table></figure>
<p>其中<code>logdir</code>指向<code>FileWriter</code>将其数据序列化的目录。如果此logdir目录包含包含单独运行的序列化数据的子目录，则TensorBoard将可视化所有这些运行的数据。TensorBoard开始运行之后，就可以打开您的Web浏览器到<code>localhost:6006</code>来查看TensorBoard了。</p>
<p>当你看着TensorBoard，你会看到在右上角的导航选项卡。每个选项卡表示可以可视化的一组序列化数据。</p>
<p>有关如何使用图形选项卡可视化图形的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-图的可视化/">TensorBoard：图形可视化</a>。</p>
<p>有关TensorBoard的更多使用信息，请参阅<a href="https://www.tensorflow.org/code/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="url">
                【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-06T22:24:58+08:00" content="2017-03-06">
            2017-03-06
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>本教程将介绍如何在tf.contrib.learn中创建输入函数。您将对如何构造一个用于预处理并将数据反馈到你的模型的<code>input_fn</code>操作有一个大致的了解。然后，您将实现一个<code>input_fn</code>，它将训练，评估和预测数据提供给神经网络回归，并用于预测房屋数据的中位数值。</p>
<h2 id="使用input_fn的自定义输入管道">使用input_fn的自定义输入管道</h2><p>当通过使用tf.contrib.learn来训练一个神经网络时，可以将您的特征和目标数据直接传递到你的<code>fit</code>(拟合)、<code>evaluate</code>(评估)或<code>predict</code>(预测)操作中。下面是从<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门教程</a>中获取的示例：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">training_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TRAINING, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">test_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TEST, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">...</div><div class="line"></div><div class="line">classifier.fit(x=training_set<span class="selector-class">.data</span>,</div><div class="line">               y=training_set<span class="selector-class">.target</span>,</div><div class="line">               steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>这种数据量不大的情况下，我们即使不处理数据源，也可好获得良好的效果。但是在需要更多特征工程的情况下，<code>tf.contrib.learn</code>支持使用自定义输入函数（<code>input_fn</code>），它可以将预处理和管道数据的逻辑封装到模型中。</p>
<h3 id="input_fn的剖析">input_fn的剖析</h3><p>以下代码说明了输入函数的基本框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_fn</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># Preprocess your data here...</span></div><div class="line"></div><div class="line">    <span class="comment"># ...then return 1) a mapping of feature columns to Tensors with</span></div><div class="line">    <span class="comment"># the corresponding feature data, and 2) a Tensor containing labels</span></div><div class="line">    <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>输入函数的主体包含用于预处理输入数据的特定逻辑，例如<strong>擦除不良样本</strong>或<strong><a href="https://en.wikipedia.org/wiki/Feature_scaling" target="_blank" rel="external">特征缩放</a></strong>。</p>
<p>输入函数必须返回以下两个值，这两个值包含要输入到模型中的最终特征和标签数据（如上面的代码框架中所示）：</p>
<p><code>feature_cols</code></p>
<pre><code>包含将特征列名称映射到包含相应特征数据的<span class="escape">`T</span>ensor<span class="escape">`（</span>或<span class="escape">`S</span>parseTensor<span class="escape">`）</span>的键/值对的字典。
</code></pre><p><code>labels</code></p>
<pre><code>包含您的标签（目标）值的<span class="escape">`T</span>ensor<span class="escape">`：</span>你的模型的值的目的是用于预测。
</code></pre><h3 id="将特征数据转换为Tensor">将特征数据转换为Tensor</h3><p>如果你的特征/标签数据储存在<a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a>数据帧中或<a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a>数组中，那么你需要将其转换为<code>Tensor</code>，然后从您的<code>input_fn</code>中返回它。</p>
<p>对于连续数据，可以使用<code>tf.constant</code>创建和填充<code>Tensor</code>：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_column_data = [<span class="number">1</span>, <span class="number">2.4</span>, <span class="number">0</span>, <span class="number">9.9</span>, <span class="number">3</span>, <span class="number">120</span>]</div><div class="line">feature_tensor = tf.constant(feature_column_data)</div></pre></td></tr></table></figure>
<p>对于<a href="https://en.wikipedia.org/wiki/Sparse_matrix" target="_blank" rel="external">稀疏分类数据</a>（大多数值为0的数据），您应该替换为填充一个<code>SparseTensor</code>，它使用三个参数来实例化：</p>
<p><code>dense_shape</code></p>
<pre><code>tensor的形状。获取一个列表，指示每个维度中元素的数量。例如：`dense_shape=[<span class="number">3</span>,<span class="number">6</span>]`指定了一个二维的<span class="number">3</span>x6的tensor，`dense_shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]`指定了一个三维的<span class="number">2</span>x3x4的tensor，`dense_shape=[<span class="number">9</span>]`指定了一个拥有<span class="number">9</span>个元素的一维tensor。
</code></pre><p><code>indices</code></p>
<pre><code>您的tensor中包含非零元素的索引。值为一个列表，其中每一项本身是包含非零元素的索引的列表。（元素是零索引的 - 即，`[<span class="number">0</span>,<span class="number">0</span>]`是二维张量中第一行的第一列中的元素的索引值）。例如：`indices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]`指定了索引为`[<span class="number">1</span>,<span class="number">3</span>]`和`[<span class="number">2</span>,<span class="number">4</span>]`的元素具有非零值。
</code></pre><p><code>values</code></p>
<pre><code>值为一维tensor。<span class="escape">`v</span>alues<span class="escape">`的</span>项<span class="escape">`i</span><span class="escape">`对</span>应于<span class="escape">`i</span>ndices<span class="escape">`中</span>的项<span class="escape">`i</span><span class="escape">`，</span>并且指定了它的值。例如，给定了<span class="escape">`i</span>ndices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]<span class="escape">`，</span>那么参数<span class="escape">`v</span>alues=[<span class="number">18</span>, <span class="number">3.6</span>]<span class="escape">`就</span>指定了tensor的元素<span class="escape">`[</span><span class="number">1</span>,<span class="number">3</span>]<span class="escape">`的</span>值为<span class="number">18</span>，元素<span class="escape">`[</span><span class="number">2</span>,<span class="number">4</span>]<span class="escape">`的</span>值为<span class="number">3.6</span>。
</code></pre><p>以下代码定义了一个具有3行和5列的二维<code>SparseTensor</code>。具有索引<code>[0,1]</code>的元素的值为6，并且索引为<code>[2,4]</code>的元素值为0.5（所有其他值为0）：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sparse_tensor = tf.SparseTensor(indices=[[<span class="number">0</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">4</span>]],</div><div class="line">                                values=[<span class="number">6</span>, <span class="number">0.5</span>],</div><div class="line">                                dense_shape=[<span class="number">3</span>, <span class="number">5</span>])</div></pre></td></tr></table></figure>
<p>这对应了下面的稠密tensor(dense tensor)：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[[<span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.5</span>]]</div></pre></td></tr></table></figure>
<p>更多关于<code>SparseTensor</code>的内容，请见<a href="https://www.tensorflow.org/api_docs/python/tf/SparseTensor" target="_blank" rel="external"><code>tf.SparseTensor</code></a></p>
<h3 id="将input_fn数据传递给您的模型">将input_fn数据传递给您的模型</h3><p>要将数据馈送到您的模型进行训练，您只需将创建的输入函数作为<code>input_fn</code>参数的值传递到<code>fit</code>运算即可，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn,</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>请注意，<code>input_fn</code>负责将特征和标签数据提供给模型，并在<code>fit</code>(拟合)中替换<code>x</code>和<code>y</code>参数。如果为<code>fit</code>提供了一个不为空的<code>input_fn</code>值与不为<code>None</code>的<code>x</code>或<code>y</code>结合，它将抛出一个<code>ValueError</code>。</p>
<p>还要注意一点，<code>input_fn</code>参数必须接收一个函数对象（例如<code>input_fn = my_input_fn</code>），而不是函数调用的返回值（<code>input_fn = my_input_fn()</code>）。这意味着，如果您尝试在<code>fit</code>的调用中按照下面的方式，将参数传递给输入函数，则会导致TypeError：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn(training_set),</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>但是，如果你想要参数化你的输入函数，有一些其他的方法可以做到。您可以使用不带参数的包装函数作为<code>input_fn</code>，并使用它来调用具有所需参数的输入函数。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_function_training_set</span><span class="params">()</span>:</span></div><div class="line">  <span class="keyword">return</span> my_input_function(training_set)</div><div class="line"></div><div class="line">classifier.fit(input_fn=my_input_fn_training_set, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>或者，你可以使用Python的<a href="https://docs.python.org/2/library/functools.html#functools.partial" target="_blank" rel="external"><code>functools.partial</code></a>方法来构造一个新的所有参数值固定的方法对象：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">classifier.fit(input_fn=functools.partial(my_input_<span class="keyword">function</span>,</div><div class="line">                                          data_<span class="built_in">set</span>=training_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>第三种方式是将<code>input_fn</code>调用包装在<a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" target="_blank" rel="external"><code>lambda</code></a>中，并将其传递给<code>input_fn</code>参数：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: my_input_fn(training_set), steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>构建您的输入管道的一个很大的优势如上所示 – 可以接受数据集的参数 – 是你只需修改数据集的参数，就可以传递相同的<code>input_fn</code>到<code>evaluate</code>和<code>predict</code>操作上。例如：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.evaluate(input_fn=lambda: my_input_fn(<span class="built_in">test</span>_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>这种方法增强了代码的可维护性：不需要针对每种类型的操作捕获单独变量（例如，<code>x_train</code>，<code>x_test</code>，<code>y_train</code>，<code>y_test</code>）中的<code>x</code>和<code>y</code>值。</p>
<h3 id="一个用于波士顿房屋数据的神经网络">一个用于波士顿房屋数据的神经网络</h3><p>在本教程的剩余部分，您将编写一个输入函数，用于预处理从<a href="https://archive.ics.uci.edu/ml/datasets/Housing" target="_blank" rel="external">UCI住宅数据集</a>中提取的一组波士顿房屋数据，并使用它来将数据馈送到神经网络回归器，以预测房屋中值。</p>
<p>您将用于训练神经网络的<a href="https://www.tensorflow.org/get_started/input_fn#setup" target="_blank" rel="external">波士顿CSV数据集</a>包含以下波士顿郊区的<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names" target="_blank" rel="external">特征数据</a>：</p>
<table>
<thead>
<tr>
<th style="text-align:left">特征</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CRIM</td>
<td style="text-align:left">人均犯罪率</td>
</tr>
<tr>
<td style="text-align:left">ZN</td>
<td style="text-align:left">超过25,000+平方呎地段的住宅用地的部分</td>
</tr>
<tr>
<td style="text-align:left">INDUS</td>
<td style="text-align:left">非零售业的土地部分</td>
</tr>
<tr>
<td style="text-align:left">NOX</td>
<td style="text-align:left">一氧化氮浓度 以百万分之一为单位</td>
</tr>
<tr>
<td style="text-align:left">RM</td>
<td style="text-align:left">每个住宅平均房间数</td>
</tr>
<tr>
<td style="text-align:left">AGE</td>
<td style="text-align:left">在1940年之前建造的自用住宅的部分</td>
</tr>
<tr>
<td style="text-align:left">DIS</td>
<td style="text-align:left">到波士顿地区就业中心的距离</td>
</tr>
<tr>
<td style="text-align:left">TAX</td>
<td style="text-align:left">每$10,000的房产税税率</td>
</tr>
<tr>
<td style="text-align:left">PTRATIO</td>
<td style="text-align:left">学生 - 教师比例</td>
</tr>
</tbody>
</table>
<p>你的模型预测的标签是MEDV，自用住宅的价格中值，以千美元计。</p>
<h2 id="构建">构建</h2><p>下载以下数据集：<a href="http://download.tensorflow.org/data/boston_train.csv" target="_blank" rel="external">boston_train.csv</a>, <a href="http://download.tensorflow.org/data/boston_test.csv" target="_blank" rel="external">boston_test.csv</a>, 和 <a href="http://download.tensorflow.org/data/boston_predict.csv" target="_blank" rel="external">boston_predict.csv</a>。</p>
<p>以下部分提供了如何创建输入函数的手把手的步骤，将这些数据集送入神经网络回归，训练和评估模型，并进行房屋价值预测。完整的最终代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/input_fn/boston.py" target="_blank" rel="external">这里</a>。</p>
<h3 id="输入房屋数据">输入房屋数据</h3><p>要开始，请设置导入所需的库（包括<code>pandas</code>和<code>tensorflow</code>），并将<a href="https://www.tensorflow.org/get_started/monitors#enabling_logging_with_tensorflow" target="_blank" rel="external">日志级别设置</a>为<code>INFO</code>以获取更详细的日志输出：</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="title">tf</span>.logging.set_verbosity(tf.logging.<span class="type">INFO</span>)</div></pre></td></tr></table></figure>
<p>在<code>COLUMNS</code>中定义数据集的列名称。要区分特征和标签，还需要定义<code>FEATURES</code>和<code>LABEL</code>。然后将三个CSV（<code>tf.train</code>，<code>tf.test</code>和<code>predict</code>）读入pandas <code>DataFrame</code>s：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="attr">COLUMNS</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>, <span class="string">"age"</span>,</div><div class="line">           <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>, <span class="string">"medv"</span>]</div><div class="line"><span class="attr">FEATURES</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>,</div><div class="line">            <span class="string">"age"</span>, <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>]</div><div class="line"><span class="attr">LABEL</span> = <span class="string">"medv"</span></div><div class="line"></div><div class="line"><span class="attr">training_set</span> = pd.read_csv(<span class="string">"boston_train.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                           <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">test_set</span> = pd.read_csv(<span class="string">"boston_test.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                       <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">prediction_set</span> = pd.read_csv(<span class="string">"boston_predict.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                             <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div></pre></td></tr></table></figure>
<h3 id="定义特征列并创建回归">定义特征列并创建回归</h3><p>接下来，为输入数据创建<code>FeatureColumn</code>list，正式指定要用于训练的特征集。由于房屋数据集中的所有特征都包含连续的值，因此可以使用<code>tf.contrib.layers.real_valued_column()</code>函数创建其<code>FeatureColumn</code>s：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_cols = [tf<span class="selector-class">.contrib</span><span class="selector-class">.layers</span><span class="selector-class">.real_valued_column</span>(k)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</div></pre></td></tr></table></figure>
<p>注意：有关特征列的更深入的内容，请参阅此<a href="https://www.tensorflow.org/tutorials/linear#feature_columns_and_transformations" target="_blank" rel="external">简介</a>，以及说明如何为分类数据定义<code>FeatureColumns</code>的示例，请参阅线<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">性模型教程</a>。</p>
<p>现在，为神经网络回归模型实例化一个<code>DNNRegressor</code>。这里你需要提供两个参数：<code>hidden_units</code>，指定每个隐藏层中的节点数量的超参数(hyperparameter)（这里，有两个隐藏层，每个隐藏层都具有10个节点），以及<code>feature_columns</code>，包含您刚定义的<code>FeatureColumns</code>list：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">regressor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.DNNRegressor</span>(feature_columns=feature_cols,</div><div class="line">                                          hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</div><div class="line">                                          model_dir=<span class="string">"/tmp/boston_model"</span>)</div></pre></td></tr></table></figure>
<h3 id="构建input_fn">构建input_fn</h3><p>要将输入数据传递到<code>regressor</code>，请创建一个输入函数，它将接受一个pandas <code>Dataframe</code>并返回特征列和标签值作为<code>Tensor</code>s：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_set)</span>:</span></div><div class="line">  feature_cols = &#123;k: tf.constant(data_set[k].values)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;</div><div class="line">  labels = tf.constant(data_set[LABEL].values)</div><div class="line">  <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>请注意，输入数据被传递到<code>data_set</code>参数中的<code>input_fn</code>中，这意味着该函数可以处理您导入的任何<code>DataFrames</code>：<code>training_set</code>，<code>test_set</code>和<code>prediction_set</code>。</p>
<h3 id="训练回归">训练回归</h3><p>要训​​练神经网络回归，运行指定了包含有<code>training_set</code>的<code>input_fn</code>的<code>fit</code>函数，如下：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">regressor<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: input_fn(training_set), steps=<span class="number">5000</span>)</div></pre></td></tr></table></figure>
<p>您应该能看到类似于以下内容的日志输出，它会报告每100步的训练loss值：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1</span>: loss = <span class="number">483.179</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">101</span>: loss = <span class="number">81.2072</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">201</span>: loss = <span class="number">72.4354</span></div><div class="line">...</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1801</span>: loss = <span class="number">33.4454</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1901</span>: loss = <span class="number">32.3397</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">2001</span>: loss = <span class="number">32.0053</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4801</span>: loss = <span class="number">27.2791</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4901</span>: loss = <span class="number">27.2251</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving checkpoints <span class="keyword">for</span> <span class="number">5000</span> into <span class="regexp">/tmp/</span>boston_model/model.ckpt.</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Loss <span class="keyword">for</span> <span class="keyword">final</span> <span class="string">step:</span> <span class="number">27.1674</span>.</div></pre></td></tr></table></figure>
<h3 id="评估模型">评估模型</h3><p>接下来，看看训练模型如何针对测试数据集执行。运行<code>evaluate</code>，这次将<code>test_set</code>传递给<code>input_fn</code>：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">ev</span> = regressor.evaluate(<span class="attr">input_fn=lambda:</span> input_fn(test_set), <span class="attr">steps=1)</span></div></pre></td></tr></table></figure>
<p>从<code>ev</code>的结果中检索损失并将其打印到输出：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">loss_score = ev[<span class="string">"loss"</span>]</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"Loss: &#123;0:f&#125;"</span>.format(loss_score)</span></span>)</div></pre></td></tr></table></figure>
<p>您应该会看到类似以下的结果：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Eval steps [<span class="number">0</span>,<span class="number">1</span>) <span class="keyword">for</span> training step <span class="number">5000.</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving evaluation summary <span class="keyword">for</span> <span class="number">5000</span> <span class="string">step:</span> loss = <span class="number">11.9221</span></div><div class="line"><span class="string">Loss:</span> <span class="number">11.922098</span></div></pre></td></tr></table></figure>
<h3 id="进行预测">进行预测</h3><p>最后，您可以使用模型预测<code>prediction_set</code>中的房屋中值，其中包含特征数据，但没有六个样本的标签：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">y = regressor.<span class="keyword">predict</span>(input_fn=lambda: input_fn(prediction_set))</div><div class="line"># .<span class="keyword">predict</span>() returns <span class="keyword">an</span> iterator; convert to a <span class="keyword">list</span> and <span class="keyword">print</span> predictions</div><div class="line">predictions = <span class="keyword">list</span>(itertools.islice(y, 6))</div><div class="line"><span class="keyword">print</span> (<span class="string">"Predictions: &#123;&#125;"</span>.<span class="keyword">format</span>(str(predictions)))</div></pre></td></tr></table></figure>
<p>您的结果应包含以 $1000 计的六次房价预测，例如：</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Predictions: [ <span class="number">33.30348587</span>  <span class="number">17.04452896</span>  <span class="number">22.56370163</span>  <span class="number">34.74345398</span>  <span class="number">14.55953979</span></div><div class="line">  <span class="number">19.58005714</span>]</div></pre></td></tr></table></figure>
<h2 id="其他资源">其他资源</h2><p>本教程专注于为神经网络回归创建一个<code>input_fn</code>。要了解更多有关对其他类型模型使用<code>input_fn</code>的信息，请查看以下资源：</p>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="external">TensorFlow的大尺寸线性模型</a>：这种对TensorFlow中的线性模型的介绍提供了用于变换输入数据的特征列和技术的高级概述。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>：本教程包括为线性分类模型创建<code>FeatureColumn</code>s和<code>input_fn</code>，该模型根据人口普查数据预测收入范围。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="external">TensorFlow宽＆深学习教程</a>：基于<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>，本教程涵盖了使用<code>DNNLinearCombinedClassifier</code>组合线性模型和神经网络的“宽和深”模型的<code>FeatureColumn</code>和<code>input_fn</code>创建。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/05/关于机器学习的一些思考/" itemprop="url">
                关于机器学习的一些思考
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-05T16:40:58+08:00" content="2017-03-05">
            2017-03-05
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/05/关于机器学习的一些思考/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/05/关于机器学习的一些思考/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>我大概是在两年前开始正式关注机器学习领域的，当时一心想做一个基于机器学习的五子棋程序，希望能达到机器自动理解五子棋游戏规则的效果，但没能成功，于是我开始找一些机器学习领域的课程和书籍开始啃。</p>
<p>当时机器学习在国内还是一个很少听到的名词，但当我学习这方面的东西的时候，我深深的感受到这个领域的东西和我之前学到的技术不是一个维度的东西，并且它将深远的影响未来的发展。直到后来AlphaGo的出现，以及Google开源了TensorFlow，这一系列的大事件的发生，悄然在业内刮起了一股人工智能风。</p>
<p>TensorFlow在开源之初，国内的<strong>极客学院</strong>发起了文档的翻译工作，还记的在其翻译文档的首页这样写到：</p>
<blockquote>
<p>你正在阅读的项目可能会比 Android 系统更加深远地影响着世界！</p>
</blockquote>
<p>不管这句话说得是否过于夸大，但TensorFlow在github上开源一个月之内就收到了10000+的star，这是github上机器学习领域也是python领域star增长最快的项目了。截止目前，TensorFlow的star为49227，已经超过了linux的42490。可见，机器学习的发展速度之迅猛，是不容小视的。</p>
<p>本文是我对机器学习领域的一些见解和思考，主要涉及<strong>机器学习的定义</strong>，<strong>机器学习的学习方式</strong>以及<strong>相关概念的理解</strong>。你会看到很多教科书上看不到的解读，虽然不是很严谨，但有助于你对一些概念建立起直觉上的理解，从而帮助你更好的了解这一领域的知识。</p>
<h2 id="思考1：机器学习是什么">思考1：机器学习是什么</h2><h3 id="机器学习定义">机器学习定义</h3><blockquote>
<p>机器学习(Machine Learning, ML)是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。</p>
</blockquote>
<p>这是百度百科给出的定义，更加通俗的解释一下，机器学习是人工智能领域下的子领域，通过对大量现有数据的分析运算来对未知数据进行预测的一种学科。（虽然说法不严谨，但这种解释有助于理解）</p>
<p>将机器学习的通用模型类比于养一个小孩：</p>
<ul>
<li>训练过程就像是养一个小孩子</li>
<li>如果小孩子小的时候接触到了正确的教育（这里正确的教育就是<strong>训练数据集</strong>）</li>
<li>如果小孩子本身的悟性很高（悟性很高类比于有很好的<strong>学习算法</strong>）</li>
<li>那么这个孩子经过一段时间的成长学习后（类比于机器学习的<strong>训练</strong>阶段）</li>
<li>会成为一个有用之才（得到和很好的<strong>假设函数</strong>，即训练模型）</li>
<li>当他遇到新的人和事的时候（接受<strong>测试数据</strong>）</li>
<li>就能够处理的很好（<strong>预测结果</strong>）</li>
</ul>
<p>这就是机器学习的通用模型，虽然不是严谨的学术定义，但相信这能使你建立一种直觉上的认识。</p>
<h3 id="这是一项新技术吗？">这是一项新技术吗？</h3><p>机器学习目前处于学术界迈向工业界的一个过程，其核心算法几十年前就有了，理念也绝非新鲜事物，达到工业级别是一个时间问题，而现在<strong>我们就处在这一学术界迈向工业界的关键阶段</strong>。</p>
<p>其实，机器学习的核心概念早在第一台计算机制造之前就已经产生了。这里也不做过多介绍，大家可以自行去搜索。</p>
<h2 id="思考2：如何学习机器学习">思考2：如何学习机器学习</h2><h3 id="学习框架_or_学习算法?">学习框架 or 学习算法?</h3><p>完全没有学过这一领域的东西，是否应该直接上手TensorFlow之类的框架呢？</p>
<p>框架只是工具，不管是TensorFlow还是Caffe还是Torch，都是对算法的封装，很多之前做其他方面开发的程序员，在接触一个框架或者工具时，都倾向于追求能达到“直接去调用一下就得到结果”这样的效果，但机器学习领域的框架并不是如此，它要求你对机器学习领域的算法有一定了解，要明白自己在做什么。</p>
<p>所以先对这个领域的算法知识有个掌握之后，再去学习和使用框架来实践操作可能是效率更高的一种学习模式。相反，直接上手来学习框架，期望直接调用一些API就得出结果的想法会让你有种寸步难行的感觉。</p>
<p>这里安利一下<a href="https://www.coursera.org/" target="_blank" rel="external">coursera</a>上的吴恩达老师的<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">机器学习</a>课程（可能会需要翻墙才能访问，自行购买vpn）。这门课深入浅出的讲解了机器学习领域的流行的算法的实现原理。</p>
<blockquote>
<p>介绍一下吴恩达老师，在最强大脑第四季开播之前，可能知道他的人很少。吴恩达是华裔美国人，是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任，是Coursera的联合创始人。之前是google负责google大脑项目，后来在14年5月16日加入百度，担任百度首席科学家，负责百度研究院的领导工作，尤其是Baidu Brain计划。这是中国互联网公司迄今为止引进的最重量级人物。</p>
</blockquote>
<h3 id="深入底层_or_关注上层？">深入底层 or 关注上层？</h3><p>在技术领域一直流传着这样一种理念：底层的就是牛X的。上层技术变化无常，但底层技术万变不离其宗。再加上底层技术的学习成本远高于上层技术，而且吃透了底层技术能够对上层技术有更深刻的理解，导致程序员对底层技术有一种神圣的向往情节。</p>
<p>技术领域，专注细节不是坏事，但对于机器学习这个领域呢？恐怕我们需要重新考量一下这种思维模式了。</p>
<p>其实在机器学习领域，也是提倡对底层实现算法有一定的了解的，但并不代表我们要去亲自实现一些算法，比如神经网络中的反向传播算法的实现，很多框架都已经写的很完善了，而且都是数值计算领域的专家来实现的高质量高性能的代码，我们没必要花时间和精力来重新造轮子，也没必要去研究他们是如何造的这个轮子。我们更应该把宝贵的时间留在理解这些算法的原理上，以及学会使用这些算法来应用到实际中的问题，这才是把好钢用到了刀刃上。</p>
<p>实际上，正确的学习方式是，首先学习并理解算法原理，在直觉层面建立起对算法的认识，然后快速动手实践，将学到的算法应用到小项目里，不用太过在意写的东西是不是很挫，重要的是开始写！然后再不断的完善你的项目。带着一些问题去继续学习，你会有更多的收获。</p>
<h3 id="不要想太多有的没的">不要想太多有的没的</h3><p>可能很多人跟我一样，刚开始了解这一领域的东西的时候，很是兴奋，感觉造出一个通用人工智能指日可待了。再加上近些年随着人工智能概念的兴起，出来了一批相关影视作品和科幻小说，更让我们对人工智能产生了一系列不切实际的想法。</p>
<p>对于这一点，我想说明的是，不要过分执迷于AI能创建出智能大脑的想法，除非你是业内出类拔萃的专家。科幻小说与电影只是一种艺术表现手法，并不代表着未来。通常，人们看不懂看不透的地方就容易形成骗局，通用智能虽然是人工智能一直以来在追求的一个目标，但目前主流学术发展方向并没有朝着这方面走。机器学习、深度学习的确在飞速的进步，未来也会波及到很多行业，但这个学科归根结底还是一门基于数据的学科，并没有达到拥有情感、独立思考等这方面的能力，实际上，绝大多数业内专家对这方面的想法是持有厌恶态度的，倒是相关的社科类软文在这个时代被吹上了天。</p>
<p>因此，与其花时间想这些有的没的，还不如花时间脚踏实地的去学习一下算法、写写代码，除非你想成为一个科幻小说作家。</p>
<h2 id="思考3：机器学习中一些概念的解读">思考3：机器学习中一些概念的解读</h2><p>机器学习领域中有很多很有趣、很耐人寻味的原理值得细细品味，下面是我对其中部分概念的直觉上的理解，可能你在教科书或者教学视频上看不到这种解读，但这些概念所折射出来的现象也许就是我所描述的那样。当然，如果你没有看过这个领域，甚至没有写过代码也没关系，我保证能让你能读得懂。</p>
<h3 id="神经网络">神经网络</h3><p><strong>神经网络</strong>是机器学习领域出镜率很高的一个词汇，很多人对它的理解一直是停留在“<strong>很牛X，很复杂</strong>”的状态。下面用一个例子来解释神经网络的使用原理：</p>
<p>假设你有一个下周六是否要去电影院看电影的决定。这个决定的结果无非只有两种：<strong>去</strong>或者<strong>不去</strong>。</p>
<p>影响你去或不去的因素有很多：</p>
<ul>
<li>是否有人陪</li>
<li>是否有想看的电影</li>
<li>是否有时间</li>
<li>天气是否足够好</li>
<li>…</li>
</ul>
<p>我相信你可以列出足够多的理由来拒绝周末去看电影，但为了方便描述起见，我们先用三个条件：<strong>是否有人陪</strong>、<strong>是否有想看的电影</strong>、<strong>是否有时间</strong>。</p>
<p>好，现在我们来用三个圈来表示这三个条件。</p>
<p><img src="/img/17_03_05/002.png" alt=""></p>
<p>圆圈中间的数值代表对做出去看电影的决策的影响程度，可以看到这里<strong>是否有时间</strong>的影响程度是最大的（这里的每个小圈，其实就是神经网络中的<strong>神经元</strong>，上面的数值就是<strong>权值</strong>）。</p>
<p>我们接下来把我们的神经网络补充完整：</p>
<p><img src="/img/17_03_05/003.png" alt=""></p>
<p>我们又加了两个圈和一些箭头。好，对应图中，如果我们现在<strong>有想看的电影，可是没有人陪，但有时间</strong>，那么我们的计算方式就是:</p>
<p><img src="/img/17_03_05/004.png" alt=""></p>
<p>$$<br>(-1)×0.3 + 1×0.6 + 1×1.0 = 1.3<br>$$</p>
<p>输出结果是一个大于0的值：1.3，代表我们会做出去看电影的决定。</p>
<p>类似的，假如我们<strong>有人陪，有想看的电影，但是没时间</strong>：</p>
<p>$$<br>1×0.3 + 1×0.6 + (-1)×1.0 = -0.1<br>$$</p>
<p>是一个负数，代表我们不会去看电影。</p>
<p>这就是一个训练好的神经网络的使用方式，这幅图就是一个典型的三层神经网络，从左到右依次是<strong>输出层</strong>、<strong>隐藏层</strong>、<strong>输出层</strong>，其中0.3，0.6，1.0是通过<strong>训练</strong>得出的<strong>权值</strong>。</p>
<p><img src="/img/17_03_05/005.png" alt=""></p>
<p>我相信你对神经网络还是有很多疑问，比如0.3，0.6和1.0是怎么得来的（实际上是通过<strong>反向传播算法</strong>得来的），但神经网络运作的大体模式就是这样，希望你能对它产生一种宏观层面的认识。</p>
<h3 id="偏拟合_和_过拟合">偏拟合 和 过拟合</h3><p><strong>偏拟合</strong>和<strong>过拟合</strong>具体是什么意思呢？不要被陌生的名词吓到。</p>
<p>首先要说明的是，这两个词都不是褒义词，都是我们不想看到的一种状态。</p>
<p>其实所谓<strong>偏拟合</strong>就是相当于某一领域经验不足的人，由于经历的事情太少，容易做出一些错误的判断，这种现象就是<strong>偏拟合</strong>。</p>
<p>所谓<strong>过拟合</strong>，恰恰相反，是指某一领域经验非常丰富的人，由于经历的事情太多，反而容易对新的事物产生偏见（因为既往的经验会告诉他这是不对的），从而产生错误的决定。</p>
<p>教科书上不会这么解释<strong>偏拟合</strong>和<strong>过拟合</strong>的概念，但事实上这个概念描述的就是这样的现象。是不是我们身边随处可见这两种现象呢？</p>
<h3 id="查准率_和_召回率">查准率 和 召回率</h3><p>假设我们现在写了个用于预测病人是否患有肺癌的程序，我们出入了100个病人的体征数据，然后来告知这一批病人有谁不幸得了肺癌。</p>
<p>假设我们的预测准确率为98%，这个结果乍一看是不是很高呢？但我告诉你另一个事实，那就是我们只有两个病人是真正患有肺癌的，然而我们的算法正确的识别了两者中的一位，并且还错误的认为在98名没有患有肺癌的患者里有一位癌症患者。那这还是一个好结果吗？</p>
<p>很明显，100个人里只有两个人患有癌症，其中一个还预测错误，这是一个很差的结果，但我们的准确率为98%，因为我们预测对了100个人中的98个人，所以从准确率上来看并不差，但实际结果却很差。</p>
<p>这就是典型的<strong>偏斜类</strong>问题。</p>
<p>也许有人会说，这表明了数据会说谎，但实际情况是，数据并没有说谎，只不过我们看待数据的方式不够科学。</p>
<p>科学的方式就是引入<strong>查准率</strong>和<strong>召回率</strong>。</p>
<p>在这里:</p>
<p>$$<br>查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量}<br>$$</p>
<p>$$<br>召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量}<br>$$</p>
<p>可见，<strong>查准率</strong>和<strong>召回率</strong>都是越高越好的。</p>
<p>那么我们的例子中<strong>查准率</strong>和<strong>召回率</strong>的真实值分别为：</p>
<p>$$<br>查准率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {预测患有肺癌的病人数量} = \frac{1} {2} = 0.5<br>$$</p>
<p>$$<br>召回率 = \frac{在预测患有肺癌的病人中，预测正确的数量} {实际患有肺癌病人的数量} = \frac{1} {2} = 0.5<br>$$</p>
<p>我们的查准率和召回率都很低。所以换个角度来看待数据，会有新的发现。</p>
<p>查准率和召回率是两个维度的数据，有的时候我们为了追求高查准率，会得到一个低召回率的结果；有的时候我们为了追求高召回率，却会得到一个低查准率的结果。这种顾此失彼的状态，也不是我们想要。</p>
<p>所以我们引入了一个叫做<strong>Fscore</strong>的方法来对两种进行一个整体的衡量，其表达式为：</p>
<p>$$<br>Fscore = \frac{查准率×召回率} {查准率+召回率}<br>$$</p>
<p>这里我们的$Fscore=0.25$。</p>
<p>我们生活中也处处充满着<strong>准确率高但查准率和召回率低的例子</strong>：</p>
<p>我们往往会有这种体验，一些成功的名人说的话似乎都很有道理，但其实他们说的有道理的话似乎都比较“大”；而有些人，专注于某一特定领域的专家，在发表一些观点的时候，用词都非常谨慎，因为他们在描述一件具体的事物。</p>
<p>所以，我们会发现，<strong>越“大”的话，越容易获得较高的准确率；越“专”的话，越不容易获得较高的准确率</strong>。</p>
<p>所以带着这种角度，我们去审视一下：</p>
<ul>
<li>失败是成功之母。</li>
<li>天才是99%的汗水加1%的灵感。</li>
<li>…</li>
</ul>
<p>类似这类的<strong>鸡汤名言</strong>，我们会有新的思考。我们会发现，真正的牛人说的话，不仅仅准确率高，而且查准率和召回率也很高。</p>
<h3 id="无监督学习">无监督学习</h3><p><strong>无监督学习</strong>是相对于<strong>监督学习</strong>而言的。那么什么是<strong>监督学习</strong>呢？</p>
<p><strong>监督学习</strong>通俗的将就是我们告诉机器一堆格式为：</p>
<p><strong>bulabulabula的东西，是xxx</strong></p>
<p>来预测未知类别的数据：</p>
<p><strong>bulabulabula的东西，是？</strong></p>
<p>例如通过体征来预测性别：</p>
<p>已有100个数据：</p>
<ul>
<li>身高175cm，短发，70kg的人是男性</li>
<li>身高165cm，长发，48kg的人是女性</li>
<li>…</li>
</ul>
<p>那么：</p>
<ul>
<li>身高170cm，长发，55kg的人是？</li>
</ul>
<p>这种预测类别已知的机器学习，就是<strong>监督学习</strong>。典型的<strong>监督学习</strong>的案例有<strong>语音识别</strong>、<strong>图像识别</strong>、<strong>人脸识别</strong>等等。</p>
<p>所谓<strong>无监督学习</strong>就是我们并不能知道数据所属的类别，通过算法使数据自动地按照相似的类别聚合起来，即所谓的<strong>聚类算法</strong>。</p>
<p>我们俗话所说的<strong>物以类聚，人以群分</strong>就是无监督学习的体现。</p>
<p>其实，仔细想想，人类社会的发展演化过程，是不是就是一个大型的<strong>无监督学习</strong>的过程呢？我们都是这个学习过程中的一环，是这个大型的神经网络中的一个神经元，我们社会的发展形态和目标在各个阶段都是不一样的，即使我们无法过远地预测到未来进化的方向，但我们一直在自我学习的过程中不断进化。也许这正是生命的本质。</p>
<hr>
<p>以上观点可能不是很严谨，也不是正统的机器学习理论，是本人对机器学习的一些思考。如有概念上的错误，欢迎斧正。也欢迎在评论区和我一起讨论<strong>机器学习</strong>的相关问题。</p>
<p>非常感谢您能读完我的文章，最后安利一下我的一个实验项目<a href="http://118.190.96.169:3389/iw/help/" target="_blank" rel="external">智能背词算法</a>，目前处于数据采集阶段，具体使用方式见帮助页面。谢谢~</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/05/【Tensorflow r1.0 文档翻译】【tf.contrib.learn快速入门】/" itemprop="url">
                【Tensorflow r1.0 文档翻译】【tf.contrib.learn快速入门】
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-05T15:19:58+08:00" content="2017-03-05">
            2017-03-05
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/05/【Tensorflow r1.0 文档翻译】【tf.contrib.learn快速入门】/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/05/【Tensorflow r1.0 文档翻译】【tf.contrib.learn快速入门】/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>TensorFlow的高级机器学习API(tf.contrib.learn)使得各种机器学习模型的配置、训练和评估都变得简单。在本教程中，你将使用tf.contrib.learn来构建一个<a href="https://en.wikipedia.org/wiki/Artificial_neural_network" target="_blank" rel="external">神经网络</a>分类器，并且在<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set" target="_blank" rel="external">Iris数据集</a>上进行训练，以达到通过萼片/花瓣几何来预测花的种类。您将编写代码以执行以下五个步骤：</p>
<ul>
<li>1.加载格包含Iris的训练和测试数据的CSV到TensorFlow数据集中。</li>
<li>2.构建一个<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier" target="_blank" rel="external">神经网络分类器</a>。</li>
<li>3.使用训练数据拟合模型</li>
<li>4.评估模型的准确性</li>
<li>5.分类新样品</li>
</ul>
<blockquote>
<p><strong>注意：</strong>在开始本教程之前，请确认在你的机器上已经<a href="https://www.tensorflow.org/install/index" target="_blank" rel="external">安装了TensorFlow</a>。</p>
</blockquote>
<h2 id="完整的神经网络源代码">完整的神经网络源代码</h2><p>这里是神经网络分类器的完整代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># Data sets</span></div><div class="line">IRIS_TRAINING = <span class="string">"iris_training.csv"</span></div><div class="line">IRIS_TEST = <span class="string">"iris_test.csv"</span></div><div class="line"></div><div class="line"><span class="comment"># Load datasets.</span></div><div class="line">training_set = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">    filename=IRIS_TRAINING,</div><div class="line">    target_dtype=np.int,</div><div class="line">    features_dtype=np.float32)</div><div class="line">test_set = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">    filename=IRIS_TEST,</div><div class="line">    target_dtype=np.int,</div><div class="line">    features_dtype=np.float32)</div><div class="line"></div><div class="line"><span class="comment"># Specify that all features have real-value data</span></div><div class="line">feature_columns = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, dimension=<span class="number">4</span>)]</div><div class="line"></div><div class="line"><span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></div><div class="line">classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,</div><div class="line">                                            hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">                                            n_classes=<span class="number">3</span>,</div><div class="line">                                            model_dir=<span class="string">"/tmp/iris_model"</span>)</div><div class="line"></div><div class="line"><span class="comment"># Fit model.</span></div><div class="line">classifier.fit(x=training_set.data,</div><div class="line">               y=training_set.target,</div><div class="line">               steps=<span class="number">2000</span>)</div><div class="line"></div><div class="line"><span class="comment"># Evaluate accuracy.</span></div><div class="line">accuracy_score = classifier.evaluate(x=test_set.data,</div><div class="line">                                     y=test_set.target)[<span class="string">"accuracy"</span>]</div><div class="line">print(<span class="string">'Accuracy: &#123;0:f&#125;'</span>.format(accuracy_score))</div><div class="line"></div><div class="line"><span class="comment"># Classify two new flower samples.</span></div><div class="line">new_samples = np.array(</div><div class="line">    [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>], [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], dtype=float)</div><div class="line">y = list(classifier.predict(new_samples, as_iterable=<span class="keyword">True</span>))</div><div class="line">print(<span class="string">'Predictions: &#123;&#125;'</span>.format(str(y)))</div></pre></td></tr></table></figure>
<p>接下来，我们将详细介绍这部分代码的细节。</p>
<h2 id="将Iris_CSV数据加载到TensorFlow">将Iris CSV数据加载到TensorFlow</h2><p><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set" target="_blank" rel="external">Iris数据集</a>包含150行数据，包括来自三个相关鸢尾花物种，其中每个物种包含50个样本：山鸢尾，杂色鸢尾和维吉尼亚鸢尾。</p>
<p><img src="/img/17_03_05/001.jpg" alt=""></p>
<p><strong>从左到右依次是：<a href="https://commons.wikimedia.org/w/index.php?curid=170298" target="_blank" rel="external">山鸢尾</a>(by <a href="https://commons.wikimedia.org/wiki/User:Radomil" target="_blank" rel="external">Radomil</a>, CC BY-SA 3.0),<a href="https://commons.wikimedia.org/w/index.php?curid=248095" target="_blank" rel="external">杂色鸢尾</a>(by <a href="https://commons.wikimedia.org/wiki/User:Dlanglois" target="_blank" rel="external">Dlanglois</a>, CC BY-SA 3.0)和<a href="https://www.flickr.com/photos/33397993@N05/3352169862" target="_blank" rel="external">维吉尼亚鸢尾</a>(by <a href="https://www.flickr.com/photos/33397993@N05" target="_blank" rel="external">Frank Mayfield</a>, CC BY-SA 2.0)</strong></p>
<p>每行包含每个花样品的以下数据：<a href="https://en.wikipedia.org/wiki/Sepal" target="_blank" rel="external">萼片</a>长度，萼片宽度，<a href="https://en.wikipedia.org/wiki/Petal" target="_blank" rel="external">花瓣</a>长度，花瓣宽度以及花的品种。花的品种用整数表示，0表示山鸢尾，1表示杂色鸢尾，2表示维吉尼亚鸢尾。</p>
<table>
<thead>
<tr>
<th style="text-align:left">萼片长度(Sepal Length)</th>
<th style="text-align:left">萼片宽度(Sepal Width)</th>
<th style="text-align:left">花瓣长度(Petal Length)</th>
<th style="text-align:left">花瓣宽度(Petal Width)</th>
<th style="text-align:left">品种(Species)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">5.1</td>
<td style="text-align:left">3.5</td>
<td style="text-align:left">1.4</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0</td>
</tr>
<tr>
<td style="text-align:left">4.9</td>
<td style="text-align:left">3.0</td>
<td style="text-align:left">1.4</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0</td>
</tr>
<tr>
<td style="text-align:left">4.7</td>
<td style="text-align:left">3.2</td>
<td style="text-align:left">1.3</td>
<td style="text-align:left">0.2</td>
<td style="text-align:left">0</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
<tr>
<td style="text-align:left">7.0</td>
<td style="text-align:left">3.2</td>
<td style="text-align:left">4.7</td>
<td style="text-align:left">1.4</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">6.4</td>
<td style="text-align:left">3.2</td>
<td style="text-align:left">4.5</td>
<td style="text-align:left">1.5</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">6.9</td>
<td style="text-align:left">3.1</td>
<td style="text-align:left">4.9</td>
<td style="text-align:left">1.5</td>
<td style="text-align:left">1</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
<tr>
<td style="text-align:left">6.5</td>
<td style="text-align:left">3.0</td>
<td style="text-align:left">5.2</td>
<td style="text-align:left">2.0</td>
<td style="text-align:left">2</td>
</tr>
<tr>
<td style="text-align:left">6.2</td>
<td style="text-align:left">3.4</td>
<td style="text-align:left">5.4</td>
<td style="text-align:left">2.3</td>
<td style="text-align:left">2</td>
</tr>
<tr>
<td style="text-align:left">5.9</td>
<td style="text-align:left">3.0</td>
<td style="text-align:left">5.1</td>
<td style="text-align:left">1.8</td>
<td style="text-align:left">2</td>
</tr>
</tbody>
</table>
<p>在本教程中，Iris数据已随机分到两个单独的CSV中：</p>
<ul>
<li>一个包含了120个样本的训练集(<a href="http://download.tensorflow.org/data/iris_training.csv" target="_blank" rel="external">iris_training.csv</a>)</li>
<li>一个包含了30个样本的测试集(<a href="http://download.tensorflow.org/data/iris_test.csv" target="_blank" rel="external">iris_test.csv</a>)</li>
</ul>
<p>将这些文件放在与Python代码相同的目录中。</p>
<p>首先导入TensorFlow和numpy：</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div></pre></td></tr></table></figure>
<p>接下来，使用<code>learn.datasets.base</code>中的<a href="https://www.tensorflow.org/code/tensorflow/contrib/learn/python/learn/datasets/base.py" target="_blank" rel="external"><code>load_csv_with_header()</code></a>方法将训练和测试集装入数据集。<code>load_csv_with_header()</code>方法需要三个必需的参数：</p>
<ul>
<li><code>filename</code>，CSV文件的路径</li>
<li><code>target_dtype</code>，接受数据集的目标值的<a href="http://docs.scipy.org/doc/numpy/user/basics.types.html" target="_blank" rel="external"><code>numpy</code>数据类型</a>。</li>
<li><code>features_dtype</code>，接受数据集的特征值的<a href="http://docs.scipy.org/doc/numpy/user/basics.types.html" target="_blank" rel="external"><code>numpy</code>数据类型</a>。</li>
</ul>
<p>在这里，target（你训练模型预测的值）是花种，它是一个从0-2的整数，所以对应的适当的<code>numpy</code>数据类型是<code>np.int</code>：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Data sets</span></div><div class="line"><span class="attr">IRIS_TRAINING</span> = <span class="string">"iris_training.csv"</span></div><div class="line"><span class="attr">IRIS_TEST</span> = <span class="string">"iris_test.csv"</span></div><div class="line"></div><div class="line"><span class="comment"># Load datasets.</span></div><div class="line"><span class="attr">training_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">    <span class="attr">filename=IRIS_TRAINING,</span></div><div class="line">    <span class="attr">target_dtype=np.int,</span></div><div class="line">    <span class="attr">features_dtype=np.float32)</span></div><div class="line"><span class="attr">test_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">    <span class="attr">filename=IRIS_TEST,</span></div><div class="line">    <span class="attr">target_dtype=np.int,</span></div><div class="line">    <span class="attr">features_dtype=np.float32)</span></div></pre></td></tr></table></figure>
<p>tf.contrib.learn中的<code>Dataset</code>是<a href="https://docs.python.org/2/library/collections.html#collections.namedtuple" target="_blank" rel="external">命名元组</a>；您可以通过<code>data</code>和<code>target</code>字段访问特征数据和目标值。这里<code>training_set.data</code>和<code>training_set.target</code>分别包含训练集的特征数据和目标值；<code>test_set.data</code>和<code>test_set.target</code>分别包含测试集的特征数据和目标值。</p>
<p>在后面的<a href="#将DNN分类器用于Iris训练数据">“将DNN分类器用于Iris训练数据”</a>中，你将使用到<code>training_set.data</code>和<code>training_set.target</code>来训练你的模型，在<a href="#评估模型精度">“评估模型精度”</a>中，你将使用<code>test_set.data</code>和<code>test_set.target</code>。但首先，你需要在下一节中构建你的模型。</p>
<h2 id="构建一个深度神经网络分类器">构建一个深度神经网络分类器</h2><p>tf.contrib.learn提供了一系列预定义的模型，叫做<a href="https://www.tensorflow.org/api_guides/python/contrib.learn#estimators" target="_blank" rel="external">Estimator</a>s。通过Estimator，您可以对您的数据很方便的进行训练和评估操作，达到“开箱即用”的效果。在这里，您将配置一个深层神经网络分类器模型以适应Iris数据。通过使用tf.contrib.learn，你可以仅仅使用一行代码就实例化一个<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier" target="_blank" rel="external"><code>tf.contrib.learn.DNNClassifier</code></a>。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># Specify that all features have real-value data</div><div class="line">feature_columns = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, dimension=<span class="number">4</span>)]</div><div class="line"></div><div class="line"># Build <span class="number">3</span> layer DNN with <span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span> units respectively.</div><div class="line">classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,</div><div class="line">                                            hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">                                            n_classes=<span class="number">3</span>,</div><div class="line">                                            model_dir=<span class="string">"/tmp/iris_model"</span>)</div></pre></td></tr></table></figure>
<p>上面的代码首先定义了模型的特征列，它指定了数据集中特征的数据类型。所有的特征数据都是连续的，因此<code>tf.contrib.layers.real_valued_column</code>是用于构造特征列的适当函数。数据集中有四个特征（萼片宽度，萼片高度，花瓣宽度和花瓣高度），因此相应的尺寸必须设置为4以保存所有数据。</p>
<p>然后，代码使用以下参数创建<code>DNNClassifier</code>模型：</p>
<ul>
<li><code>feature_columns=feature_columns</code>。上面定义的一组特征</li>
<li><code>hidden_units=[10, 20, 10]</code>。三个<a href="http://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw" target="_blank" rel="external">隐藏层</a>分别包含10，20，10个神经元。</li>
<li><code>n_classes=3</code>。三个目标类，代表三个鸢尾物种。</li>
<li><code>model_dir=/tmp/iris_model</code>。TensorFlow在模型训练期间将保存检查点数据的目录。有关使用TensorFlow进行日志记录和监视的更多信息，请见<a href="">使用tf.contrib.learn记录和监视的基本知识</a>。</li>
</ul>
<h2 id="将DNN分类器用于Iris训练数据">将DNN分类器用于Iris训练数据</h2><p>现在，你已经配置好了你的DNN<code>classifier</code>模型，你可以使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/BaseEstimator#fit" target="_blank" rel="external"><code>fit</code></a>方法来将Iris训练数据应用到分类器上。将特征数据（<code>training_set.data</code>），目标值（<code>training_set.target</code>）和要训练的步数（这里是<code>2000</code>）作为参数传递：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Fit model</span></div><div class="line">classifier.fit(<span class="attr">x=training_set.data,</span> <span class="attr">y=training_set.target,</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>模型的状态保存在<code>classifier</code>(分类器)中，这意味着如果你喜欢，你可以迭代地训练。上面的代码执行效果等同于下面这两行代码：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">classifier.fit(x=training_set<span class="selector-class">.data</span>, y=training_set<span class="selector-class">.target</span>, steps=<span class="number">1000</span>)</div><div class="line">classifier.fit(x=training_set<span class="selector-class">.data</span>, y=training_set<span class="selector-class">.target</span>, steps=<span class="number">1000</span>)</div></pre></td></tr></table></figure>
<p>但是，如果您希望在训练时跟踪模型，则可能需要使用TensorFlow<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/monitors" target="_blank" rel="external">monitor</a>(监视器)来执行日志操作。关于这个主题更多的内容，请见教程<a href="">使用tf.contrib.learn记录和监视的基本知识</a>。</p>
<h2 id="评估模型精度">评估模型精度</h2><p>你已经将Iris的训练数据适配到了<code>DNNClassifier</code>模型上；现在，您可以使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/BaseEstimator#evaluate" target="_blank" rel="external"><code>evaluate</code></a>方法在Iris测试数据上检查其准确性。像<code>fit</code>（拟合）一样，<code>evaluate</code>（评估操作）将特征数据和目标值作为参数，并返回带有评估结果的<code>dict</code>（字典）。以下代码通过了Iris测试数据-<code>test_set.data</code>和<code>test_set.target</code>来评估和打印结果的准确性：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">accuracy_score = classifier.evaluate(x=test_set<span class="selector-class">.data</span>, y=test_set.target)[<span class="string">"accuracy"</span>]</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">'Accuracy: &#123;0:f&#125;'</span>.format(accuracy_score)</span></span>)</div></pre></td></tr></table></figure>
<p>运行全部的脚本，并检查结果的准确度：</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">Accuracy:</span> <span class="number">0.966667</span></div></pre></td></tr></table></figure>
<p>您的准确度结果可能有所不同，但应该是高于90％的。这对于相对较小的数据集是一个不错的结果了！</p>
<h2 id="分类新样品">分类新样品</h2><p>使用评估器的<code>predict()</code>方法来分类一个新的样本。例如，说你有这两个新的花样本：</p>
<table>
<thead>
<tr>
<th style="text-align:left">萼片长度(Sepal Length)</th>
<th style="text-align:left">萼片宽度(Sepal Width)</th>
<th style="text-align:left">花瓣长度(Petal Length)</th>
<th style="text-align:left">花瓣宽度(Petal Width)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">6.4</td>
<td style="text-align:left">3.2</td>
<td style="text-align:left">4.5</td>
<td style="text-align:left">1.5</td>
</tr>
<tr>
<td style="text-align:left">5.8</td>
<td style="text-align:left">3.1</td>
<td style="text-align:left">5.0</td>
<td style="text-align:left">1.7</td>
</tr>
</tbody>
</table>
<p>你可以用以下代码预测他们的物种：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># Classify two new flower samples.</div><div class="line">new_samples = np.array(</div><div class="line">    <span class="string">[[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]]</span>, dtype=float)</div><div class="line">y = list(classifier.predict(new_samples, as_iterable=True))</div><div class="line"><span class="built_in">print</span>(<span class="string">'Predictions: &#123;&#125;'</span>.format(str(y)))</div></pre></td></tr></table></figure>
<p><code>predict()</code>方法返回了一个预测数组，每个样本对应其中的一个结果：</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Prediction: <span class="string">[1 2]</span></div></pre></td></tr></table></figure>
<p>该模型预测的结果为：第一个样本是杂色鸢尾，第二个样本是维吉尼亚鸢尾。</p>
<h2 id="其他资源">其他资源</h2><ul>
<li>有关tf.contrib.learn的更多参考资料，请参阅<a href="https://www.tensorflow.org/api_guides/python/contrib.learn" target="_blank" rel="external">官方API文档</a>。</li>
<li>要了解有关使用tf.contrib.learn创建线性模型的更多信息，请参阅<a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="external">使用TensorFlow的大型线性模型</a>。</li>
<li>要使用tf.contrib.learn API构建自己的评估器，请查看<a href="http://terrytangyuan.github.io/2016/07/08/understand-and-build-tensorflow-estimator/" target="_blank" rel="external">TensorFlow中的Building Machine Learning Estimator</a>。</li>
<li>要在浏览器中尝试神经网络建模和可视化，请查看<a href="http://playground.tensorflow.org/" target="_blank" rel="external">Deep Playground</a>。</li>
<li>有关神经网络的更高级教程，请参阅<a href="https://www.tensorflow.org/tutorials/deep_cnn" target="_blank" rel="external">卷积神经网络</a>和<a href="https://www.tensorflow.org/tutorials/recurrent" target="_blank" rel="external">循环神经网络</a>。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/03/【Tensorflow r1.0 文档翻译】Tensorflow原理导论/" itemprop="url">
                【Tensorflow r1.0 文档翻译】Tensorflow原理导论
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-03T21:19:58+08:00" content="2017-03-03">
            2017-03-03
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/03/【Tensorflow r1.0 文档翻译】Tensorflow原理导论/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/03/【Tensorflow r1.0 文档翻译】Tensorflow原理导论/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>代码：<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/" target="_blank" rel="external">tensorflow/examples/tutorials/mnist/</a></p>
<p>这篇教程的目的是为了展示如何使用TensorFlow来训练并评估一个简单的<strong>前馈神经网络(feed-forward neural network)</strong>用来识别MNIST手写数字数据集。本教程的目标读者是有兴趣使用TensorFlow的有经验的机器学习用户。</p>
<p>这部分教程不是为了教授普通的机器学习。</p>
<p>请确保您已按照说明<a href="https://www.tensorflow.org/install/index" target="_blank" rel="external">安装了TensorFlow</a>。</p>
<h2 id="教程文件">教程文件</h2><p>本教程引用以下文件：</p>
<table>
<thead>
<tr>
<th style="text-align:left">文件</th>
<th style="text-align:left">目标</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist.py" target="_blank" rel="external"><code>mnist.py</code></a></td>
<td style="text-align:left">构建一个完全连接的MNIST模型的代码。</td>
</tr>
<tr>
<td style="text-align:left"><a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/fully_connected_feed.py" target="_blank" rel="external"><code>fully_connected_feed.py</code></a></td>
<td style="text-align:left">利用下载的数据集训练构建好的MNIST模型的主要代码，以数据反馈字典（feed dictionary）的形式作为输入模型。</td>
</tr>
</tbody>
</table>
<p>只需要运行<code>fully_connected_feed.py</code>文件，就可以开启训练：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">python</span> fully_connected_feed.<span class="keyword">py</span></div></pre></td></tr></table></figure>
<h2 id="准备数据">准备数据</h2><p>MNIST是机器学习中的经典问题。这个问题是查看28x28像素的手写数字灰度图像，并确定图像表示的数字，数字范围是0到9。</p>
<p><img src="/img/17_03_03/001.png" alt=""></p>
<p>更多的信息，参加<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Yann LeCun’s MNIST page</a>或者<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">Chris Olah’s visualizations of MNIST</a>。</p>
<h3 id="下载">下载</h3><p>在<code>run_training()</code>方法的开始部分，<code>input_data.read_data_sets()</code>方法会确保你的本地训练文件夹中，已经下载了正确的数据，然后将这些数据解压并返回一个含有<code>DataSet</code>实例的字典。</p>
<figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">dat<span class="built_in">a_sets</span> = input_data.read_dat<span class="built_in">a_sets</span>(FLAGS.train_dir, FLAGS.fake_data)</div></pre></td></tr></table></figure>
<p><strong>注意：</strong><code>fake_data</code>标记是用于单元测试的，读者可以不必理会。</p>
<table>
<thead>
<tr>
<th style="text-align:left">数据集</th>
<th style="text-align:left">目标</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>data_sets.train</code></td>
<td style="text-align:left">55000图像和标签，用于初级训练。</td>
</tr>
<tr>
<td style="text-align:left"><code>data_sets.validation</code></td>
<td style="text-align:left">5000图像和标签，用于迭代验证训练准确性。</td>
</tr>
<tr>
<td style="text-align:left"><code>data_sets.test</code></td>
<td style="text-align:left">10000图像和标签，用于最终测试训练的准确性。</td>
</tr>
</tbody>
</table>
<h3 id="输入和占位符">输入和占位符</h3><p><code>placeholder_inputs()</code>方法创建了两个<code>tf.placeholder</code>操作，用于定义输入的形状。形状参数中包含<code>batch_size</code>值，后续还会将实际的训练样本传入图中。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="attr">images_placeholder</span> = tf.placeholder(tf.float32, <span class="attr">shape=(batch_size,</span></div><div class="line">                                                       mnist.IMAGE_PIXELS))</div><div class="line"><span class="attr">labels_placeholder</span> = tf.placeholder(tf.int32, <span class="attr">shape=(batch_size))</span></div></pre></td></tr></table></figure>
<p>在训练的循环代码的下方，传入的整个图像和标签数据集会被切片，以符合每一个操作所设置的<code>batch_size</code>值，占位符操作将会填补以符合这个<code>batch_size</code>值。然后使用<code>feed_dict</code>参数，将数据传入<code>sess.run()</code>函数。</p>
<h2 id="构建图">构建图</h2><p>在为数据创建占位符之后，就可以运行<code>mnist.py</code>文件，经过三阶段的模式函数操作：<code>inference()</code>， <code>loss()</code>，和<code>training()</code>。图表就构建完成了。</p>
<ul>
<li>1.<code>inference()</code>-尽可能地构建好图表，满足促使神经网络向前反馈并做出预测的要求。</li>
<li>2.<code>loss()</code>-往inference图表中添加生成损失（loss）所需要的操作（ops）。</li>
<li>3.<code>training()</code>-往损失图表中添加计算并应用梯度（gradients）所需的操作。</li>
</ul>
<p><img src="/img/17_03_03/002.png" alt=""></p>
<h3 id="推理(Inference)">推理(Inference)</h3><p><code>inference()</code>函数会尽可能地构建图表，做到返回包含了预测结果（output prediction）的Tensor。</p>
<p>它采用图像占位符作为输入，并在其上借助<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks" target="_blank" rel="external">ReLU</a>)激活函数构建一对完全连接层，以及一个有着十个节点、指明了输出logtis模型的线性层。</p>
<p>每个图层都在唯一的<a href="https://www.tensorflow.org/api_docs/python/tf/name_scope" target="_blank" rel="external"><code>tf.name_scope</code></a>下创建，创建于该作用域之下的所有元素都将带有其前缀。</p>
<figure class="highlight actionscript"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'hidden1'</span>):</div></pre></td></tr></table></figure>
<p>在定义的范围内，由这些层中的每一个使用的权重和偏差被生成为<a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank" rel="external"><code>tf.Variable</code></a>实例，具有它们期望的形状：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">weights = <span class="keyword">tf</span>.Variable(</div><div class="line">    <span class="keyword">tf</span>.truncated_normal([IMAGE_PIXELS, hidden1_units],</div><div class="line">                        stddev=<span class="number">1.0</span> / math.<span class="built_in">sqrt</span>(float(IMAGE_PIXELS))),</div><div class="line">    name=<span class="string">'weights'</span>)</div><div class="line">biases = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.zeros([hidden1_units]),</div><div class="line">                     name=<span class="string">'biases'</span>)</div></pre></td></tr></table></figure>
<p>例如，当在<code>hidden1</code>范围下创建这些时，赋予权重变量的唯一名称将是“<code>hidden1 / weights</code>”。</p>
<p>每个变量在构建时，都会执行初始化操作。</p>
<p>在大多数情况下，通过<a href="https://www.tensorflow.org/api_docs/python/tf/truncated_normal" target="_blank" rel="external"><code>tf.truncated_normal</code></a>函数初始化权重变量，给赋予的shape则是一个二维tensor，其中第一个维度代表该层中权重变量所连接（connect from）的单元数量，第二个维度代表该层中权重变量所连接到的（connect to）单元数量。第一层，名字为<code>hidden1</code>，它的尺寸是<code>[IMAGE_PIXELS, hidden1_units]</code>，因为权重变量将图像输入连接到了<code>hidden1</code>层。<code>tf.truncated_normal</code>初始函数将根据所得到的均值和标准差，生成一个随机分布。</p>
<p>然后，通过<a href="https://www.tensorflow.org/api_docs/python/tf/zeros" target="_blank" rel="external"><code>tf.zeros</code></a>函数初始化偏差变量（biases），确保所有偏差的起始值都是0，而它们的形状则是其在该层中所接到的（connect to）单元数量。</p>
<p>图表的三个主要操作，分别是两个<code>tf.nn.relu</code>操作，它们中嵌入了隐藏层所需的<a href="https://www.tensorflow.org/api_docs/python/tf/matmul" target="_blank" rel="external"><code>tf.matmul</code></a>；以及logits模型所需的另外一个<code>tf.matmul</code>。三者依次生成，各自的<code>tf.Variable</code>实例则与输入占位符或下一层的输出tensor所连接。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hidden1 = tf<span class="selector-class">.nn</span><span class="selector-class">.relu</span>(tf.matmul(images, weights) + biases)</div></pre></td></tr></table></figure>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hidden2 = tf<span class="selector-class">.nn</span><span class="selector-class">.relu</span>(tf.matmul(hidden1, weights) + biases)</div></pre></td></tr></table></figure>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">logits</span> = tf.matmul(hidden2, weights) + biases</div></pre></td></tr></table></figure>
<p>最终，程序会返回包含了输出结果的<code>logits</code>Tensor。</p>
<h3 id="损失">损失</h3><p><code>loss()</code>函数通过添加所需的损失操作，进一步构建图表。</p>
<p>首先，来自<code>labels_placeholder</code>的值将转换为64位整数。然后，添加一个<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits" target="_blank" rel="external">tf.nn.sparse_softmax_cross_entropy_with_logits</a>操作，以从<code>labels_placeholder</code>自动生成1-hot标签，并且与<code>inference()</code>函数的输出logits与那些1-hot标签进行比较。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="attr">labels</span> = tf.to_int64(labels)</div><div class="line"><span class="attr">cross_entropy</span> = tf.nn.sparse_softmax_cross_entropy_with_logits(</div><div class="line">    <span class="attr">labels=labels,</span> <span class="attr">logits=logits,</span> <span class="attr">name='xentropy')</span></div></pre></td></tr></table></figure>
<p>然后使用<a href="https://www.tensorflow.org/api_docs/python/tf/reduce_mean" target="_blank" rel="external"><code>tf.reduce_mean</code></a>来求在批量维度（第一维度）上的交叉熵的平均值，作为总损失。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">loss</span> = tf.reduce_mean(cross_entropy, name=<span class="string">'xentropy_mean'</span>)</div></pre></td></tr></table></figure>
<p>然后将包含损失值的张量返回。</p>
<blockquote>
<p><strong>注意：</strong>交叉熵是信息论中的一种理论，它用于描述神经网络的预测结果相对于实际所给定的真实结果的偏差程度。更多的信息，请参阅博文<a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="external">《可视化信息理论》</a>。</p>
</blockquote>
<h3 id="训练">训练</h3><p><code>training()</code>方法通过添加<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">梯度下降</a>的操作来最小化损失。</p>
<p>首先，它通过<code>loss()</code>方法接受损失tensor，然后传递到<a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar" target="_blank" rel="external"><code>tf.summary.scalar</code></a>，用于在与<code>SummaryWriter</code>（见下文）一起使用时生成事件文件中的摘要值的操作。在这里，它将在每次写出摘要时发出损失的快照值。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf<span class="selector-class">.summary</span><span class="selector-class">.scalar</span>(<span class="string">'loss'</span>, loss)</div></pre></td></tr></table></figure>
<p>接下来，我们实例化一个<a href="https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer" target="_blank" rel="external"><code>tf.train.GradientDescentOptimizer</code></a>，负责按照所要求的学习效率（learning rate）应用梯度下降法（gradients）。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">optimizer = tf<span class="selector-class">.train</span><span class="selector-class">.GradientDescentOptimizer</span>(learning_rate)</div></pre></td></tr></table></figure>
<p>之后，我们生成一个单个的变量用于统计全局训练的次数，<a href="https://www.tensorflow.org/api_docs/python/tf/train/Optimizer#minimize" target="_blank" rel="external"><code>tf.train.Optimizer.minimize</code></a>操作被同时用作在系统中更新可训练的权值，以及增加全局步长（global step）。按照惯例，这个操作被称为<code>train_op</code>，TensorFlow会话必须运行的，以便引入一个完整的训练步骤（见下文）。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">global_step</span> = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="literal">False</span>)</div><div class="line"><span class="attr">train_op</span> = optimizer.minimize(loss, global_step=global_step)</div></pre></td></tr></table></figure>
<h2 id="训练模型">训练模型</h2><p>一旦图被构建，它就可以在由<code>fully_connected_feed.py</code>中的用户代码控制的循环中迭代地训练和求值。</p>
<h3 id="图">图</h3><p>在<code>run_training()</code>方法的一开始的部分，是一个python的<code>with</code>命令，这表示所有构建的操作将与默认全局<a href="https://www.tensorflow.org/api_docs/python/tf/Graph" target="_blank" rel="external"><code>tf.Graph</code></a>实例相关联。</p>
<figure class="highlight coq"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">with</span> tf.<span class="keyword">Graph</span>().as_default():</div></pre></td></tr></table></figure>
<p><code>tf.Graph</code>实例是一系列可以作为整体执行的操作。TensorFlow的大部分场景只需要依赖默认图表一个实例即可。</p>
<p>利用多个图表的更加复杂的使用场景也是可能的，但是超出了本教程的范围。</p>
<h3 id="会话">会话</h3><p>完成全部的构建准备、生成全部所需的操作之后，我们就可以创建一个<a href="https://www.tensorflow.org/api_docs/python/tf/Session" target="_blank" rel="external">tf.Session</a>，用于运行图表。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">sess</span> = tf.Session()</div></pre></td></tr></table></figure>
<p>另外，也可以利用<code>with</code>代码块生成<code>Session</code>，限制作用域：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">with <span class="keyword">tf</span>.Session() <span class="keyword">as</span> ses<span class="variable">s:</span></div></pre></td></tr></table></figure>
<p><code>Session</code>函数中没有传入参数，表明该代码将会依附于（如果还没有创建会话，则会创建新的会话）默认的本地会话。</p>
<p>生成会话之后，所有<code>tf.Variable</code>实例都会立即通过调用各自初始化操作中的<a href="https://www.tensorflow.org/api_docs/python/tf/Session#run" target="_blank" rel="external"><code>tf.Session.run</code></a>函数进行初始化。</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">init</span> = tf.global_variables_initializer()</div><div class="line">sess.run(<span class="keyword">init</span>)</div></pre></td></tr></table></figure>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/Session#run" target="_blank" rel="external"><code>tf.Session.run</code></a>方法将会运行图表中与作为参数传入的操作相对应的完整子集。在初次调用时，<code>init</code>操作只包含了变量初始化程序<a href="https://www.tensorflow.org/api_docs/python/tf/group" target="_blank" rel="external"><code>tf.group</code></a>。图表的其他部分不会在这里，而是在下面的训练循环运行。</p>
<h3 id="训练循环">训练循环</h3><p>在通过会话来初始化变量后，就可以开始训练了。</p>
<p>训练的每一步都是通过用户代码控制，而能实现有效训练的最简单循环就是：</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="keyword">step</span> <span class="keyword">in</span> xrange(FLAGS.max_steps):</div><div class="line">    sess.<span class="built_in">run</span>(train_op)</div></pre></td></tr></table></figure>
<p>但是，本教程中的例子要更为复杂一点，原因是我们必须把输入的数据根据每一步的情况进行切分，以匹配之前生成的占位符。</p>
<h3 id="向图表提供反馈">向图表提供反馈</h3><p>执行每一步时，我们的代码会生成一个反馈字典（feed dictionary），其中包含对应步骤中训练所要使用的样本，这些样本的key就是其所代表的占位符操作。</p>
<p><code>fill_feed_dict</code>函数会查询给定的<code>DataSet</code>，索要下一批次`batch_size的图像和标签，与占位符相匹配的Tensor则会包含下一批次的图像和标签。</p>
<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">images_feed, labels_feed = data_set.next_batch(<span class="keyword">FLAGS</span>.batch_size,</div><div class="line">                                               <span class="keyword">FLAGS</span>.fake_data)</div></pre></td></tr></table></figure>
<p>然后，以占位符作为键，创建一个Python字典对象，值则是其代表的反馈Tensor。</p>
<figure class="highlight dts"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">feed_dict = &#123;</div><div class="line"><span class="symbol">    images_placeholder:</span> images_feed,</div><div class="line"><span class="symbol">    labels_placeholder:</span> labels_feed,</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这个字典随后作为<code>feed_dict</code>参数，传入<code>sess.run()</code>函数中，为这一步的训练提供输入样本。</p>
<h3 id="检查状态">检查状态</h3><p>在运行<code>sess.run</code>时，要在代码中明确其需要获取的两个值：<code>[train_op, loss]</code>。</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="keyword">step</span> <span class="keyword">in</span> <span class="built_in">xrange</span>(FLAGS.max_steps):</div><div class="line">    feed_dict = fill_feed_dict(data_sets.train,</div><div class="line">                               images_placeholder,</div><div class="line">                               labels_placeholder)</div><div class="line">    <span class="symbol">_</span>, loss_value = sess.run([train_op, loss],</div><div class="line">                             feed_dict=feed_dict)</div></pre></td></tr></table></figure>
<p>因为要获取这两个值，<code>sess.run()</code>会返回一个有两个元素的元组。其中每一个<code>Tensor</code>对象，对应了返回的元组中的numpy数组，而这些数组中包含了当前这步训练中对应Tensor的值。由于<code>train_op</code>并不会产生输出，其在返回的元祖中的对应元素就是<code>None</code>，所以会被抛弃。但是，如果模型在训练中出现偏差，<code>loss</code> Tensor的值可能会变成NaN，所以我们要获取它的值，并记录下来。</p>
<p>假设训练一切正常，没有出现NaN，训练循环会每隔100个训练步骤，就打印一行简单的状态文本，告知用户当前的训练状态。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">if</span> <span class="built_in">step</span> % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">    <span class="built_in">print</span> <span class="string">'Step %d: loss = %.2f (%.3f sec)'</span> % (<span class="built_in">step</span>, loss_value, duration)</div></pre></td></tr></table></figure>
<h3 id="状态可视化">状态可视化</h3><p>为了发出<a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="external">TensorBoard</a>所使用的事件文件（events file），所有的摘要（在这里只有一个）都要在图构建阶段合并至一个Tensor中。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">summary</span> = tf<span class="selector-class">.summary</span><span class="selector-class">.merge_all</span>()</div></pre></td></tr></table></figure>
<p>在创建好会话（session）之后，可以实例化一个<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>，用于写入包含了图表本身和即时数据具体值的事件文件。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">summary_writer = tf<span class="selector-class">.summary</span><span class="selector-class">.FileWriter</span>(FLAGS<span class="selector-class">.train_dir</span>, sess.graph)</div></pre></td></tr></table></figure>
<p>最后，每次评估<code>summary</code>(摘要)并将输出传递给<code>add_summary()</code>函数时，事件文件将被新的摘要值更新。</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">summary_str = sess.<span class="built_in">run</span>(summary, feed_dict=feed_dict)</div><div class="line">summary_writer.add_summary(summary_str, <span class="built_in">step</span>)</div></pre></td></tr></table></figure>
<p>事件文件写入完毕之后，可以就训练文件夹打开一个TensorBoard，查看即时数据的情况。</p>
<p><img src="/img/17_03_03/003.png" alt=""></p>
<blockquote>
<p><strong>注意：</strong>了解更多如何构建并运行TensorBoard的信息，请查看相关教程<a href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" target="_blank" rel="external">Tensorboard：训练过程可视化</a>。</p>
</blockquote>
<h3 id="保存检查点">保存检查点</h3><p>为了得到可以用来后续恢复模型以进一步训练或评估的检查点文件（checkpoint file），我们实例化一个<a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver" target="_blank" rel="external"><code>tf.train.Saver</code></a>。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</div></pre></td></tr></table></figure>
<p>在训练循环中，将定期调用<a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver#save" target="_blank" rel="external"><code>tf.train.Saver.save</code></a>方法，使用所有可训练变量的当前值将检查点文件写入训练目录。</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">saver.<span class="built_in">save</span>(sess, FLAGS.train_dir, global_step=<span class="keyword">step</span>)</div></pre></td></tr></table></figure>
<p>在将来的某个时间点，可以通过使用<a href="https://www.tensorflow.org/api_docs/python/tf/train/Saver#restore" target="_blank" rel="external"><code>tf.train.Saver.restore</code></a>方法重新加载模型参数来恢复训练。</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">saver</span><span class="selector-class">.restore</span>(<span class="selector-tag">sess</span>, <span class="selector-tag">FLAGS</span><span class="selector-class">.train_dir</span>)</div></pre></td></tr></table></figure>
<h2 id="评估模型">评估模型</h2><p>每隔一千个训练步骤，我们的代码会尝试使用训练数据集与测试数据集，对模型进行评估。<code>do_eval</code>函数会被调用三次，分别使用训练数据集、验证数据集合测试数据集。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">print</span> <span class="string">'Training Data Eval:'</span></div><div class="line"><span class="keyword">do</span>_<span class="built_in">eval</span>(sess,</div><div class="line">        <span class="built_in">eval</span>_correct,</div><div class="line">        images_placeholder,</div><div class="line">        labels_placeholder,</div><div class="line">        data_sets.train)</div><div class="line"><span class="built_in">print</span> <span class="string">'Validation Data Eval:'</span></div><div class="line"><span class="keyword">do</span>_<span class="built_in">eval</span>(sess,</div><div class="line">        <span class="built_in">eval</span>_correct,</div><div class="line">        images_placeholder,</div><div class="line">        labels_placeholder,</div><div class="line">        data_sets.validation)</div><div class="line"><span class="built_in">print</span> <span class="string">'Test Data Eval:'</span></div><div class="line"><span class="keyword">do</span>_<span class="built_in">eval</span>(sess,</div><div class="line">        <span class="built_in">eval</span>_correct,</div><div class="line">        images_placeholder,</div><div class="line">        labels_placeholder,</div><div class="line">        data_sets.test)</div></pre></td></tr></table></figure>
<blockquote>
<p>注意，更复杂的使用场景通常是，先隔绝<code>data_sets.test</code>测试数据集，只有在大量的超参数优化调整（hyperparameter tuning）之后才进行检查。但是，由于MNIST问题比较简单，我们在这里一次性评估所有的数据。</p>
</blockquote>
<h3 id="构建评估图(Eval_Graph)">构建评估图(Eval Graph)</h3><p>在打开默认图表（Graph）之前，我们应该先调用get_data(train=False)函数，抓取测试数据集。</p>
<p>在进入训练循环之前，评估操作应该通过<code>mnist.py</code>中的<code>evaluate()</code>函数来构建。<code>evaluate()</code>传入的<code>logist</code>和标签参数与<code>loss()</code>函数相同。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">eval_correct</span> = mnist.evaluation(logits, labels_placeholder)</div></pre></td></tr></table></figure>
<p><code>evaluation()</code>函数会生成<a href="https://www.tensorflow.org/api_docs/python/tf/nn/in_top_k" target="_blank" rel="external"><code>tf.nn.in_top_k</code></a>操作，如果在K个最有可能的预测中可以发现真的标签，那么这个操作就会将模型输出标记为正确。在本文中，我们把K的值设置为1，也就是只有在预测是真的标签时，才判定它是正确的。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">eval_correct = tf<span class="selector-class">.nn</span><span class="selector-class">.in_top_k</span>(logits, labels, <span class="number">1</span>)</div></pre></td></tr></table></figure>
<h3 id="评估输出">评估输出</h3><p>之后，我们可以创建一个循环，往其中添加<code>feed_dict</code>，并在调用<code>sess.run()</code>函数时传入<code>eval_correct</code>操作，目的就是用给定的数据集评估模型。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> step <span class="keyword">in</span> xrange(steps_per_epoch):</div><div class="line">    feed_dict = fill_feed_dict(data_<span class="built_in">set</span>,</div><div class="line">                               images_placeholder,</div><div class="line">                               labels_placeholder)</div><div class="line">    <span class="literal">true</span>_count += sess.run(<span class="built_in">eval</span>_correct, feed_dict=feed_dict)</div></pre></td></tr></table></figure>
<p><code>true_count</code>变量会累加所有<code>in_top_k</code>操作判定为正确的预测之和。接下来，只需要将正确测试的总数，除以例子总数，就可以得出准确率了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">precision = <span class="literal">true</span>_count / num_examples</div><div class="line"><span class="built_in">print</span>(<span class="string">'  Num examples: %d  Num correct: %d  Precision @ 1: %0.04f'</span> %</div><div class="line">      (num_examples, <span class="literal">true</span>_count, precision))</div></pre></td></tr></table></figure></span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/02/26/【Tensorflow r1.0 文档翻译】深入MNIST--专家级/" itemprop="url">
                【Tensorflow r1.0 文档翻译】深入MNIST--专家级
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-02-26T14:50:58+08:00" content="2017-02-26">
            2017-02-26
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/02/26/【Tensorflow r1.0 文档翻译】深入MNIST--专家级/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/02/26/【Tensorflow r1.0 文档翻译】深入MNIST--专家级/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>TensorFlow是一个用于进行大规模数值计算的强大库。其擅长的任务之一是实施和训练深层神经网络。在本教程中，我们将学到构建一个TensorFlow模型的基本步骤，并将通过这些步骤为MNIST构建一个深度卷积神经网络。</p>
<p>这个教程假设你已经熟悉神经网络和MNIST数据集。如果你尚未了解，请查看<a href="/2017/02/22/【Tensorflow%20r1.0%20文档翻译】机器学习的HelloWorld%20--%20MNIST手写数字识别/">新手指南</a>。在开始之前，请确认<a href="https://www.tensorflow.org/install/index" target="_blank" rel="external">安装</a>了TensorFlow。</p>
<h2 id="关于本教程">关于本教程</h2><p>本教程的第一部分解释了<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_softmax.py" target="_blank" rel="external">mnist_softmax.py</a>代码中发生了什么，这是Tensorflow模型的基本实现。第二部分显示了一些提高精度的方法。</p>
<p>您可以将本教程中的每个代码段复制并粘贴到Python环境中，当然你也可以选择只是读一下这部分代码。</p>
<p>我们将在本教程中完成：</p>
<ul>
<li>创建一个softmax回归函数，这是一个用于识别MNIST数字的模型，其原理是基于查看图像中的每个像素。</li>
<li>使用Tensorflow来训练模型以识别数字，方法是“查看”数千个示例（并运行我们的第一个Tensorflow会话）。</li>
<li>使用我们的测试数据检查模型的精度。</li>
<li>构建，训练和测试多层卷积神经网络以提高结果。</li>
</ul>
<h2 id="准备工作">准备工作</h2><p>在我们创建模型之前，我们首先加载MNIST数据集，并启动TensorFlow会话。</p>
<h3 id="加载MNIST数据">加载MNIST数据</h3><p>如果您要复制粘贴本教程中的代码，请从这两行代码开始，这两行代码将自动下载并读入数据：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">from tensorflow<span class="selector-class">.examples</span><span class="selector-class">.tutorials</span><span class="selector-class">.mnist</span> import input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>, one_hot=True)</div></pre></td></tr></table></figure>
<p>这里的<code>mnist</code>是一个轻量级类，将训练集，验证集和测试集存储为NumPy数组。同时提供了一个函数，用于在迭代中获得minibatch，后面我们将会用到。</p>
<h3 id="启动TensorFlow_InteractiveSession">启动TensorFlow InteractiveSession</h3><p>Tensorflow依赖于一个高效的C++后端来进行计算。与后端的这个连接叫做session。一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。</p>
<p>这里，我们使用更加方便的<code>InteractiveSession</code>类。通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些<a href="https://www.tensorflow.org/get_started/get_started#the_computational_graph" target="_blank" rel="external">计算图</a>，这些计算图是由某些操作(operations)构成的。这对于工作在交互式环境中的人们来说非常便利，比如使用IPython。如果你没有使用<code>InteractiveSession</code>，那么你需要在启动session之前构建整个计算图，然后启<a href="https://www.tensorflow.org/get_started/get_started#the_computational_graph" target="_blank" rel="external">动该计算图</a>。</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="title">sess</span> = tf.<span class="type">InteractiveSession</span>()</div></pre></td></tr></table></figure>
<h3 id="计算图">计算图</h3><p>为了在Python中执行高效的数值计算，我们通常引入类似<strong><a href="http://www.numpy.org/" target="_blank" rel="external">NumPy</a></strong>这种库来执行开销昂贵的操作。例如在Python之外其他高效的语言来执行矩阵乘法这类操作。不幸的是，每次操作之后切换回Python的动作依然是一个巨大的开销。这种开销特别的差，如果你想要以一种分布式的方式运行在GPU上的话，这里传输数据将会是一个巨大的开销。</p>
<p>TensorFlow也会在Python外部执行大量的运算，但它做了进一步的处理来规避了这种开销。取代独立于Python运行单一的代价昂贵的操作的模式，TensorFlow的方式是通过在Python中描述一个可交互的操作图，然后完全在Python之外进行运行。<strong>Theano</strong>或者<strong>Torch</strong>也有与此类似的实现。</p>
<p>在这里Python代码的作用是用来在外部定义一个操作图，然后决定具体哪一部分的运算图要被运行。详细内容，见<a href="/2017/02/20/【Tensorflow%20r1.0%20文档翻译】TensorFlow入门/">TensorFlow入门</a>中的<a href="/2017/02/20/【Tensorflow%20r1.0%20文档翻译】TensorFlow入门#用于计算的Graph（图）">用于计算的Graph（图）</a>部分。</p>
<h2 id="构建一个Softmax回归模型">构建一个Softmax回归模型</h2><p>这一节，我们通过一个单一的线性层来构建一个softmax回归模型。在下一节中，我们将把这个softmax回归扩展为一个多层卷积网络。</p>
<h3 id="占位符（Placeholders）">占位符（Placeholders）</h3><p>我们通过创建输入的图像创建的节点和输出的类别创建的分类来构建一个计算图。</p>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">x = tf.placeholder(tf.float32, <span class="built_in">shape</span>=[<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line">y_ = tf.placeholder(tf.float32, <span class="built_in">shape</span>=[<span class="keyword">None</span>, <span class="number">10</span>])</div></pre></td></tr></table></figure>
<p>这里<code>x</code>和<code>y_</code>不是具体的值。相反，他们都是一个<code>placeholder</code>（占位符）–当我们让TensorFlow开始执行计算时才被输入具体值。</p>
<p>输入图像的<code>x</code>包含一个2维的浮点数张量。这里我们赋予它一个<code>shape</code>（形状）为<code>[None, 784]</code>，其中<code>784</code>是由28乘28像素的图片单行展开后的维度数，<code>None</code>表示第一个维度大小不定，可以是任意尺寸，用以指代batch的大小。目标输出类别<code>y_</code>也包含一个2维的tensor，它每行都是一个10维的one-hot向量，用于表示相应的MNIST图像属于哪个数字类（0到9）。</p>
<p>虽然<code>placeholder</code>的<code>shape</code>参数是可选的，但有了它，TensorFlow能够自动捕捉因数据维度不一致导致的错误。</p>
<h3 id="变量（Variables）">变量（Variables）</h3><p>我们现在为我们的模型定义了权值<code>W</code>和偏置量<code>b</code>。可以将它们当作额外的输入量，但是TensorFlow有一个更好的处理方式：<code>Variable</code>。一个<code>Variable</code>代表TensorFlow计算图中的一个值，能够在计算过程中使用，甚至进行修改。在机器学习的应用过程中，模型参数一般用<code>Variable</code>来表示。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">W</span> = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</div><div class="line"><span class="attr">b</span> = tf.Variable(tf.zeros([<span class="number">10</span>]))</div></pre></td></tr></table></figure>
<p>我们在调用<code>tf.Variable</code>的时候传入初始值。在这个例子中，我们把<code>W</code>和<code>b</code>初始化全为0的tensor。<code>W</code>是一个$784×10$的矩阵（因为我们有784个输入特征以及10个输出值），<code>b</code>是一个10维向量（因为我们有10种分类）。</p>
<p>在<code>Variable</code>可以在session中被使用之前，他们必须被session初始化。此步骤使用已经指定的初始值（在这里tensor全部以0填充），并将它们分配给每个$Variable$。下面的代码可以一次初始化全部的<code>Variables</code>：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">tf</span><span class="selector-class">.global_variables_initializer</span>())</div></pre></td></tr></table></figure>
<h3 id="类别预测与损失函数">类别预测与损失函数</h3><p>现在我们可以实现我们自己的回归模型了。只需要一行代码！我们把向量化后的图片输入<code>x</code>和权重矩阵<code>W</code>相乘，加上偏置<code>b</code>，然后计算每个分类的softmax概率值。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">y</span> = tf.matmul(x,W) + b</div></pre></td></tr></table></figure>
<p>我们可以很容易地指定一个损失函数。损失表示模型的预测效果在单个示例的糟糕程度；在我们的训练过程中，我们会尽量去最小化这个值。在这里，我们的损失函数就是介于目标值和应用于模型预测的softmax激励函数之间的交叉熵。正如我们在新手教学中用到的稳定的方程一样：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">cross_entropy</span> = tf.reduce_mean(</div><div class="line">    tf.nn.softmax_cross_entropy_with_logits(<span class="attr">labels=y_,</span> <span class="attr">logits=y))</span></div></pre></td></tr></table></figure>
<p>请注意，<code>tf.nn.softmax_cross_entropy_with_logits</code>内部将softmax应用到非规范化的模型预测中，并且将所有的结果求和，通过<code>tf.reduce_mean</code>来取这些和的平均值。</p>
<h2 id="训练模型">训练模型</h2><p>现在我们已经定义好了我们的模型和用于训练的损失函数，那么用TensorFlow进行训练就很简单了。由于TensorFlow知道整个计算图，所以它可以使用自动微分来找出关于每个变量的损失梯度。TensorFlow有多种<a href="https://www.tensorflow.org/api_guides/python/train#optimizers" target="_blank" rel="external">内置的优化算法</a>。对于这个例子，我们将使用最大梯度下降，步长为0.5，来下降交叉熵。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train_step = tf<span class="selector-class">.train</span><span class="selector-class">.GradientDescentOptimizer</span>(<span class="number">0.5</span>).minimize(cross_entropy)</div></pre></td></tr></table></figure>
<p>TensorFlow在这一行中实际上是在计算图中添加新的操作。这些操作包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。</p>
<p>返回的<code>train_step</code>操作对象，在运行时会使用梯度下降来更新参数。因此，整个模型的训练可以通过反复地运行<code>train_step</code>来完成。</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> <span class="symbol">_</span> <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</div><div class="line">  <span class="built_in">batch</span> = mnist.train.next_batch(<span class="number">100</span>)</div><div class="line">  train_step.run(feed_dict=&#123;x: <span class="built_in">batch</span>[<span class="number">0</span>], y_: <span class="built_in">batch</span>[<span class="number">1</span>]&#125;)</div></pre></td></tr></table></figure>
<p>每次训练迭代我们都会加入100个训练样本。然后，然后执行一次<code>train_step</code>操作，并通过<code>feed_dict</code>将<code>placeholder</code>tensor<code>x</code>和<code>y_</code>，用训练训练数据替代。请注意，您可以使用<code>feed_dict</code>替换计算图形中的任何tensor。–它不仅仅局限于<code>placeholder</code>。</p>
<h3 id="评估模型">评估模型</h3><p>那么我们的模型表现如何呢？</p>
<p>首先，来让我们找出那些预测正确的标签。<code>tf.argmax</code>是一个很有用的方法，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。例如，<code>tf.argmax(y，1)</code>是我们的模型认为每个输入最可能的标签，而<code>tf.argmax(y_，1)</code>是正确的标签。我们可以用<code>tf.equal</code>来检查我们我预测值与真实值是否相符。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(<span class="keyword">y</span>,<span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_,<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>这行代码会给我们一组布尔值。为了确定正确预测项的比例，我们可以把布尔值转换成浮点数，然后取平均值。例如，<code>[True, False, True, True]</code>会变成<code>[1,0,1,1]</code>，取平均值后得到<code>0.75</code>.</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div></pre></td></tr></table></figure>
<p>最后，我们计算所学习到的模型在测试数据集上面的正确率。</p>
<figure class="highlight roboconf"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(accuracy.eval(feed_dict=&#123;<span class="attribute">x</span>: mnist<span class="variable">.test</span><span class="variable">.images</span>, y_: mnist<span class="variable">.test</span><span class="variable">.labels</span>&#125;))</div></pre></td></tr></table></figure>
<h2 id="构建多层卷积网络">构建多层卷积网络</h2><p>在MNIST数据集上获得92%的准确率是相当差的。甚至差到令人感到尴尬的地步。在本节中，我们将解决这个问题。我们将从一个非常简单的模型跳转到一个中等复杂的模型：一个小型的卷积神经网络。这将会使我们得到一个大概在99.2%的准确率。–虽然不是最好的结果，但还算是令人满意的一个结果。</p>
<h3 id="权值初始化">权值初始化</h3><p>要创建这个模型，我们需要创建很多权值和偏置量。通常情况下，应该使用少量噪音数据来初始化权值以用于打破对称性，并且防止0梯度产生。由于我们使用的是<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks" target="_blank" rel="external">ReLU</a>)神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。为了不在建立模型的时候反复做初始化操作，我们定义两个用于初始化的函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">  initial = tf.constant(<span class="number">0.1</span>, shape=shape)</div><div class="line">  <span class="keyword">return</span> tf.Variable(initial)</div></pre></td></tr></table></figure>
<h3 id="卷积和池化">卷积和池化</h3><p>TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做最大池（max pooling）。为了使代码更简洁，我们把这部分抽象成一个函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></div><div class="line">  <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>],</div><div class="line">                        strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div></pre></td></tr></table></figure>
<h3 id="第一层卷积">第一层卷积</h3><p>现在，我们可以实现我们的第一层了。它由一个卷积接一个最大池组成。卷积在每个5x5的patch中算出32个特征。卷积的权重tensor形状是<code>[5, 5, 1, 32]</code>。前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 而对于每一个输出通道都有一个对应的偏置量。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</div><div class="line">b_conv1 = bias_variable([<span class="number">32</span>])</div></pre></td></tr></table></figure>
<p>为了用这一层，我们把<code>x</code>变成一个4维tensor，其第<code>2</code>、第<code>3</code>维对应图片的宽、高，最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">x_image = tf.reshape(x, [<span class="number">-1</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>])</div></pre></td></tr></table></figure>
<p>然后我们将<code>x_image</code>与权值tensor进行卷积，加上偏置量，然后应用ReLU激励函数，最后最大池化。<code>max_pool_2x2</code>方法可将图片大小缩小为14x14。</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div></pre></td></tr></table></figure>
<h3 id="第二层卷积">第二层卷积</h3><p>为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="attr">W_conv2</span> = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</div><div class="line"><span class="attr">b_conv2</span> = bias_variable([<span class="number">64</span>])</div><div class="line"></div><div class="line"><span class="attr">h_conv2</span> = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line"><span class="attr">h_pool2</span> = max_pool_2x2(h_conv2)</div></pre></td></tr></table></figure>
<h3 id="密集连接层">密集连接层</h3><p>现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。我们把池化层输出的tensor reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">W_fc1 = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</div><div class="line">b_fc1 = bias_variable([<span class="number">1024</span>])</div><div class="line"></div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div></pre></td></tr></table></figure>
<h3 id="Dropout">Dropout</h3><p>为了减少过拟合，我们在输出层之前加入<a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf" target="_blank" rel="external">dropout</a>。我们用一个<code>placeholder</code>来代表一个神经元的输出在dropout中保持不变的概率。这样我们可以在训练过程中启用dropout，在测试过程中关闭dropout。 TensorFlow的<code>tf.nn.dropout</code>操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。</p>
<blockquote>
<p>对于这个小型卷积网络，性能实际上几乎相同，没有压差。Dropout往往是非常有效的减少过度拟合的方式，但当训练非常大的神经网络时，它是最有用的。</p>
</blockquote>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">keep_prob</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="attr">h_fc1_drop</span> = tf.nn.dropout(h_fc1, keep_prob)</div></pre></td></tr></table></figure>
<h3 id="读出层">读出层</h3><p>最后，我们添加一个softmax层，就像前面的单层softmax 回归一样。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="attr">W_fc2</span> = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</div><div class="line"><span class="attr">b_fc2</span> = bias_variable([<span class="number">10</span>])</div><div class="line"></div><div class="line"><span class="attr">y_conv</span> = tf.matmul(h_fc1_drop, W_fc2) + b_fc2</div></pre></td></tr></table></figure>
<h3 id="训练和评估模型">训练和评估模型</h3><p>这个模型的效果如何呢？为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码。</p>
<p>不过有以下几点不同：</p>
<ul>
<li>我们将用更复杂的ADAM优化器来替换最陡的梯度下降优化器。</li>
<li>我们将在<code>feed_dict</code>中包含附加参数<code>keep_prob</code>来控制丢失率。</li>
<li>我们将在训练过程中的每执行100次迭代时，添加一次日志记录。</li>
</ul>
<p>随时可以继续运行此代码，但它会进行20,000次训练迭代，可能需要一段时间（可能长达半小时），具体时间取决于您的处理器。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">cross_entropy = <span class="keyword">tf</span>.reduce_mean(</div><div class="line">    <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))</div><div class="line">train_step = <span class="keyword">tf</span>.train.AdamOptimizer(<span class="number">1</span><span class="keyword">e</span>-<span class="number">4</span>).minimize(cross_entropy)</div><div class="line">correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(y_conv,<span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_,<span class="number">1</span>))</div><div class="line">accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div><div class="line">sess.run(<span class="keyword">tf</span>.global_variables_initializer())</div><div class="line"><span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="number">20000</span>):</div><div class="line">  batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">  <span class="keyword">if</span> i%<span class="number">100</span> == <span class="number">0</span>:</div><div class="line">    train_accuracy = accuracy.<span class="built_in">eval</span>(feed_dict=&#123;</div><div class="line">        <span class="keyword">x</span>:batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_pro<span class="variable">b:</span> <span class="number">1.0</span>&#125;)</div><div class="line">    <span class="keyword">print</span>(<span class="string">"step %d, training accuracy %g"</span>%(i, train_accuracy))</div><div class="line">  train_step.run(feed_dict=&#123;<span class="keyword">x</span>: batch[<span class="number">0</span>], y_: batch[<span class="number">1</span>], keep_pro<span class="variable">b:</span> <span class="number">0.5</span>&#125;)</div><div class="line"></div><div class="line"><span class="keyword">print</span>(<span class="string">"test accuracy %g"</span>%accuracy.<span class="built_in">eval</span>(feed_dict=&#123;</div><div class="line">    <span class="keyword">x</span>: mnist.test.images, y_: mnist.test.labels, keep_pro<span class="variable">b:</span> <span class="number">1.0</span>&#125;))</div></pre></td></tr></table></figure>
<p>以上代码，在最终测试集上的准确率大概是99.2%。</p>
<p>目前为止，我们已经学会了用TensorFlow快捷地搭建、训练和评估一个复杂一点儿的深度学习模型。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/02/22/【Tensorflow r1.0 文档翻译】机器学习的HelloWorld -- MNIST手写数字识别/" itemprop="url">
                【Tensorflow r1.0 文档翻译】机器学习的HelloWorld -- MNIST手写数字识别
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-02-22T19:50:58+08:00" content="2017-02-22">
            2017-02-22
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/02/22/【Tensorflow r1.0 文档翻译】机器学习的HelloWorld -- MNIST手写数字识别/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/02/22/【Tensorflow r1.0 文档翻译】机器学习的HelloWorld -- MNIST手写数字识别/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>本教程面向那些不熟悉<strong>机器学习</strong>和<strong>TensorFlow</strong>的读者。如果你已经知道MNIST是什么，softmax（多项Logistic）回归是什么，你可能更喜欢这个<a href="/2017/02/26/【Tensorflow%20r1.0%20文档翻译】深入MNIST--专家级/">更快节奏的教程</a>。在开始教程之前，请确认<a href="https://www.tensorflow.org/install/index" target="_blank" rel="external">安装TensorFlow</a>。</p>
<p>当一个人开始学习如何编程时，有一个传统，就是编写的第一个程序是能够打印”Hello World.”的程序。正如编程中的”Hello World”一样，机器学习中有MNIST。</p>
<p>MNIST是一个简单的计算机视觉数据集。它由像以下这样的手写数字的图像组成：</p>
<p><img src="/img/17_02_22/001.png" alt=""></p>
<p>它还包括每个图像的标签，用于标识是哪个数字。例如，上述图像的标签是<code>5</code>,<code>0</code>,<code>4</code>和<code>1</code>。</p>
<p>在本教程中，我们将训练一个模型，用来查看图像并预测它们是什么数字。我们的目标不是训练一个真正精准的，拥有高性能的模型，而是浅尝辄止的来体验一下TensorFlow的使用。 - 尽管我们稍后会给出实现这种效果的代码。因此，我们将从一个非常简单的，称为<strong>Softmax回归</strong>的模型开始。</p>
<p>这个教程的实际代码非常短，其中真正有趣的东西只有三行代码。然而，了解背后的想法是非常重要的：TensorFlow如何工作和核心机器学习概念。因此，我们将非常仔细地完成这部分代码。</p>
<h2 id="关于本教程">关于本教程</h2><p>本教程是对<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_softmax.py" target="_blank" rel="external">mnist_softmax.py</a>中的代码进行逐行解释。</p>
<p>您可以通过以下几种不同的方式使用本教程：</p>
<ul>
<li>在阅读每行的解释时，将每个代码段逐行复制并粘贴到Python环境中。</li>
<li>在阅读教程期间，运行整个mnist_softmax.py，并使用本教程来了解您不清楚的代码行。</li>
</ul>
<p>我们将在本教程中完成：</p>
<ul>
<li>了解MNIST数据和softmax回归。</li>
<li>创建一个函数，它是一个用于识别数字的模型，其识别原理是基于查看图像中的每个像素的值来实现的。</li>
<li>使用TensorFlow来训练模型以识别数字，其训练方式是“查看”数千个示例（运行我们的第一个TensorFlow会话来执行此逻辑）。</li>
<li>使用我们的测试数据检查模型的精度。</li>
</ul>
<h2 id="MNIST数据集">MNIST数据集</h2><p>MNIST数据集托管在<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="external">Yann LeCun的站点</a>。如果您要复制粘贴本教程中的代码，请从这两行代码开始，这两行代码将自动下载并读入数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</div></pre></td></tr></table></figure>
<p>MNIST数据被分为三部分：55,000个训练数据（<code>mnist.train</code>），10,000个测试数据（<code>mnist.test</code>）和5,000个验证数据（<code>mnist.validation</code>）。这种切分是非常重要的：它能通过一部分我们并没有实际用来训练学习的数据，来确保我们的算法有很好的通用性。</p>
<p>如前所述，每个MNIST数据点有两个部分：手写数字的图像和相应的标签。我们称为图像”x”和标签”y”。训练集和测试集都包含图像及其相应的标签;例如训练图像是<code>mnist.train.images</code>，训练标签是<code>mnist.train.labels</code>。</p>
<p>每张图像的尺寸是28×28像素。我们可以把它解释为一个大的数组：</p>
<p><img src="/img/17_02_22/002.png" alt=""></p>
<p>我们可以将这个数组变成一个长度为28x28 = 784的向量。如何平铺数组其实并不重要，重要的是要保证图像和数组之间的一致性。从这个角度来看，MNIST图像只是784维向量空间中的一堆点，具有<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">非常丰富的结构</a>（警告：计算密集的可视化）。</p>
<p>展平数据丢弃了关于图像的2D结构的信息。这样做是不是并不够好？没错，最好的计算机视觉方法确实可以利用这种2D结构信息，我们将在后面的教程进行介绍。但是我们在这里所使用的一种简单方法：<strong>softmax回归</strong>（下面会给出定义），不会利用到这种信息。</p>
<p><code>mnist.train.images</code>是形状为<code>[55000,784]</code>的张量（n维数组）。第一个维度是在列表中图像的索引，第二个维度是每个图像中的每个像素点的索引。对于特定图像中的特定像素，张量中的每个条目是介于0和1之间的像素强度。</p>
<p><img src="/img/17_02_22/003.png" alt=""></p>
<p>MNIST中的每个图像都有相应的标签，标签用介于0到9之间的数字表示图像中绘制的数字。</p>
<p>为了达到本教程的目的，我们需要要将我们的标签作为“one-hot 向量”。one-hot向量是指在大多数维度上数值为0，仅在其中一个维度上数值为1的向量。在这种情况下，第n个数字将被表示为在第n维中为1的向量。例如，3将表示为$[0,0,0,1,0,0,0,0,0,0]$。因此，<code>mnist.train.labels</code>是一个形状为<code>[55000, 10]</code>的数字矩阵。</p>
<p><img src="/img/17_02_22/004.png" alt=""></p>
<p>现在，我们可以开始构建我们的模型啦！</p>
<h2 id="Softmax回归">Softmax回归</h2><p>我们知道MNIST中的每个图像都是一个在0和9之间的手写数字。因此，对于给定的图像，只有10种可能的结果。我们想要能够看到一个图像，并给出它的每个数字的概率。例如，用我们的模型来查看一个9的图片，80％的可能性确认是9，但有5％的可能是8（因为8和9顶部都有一个圈），剩余的可能性分布在其他数值上。</p>
<p>这是一个<strong>softmax回归</strong>的典型案例。如果你想给一个对象赋予其表示不同数字的概率，可以使用softmax，因为softmax可以得出一组介于0到1之间的值，并且这组值加起来结果为1。即使在以后，当我们训练其他更复杂的模型时，最后一步也是一层softmax。</p>
<p>softmax回归有两个步骤：首先我们将图片中属于某个特定数字的证据（evidence）相加，然后将该证据转换为概率。</p>
<p>为了计算给定图像在特定类中的证据，我们对像素强度进行加权求和。如果像素点有很高的强度表示和对应的标签数字不匹配，那么这一点的权值是负数，相反，权值是正数。</p>
<p>下面的图片显示了一个模型学习到的图片上每个像素对于特定数字类的权值。红色表示负权重，蓝色表示正权重。</p>
<p><img src="/img/17_02_22/005.png" alt=""></p>
<p>我们还需要增加一个偏置量（bias），因为输入往往会带有一些无关的干扰量。因此对于给定的输入图片<strong>x</strong>它代表的是数字<strong>i</strong>的证据可以表示为：</p>
<p>$$<br>\text{evidence}_i = \sum_j W_{i,~ j} x_j + b_i<br>$$</p>
<p>其中，$W_i$表示权值，$b_i$代表$i$类别的偏置量，$j$代表给定图片$x$的像素索引，用于像素求和。然后用softmax函数可以把这些证据转换成概率<strong>y</strong>：</p>
<p>$$<br>y = \text{softmax}(\text{evidence})<br>$$</p>
<p>这里softmax用作“激活”或“链接”函数，将我们的线性函数的输出变形为我们想要的形式 - 在这里，也就是10种数字的概率分布。你可以把它看作是将证据转换为每种分类的概率。它的定义是：</p>
<p>$$<br>\text{softmax}(x) = \text{normalize}(\exp(x))<br>$$</p>
<p>如果你把这个方程展开，你将得到：</p>
<p>$$<br>\text{softmax}(x)_i = \frac{\exp(x_i)}{\sum_j \exp(x_j)}<br>$$</p>
<p>但通常我们把softmax定义为第一种形式：对其输入求幂，然后将其归一化处理。这里幂运算表示，更大的证据对应更大的假设模型（hypothesis）里面的乘数权重值。反之，拥有更少的证据意味着在假设模型里面拥有更小的乘数系数。假设模型里的权值不可以是0值或者负值。Softmax然后会正则化这些权重值，使它们的总和等于1，以此构造一个有效的概率分布。（更多的关于Softmax函数的信息，可以参考Michael Nieslen的书里面的这个<a href="http://neuralnetworksanddeeplearning.com/chap3.html#softmax" target="_blank" rel="external">部分</a>，其中有关于softmax的可交互式的可视化解释。）</p>
<p>softmax回归可以表示为下面这张图，不过真实情况下会有更多的$x$值。我们通过计算出$x$的权值之和加上一个偏置量，然后代入到一个softmax中，来计算出每个输出值。</p>
<p><img src="/img/17_02_22/006.png" alt=""></p>
<p>如果我们把它写成方程的形式，我们将得到：</p>
<p><img src="/img/17_02_22/007.png" alt=""></p>
<p>我们可以“向量化”这个过程，把它变成矩阵乘法和向量加法。这有助于提升计算效率。 （这也是一个有用的思考方式。）</p>
<p><img src="/img/17_02_22/008.png" alt=""></p>
<p>更紧凑的表达形式如下：</p>
<p>$$<br>y = \text{softmax}(Wx + b)<br>$$</p>
<p>现在让我们把它变成TensorFlow可以使用的形式。</p>
<h2 id="回归的实现">回归的实现</h2><p>为了在Python中进行高效的数值计算，我们通常使用像<strong><a href="http://www.numpy.org/" target="_blank" rel="external">NumPy</a></strong>这样的库，它们会把类似矩阵乘法这样的复杂运算使用其他外部语言实现。不幸的是，从外部计算切换回Python的每一个操作，仍然是一个很大的开销。如果要在GPU上以分布式方式运行计算，那么这种开销尤其糟糕，其中传输数据的成本很高。</p>
<p>TensorFlow也在Python之外做了很大量的计算工作，但它做了进一步的完善以改善前面说的那种切换。TensorFlow不是独立于Python运行一个昂贵的操作，而是让我们可以先用图描述一系列可交互的计算操作，然后全部一起在Python之外运行。（这样类似的运行方式，可以在不少的机器学习库中看到。）</p>
<p>要使用TensorFlow，首先我们需要导入它。</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div></pre></td></tr></table></figure>
<p>我们通过操作符号变量来描述这些交互的操作单元。让我们用下面的方式创建一个：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">x</span> = tf.placeholder(tf.float32, [None, <span class="number">784</span>])</div></pre></td></tr></table></figure>
<p><code>x</code>不是一个特定的值。它是一个占位符(<code>placeholder</code>)，当我们要求TensorFlow运行一个计算时，我们将输入一个值。我们希望能够输入任意数量的MNIST图像，其中每个图像都被展开为784维向量。我们将其表示为float类型的2-D张量，形状为<code>[None, 784]</code>。（这里的<code>None</code>表示维度可以是任何长度。）</p>
<p>我们的模型还需要权重和偏差。当然我们可以把它们当做是另外的输入（使用占位符），但TensorFlow有一个更好的方法来表示它们：<code>Variable</code>。<code>Variable</code>代表一个可修改的张量，它存在于TensorFlow中用于描述交互性操作的图中。在计算过程中，它们可以被拿来使用甚至可以修改。对于机器学习应用，一般都会有模型参数，可以用Variable表示。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">W</span> = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</div><div class="line"><span class="attr">b</span> = tf.Variable(tf.zeros([<span class="number">10</span>]))</div></pre></td></tr></table></figure>
<p>我们通过给与<code>tf.Variable</code>初始值来创建<code>Variable</code>:在这种情况下，我们将<code>W</code>和<code>b</code>初始化为全部为0的张量。因为我们要通过学习得到<code>W</code>和<code>b</code>，因此它们的初始值具体是什么并不重要。</p>
<p>注意，<code>W</code>的形状为<code>[784,10]</code>，因为我们想要用784维的图片向量乘以它以得到一个10维的证据值向量，其中每一位对应着不同数字类别。<code>b</code>的形状是<code>[10]</code>，所以我们可以直接把它加到输出上面。</p>
<p>现在，我们可以实现我们的模型啦。只需要一行代码！</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">y = tf<span class="selector-class">.nn</span><span class="selector-class">.softmax</span>(tf.matmul(x, W) + b)</div></pre></td></tr></table></figure>
<p>首先，我们通过表达式<code>tf.matmul(x, W)</code>将<code>x</code>和<code>W</code>相乘。这对应于前面方程中的$Wx$，<code>x</code>是一个拥有多个输入的2D张量。紧接着，我们加上<code>b</code>，最后，代入到<code>tf.nn.softmax</code>中。</p>
<p>就是这样，在几行用来设置变量的代码之后，我们只需要一行代码就可以定义好我们的模型。这不仅仅是因为TensorFlow被设计为使<strong>softmax回归</strong>变得特别简单，它也用这种非常灵活的方式来描述其他各种数值计算，从机器学习模型对物理学模拟仿真模型。一旦被定义好之后，我们的模型就可以在不同的设备上运行：计算机的CPU，GPU，甚至是手机！</p>
<h2 id="训练">训练</h2><p>为了训练我们的模型，我们首先需要定义一个指标来评估这个模型是好的。实际上，在机器学习中，我们通常定义指标来表示一个模型是坏的，这个指标称为成本（cost）或损失（loss），然后尽量最小化这个指标。</p>
<p>一个非常常见的，非常好的用来衡量模型损失的函数称为“<strong>交叉熵(cross-entropy)</strong>”。交叉熵产生于信息论里面的信息压缩编码技术，但是它后来演变成为从博弈论到机器学习等其他领域里的重要技术手段。它的定义如下：</p>
<p>$$<br>H_{y’}(y) = -\sum_i y’_i \log(y_i)<br>$$</p>
<p><strong>y</strong>是我们预测的概率分布,<strong>y’</strong>是实际的分布（我们输入的one-hot vector)。比较粗糙的理解是，交叉熵是用来衡量相对于真实值我们所给出的预测的低效性。有关交叉熵的更详细的讨论超出了本教程的范畴，但<a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="external">理解它的原理</a>很有必要。</p>
<p>为了计算交叉熵，我们首先需要添加一个新的占位符用于输入正确值：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">y_</span> = tf.placeholder(tf.float32, [None, <span class="number">10</span>])</div></pre></td></tr></table></figure>
<p>然后，我们可以实现交叉熵方法:$-\sum y’\log(y)$</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cross_entropy = <span class="keyword">tf</span>.reduce_mean(-<span class="keyword">tf</span>.reduce_sum(y_ * <span class="keyword">tf</span>.<span class="built_in">log</span>(<span class="keyword">y</span>), reduction_indices=[<span class="number">1</span>]))</div></pre></td></tr></table></figure>
<p>首先，<code>tf.log</code>计算了每个<code>y</code>的对数。接下来，我们将<code>y_</code>与相应的<code>tf.log(y)</code>的元素做乘法运算。然后，由于参数<code>reduction_indices=[1]</code>，<code>tf.reduce_sum</code>将<code>y</code>中的第二维中的元素相加求和。最后，通过<code>tf.reduce_mean</code>计算批次中所有示例的平均值。</p>
<p>注意，在源码中，我们不使用这些信息，因为它在数值上并不稳定。取而代之的是，我们将<code>tf.nn.softmax_cross_entropy_with_logits</code>用于非规范化的逻辑上（例如，我们对<code>tf.matmul(x, W) + b</code>使用<code>softmax_cross_entropy_with_logits</code>），因为这样在数值上更稳定方法，它在内部执行了softmax的计算。在你的代码中考虑使用<code>tf.nn.softmax_cross_entropy_with_logits</code>来代替之前的逻辑。</p>
<p>现在，我们知道了我们想要我们的模型做什么，使用TensorFlow来训练它也非常简单。因为TensorFlow知道用于计算的整个图（graph），它会自动地使用<strong><a href="http://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="external">反向传播算法</a></strong>来有效地确定你的变量是如何影响你想要最小化的那个成本值的。然后它可以应用您选择的优化算法修改变量和减少损失。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">train_step = tf<span class="selector-class">.train</span><span class="selector-class">.GradientDescentOptimizer</span>(<span class="number">0.5</span>).minimize(cross_entropy)</div></pre></td></tr></table></figure>
<p>在这里，我们通过使用学习率为0.5的<a href="https://en.wikipedia.org/wiki/Gradient_descent" target="_blank" rel="external">梯度下降算法</a>令TensorFlow最小化<code>cross_entropy</code>（交叉熵）。梯度下降是一个简单的程序，它的原理是每次向着减少损失的方向移动一小步，来最小化代价函数。但TensorFlow也提供了<a href="https://www.tensorflow.org/api_guides/python/train#optimizers" target="_blank" rel="external">很多其他的优化算法</a>，只需要简单的调整一行代码就可以随意切换。</p>
<p>TensorFlow在这里实际上所做的是，它会在后台给描述你的计算的那张图里面增加一系列新的计算操作单元，用于实现反向传播算法和梯度下降算法。然后，它返回给你的只是一个单一的操作，当运行这个操作时，它用梯度下降算法训练你的模型，微调你的变量，不断减少成本。</p>
<p>我们现在可以在<code>InteractiveSession</code>中启动我们的模型：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">sess</span> = tf.InteractiveSession()</div></pre></td></tr></table></figure>
<p>我们首先要创建一个操作来初始化我们创建的变量：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">tf</span><span class="selector-class">.global_variables_initializer</span>()<span class="selector-class">.run</span>()</div></pre></td></tr></table></figure>
<p>让我们开始执行训练 - 我们将运行1000次训练步骤！</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">  batch_xs, batch_ys = mnist<span class="selector-class">.train</span><span class="selector-class">.next_batch</span>(<span class="number">100</span>)</div><div class="line">  sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)</div></pre></td></tr></table></figure>
<p>每循环一次，我们将从我们的训练集中得到一批100个随机数据点。然后我们用这些数据点作为参数替换之前的占位符来运行<code>train_step</code>。</p>
<p>使用小批随机数据称为<strong>随机训练(stochastic training)</strong> - 在这里更确切的说是随机梯度下降训练。理想情况下，我们希望将所有数据用于训练的每个步骤，因为这能给我们更好的训练结果，但很明显这需要很大的计算开销。所以，每一次训练我们可以使用不同的数据子集，这样做既可以减少计算开销，又可以最大化地学习到数据集的总体特性。</p>
<h2 id="评估我们的模型">评估我们的模型</h2><p>那么我们的模型表现如何呢？</p>
<p>首先，来让我们找出那些预测正确的标签。<code>tf.argmax</code>是一个很有用的方法，它能给出某个tensor对象在某一维上的其数据最大值所在的索引值。例如，<code>tf.argmax(y，1)</code>是我们的模型认为每个输入最可能的标签，而<code>tf.argmax(y_，1)</code>是正确的标签。我们可以用<code>tf.equal</code>来检查我们我预测值与真实值是否相符。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(<span class="keyword">y</span>,<span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_,<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>这行代码会给我们一组布尔值。为了确定正确预测项的比例，我们可以把布尔值转换成浮点数，然后取平均值。例如，<code>[True, False, True, True]</code>会变成<code>[1,0,1,1]</code>，取平均值后得到<code>0.75</code>.</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div></pre></td></tr></table></figure>
<p>最后，我们计算所学习到的模型在测试数据集上面的正确率。</p>
<figure class="highlight roboconf"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">print(sess.run(accuracy, feed_dict=&#123;<span class="attribute">x</span>: mnist<span class="variable">.test</span><span class="variable">.images</span>, y_: mnist<span class="variable">.test</span><span class="variable">.labels</span>&#125;))</div></pre></td></tr></table></figure>
<p>结果大概维持在92%左右。</p>
<p>这种结果很好吗？其实并不是很好。其实，它相当差。这是因为我们使用的是一个非常简单的模型。我们可以通过做一些简单的修改，可以将正确率提高到97%。事实上，最优秀的模型可以达到超过99.7%的准确率！（想了解更多信息，可以看看这个关于各种模型的<a href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html" target="_blank" rel="external">性能对比列表</a>。)</p>
<p>比结果更重要的是，我们从这个模型中学习到的设计思想。不过，如果你仍然对这里的结果有点失望，可以查看<a href="/2017/02/26/【Tensorflow%20r1.0%20文档翻译】深入MNIST--专家级/">下一个教程</a>，在那里你可以学习如何用FensorFlow构建更加复杂的模型以获得更好的性能！</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/02/20/【Tensorflow r1.0 文档翻译】TensorFlow入门/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorFlow入门
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-02-20T21:42:58+08:00" content="2017-02-20">
            2017-02-20
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/02/20/【Tensorflow r1.0 文档翻译】TensorFlow入门/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/02/20/【Tensorflow r1.0 文档翻译】TensorFlow入门/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h2 id="TensorFlow入门">TensorFlow入门</h2><p>这是一个TensorFlow的入门指南。在你使用这份指南之前，请先<a href="https://www.tensorflow.org/install/" target="_blank" rel="external">安装TensorFlow</a>。在充分的使用本指南之前，您应该了解以下内容：</p>
<ul>
<li>如何使用Python进行编程。</li>
<li>至少对矩阵有一些了解</li>
<li>最好是对<strong>机器学习</strong>有一点了解。但即使你对<strong>机器学习</strong>有一点了解、或者甚至完全不了解，那么你很有必要读一读这一篇指南了。</li>
</ul>
<p>TensorFlow提供了多种API。即使是最低版本的TensorFlow 核心 API，也为您提供了完整的编程控制。如果您是机器学习研究人员，或需要对模型进行精细控制的人，那么我们建议你使用TensorFlow 核心代码，否则我们建议您使用TensorFlow Core API。这些更高级的API通常比TensorFlow 核心代码更容易学习和使用。此外，较高级别的API使重复性任务更容易上手，并且在不同用户之间更一致。高级API（如<strong>tf.contrib.learn</strong>）可帮助您管理数据集、估计量、训练和推断。注意，在一些高级TensorFlow API 中，方法名称包含<code>contrib</code>的API表示仍在开发中。一些<code>contrib</code>方法可能会在随后的TensorFlow版本中发生改变或过时。</p>
<p>本指南从TensorFlow 核心教程开始。稍后，我们将演示如何在<code>tf.contrib.learn</code>中实现相同的模型。了解TensorFlow核心原则将会给你提供一个很棒的心理模型，这个模型是用于说明当您使用更紧凑的更高级别的API时，内部是如何工作的。</p>
<h2 id="Tensors（张量）">Tensors（张量）</h2><p>TensorFlow中的数据的中心单元是<strong>Tensors(张量)</strong>。tensor是由一组原始数据组成，这些原始数据是由一组任意数量维度的数组形成。一个tensor的<strong>rank</strong>是表示它尺寸的一个数值。下面是几个tensor的例子：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="number">3</span> # a rank <span class="number">0</span> tensor; this is a scalar with shape []</div><div class="line">[<span class="number">1.</span> ,<span class="number">2.</span>, <span class="number">3.</span>] # a rank <span class="number">1</span> tensor; this is a <span class="type">vector</span> with shape [<span class="number">3</span>]</div><div class="line">[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]] # a rank <span class="number">2</span> tensor; a matrix with shape [<span class="number">2</span>, <span class="number">3</span>]</div><div class="line">[[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]], [[<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]]] # a rank <span class="number">3</span> tensor with shape [<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>]</div></pre></td></tr></table></figure>
<h2 id="TensorFlow核心教程">TensorFlow核心教程</h2><h3 id="导入TensorFlow">导入TensorFlow</h3><p>TensorFlow程序的标准导入语句如下：</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div></pre></td></tr></table></figure>
<p>这样做可以使得Python能够正常访问TensorFlow的所有类、方法和符号。我们的大多数文档都假设你已经这样做了。</p>
<h3 id="用于计算的Graph（图）">用于计算的Graph（图）</h3><p>也许你会认为TensorFlow Core的程序包含下面两部分组成：</p>
<ul>
<li>1.构建<strong>computational graph（用于计算的图）</strong></li>
<li>2.运行<strong>computational graph（用于计算的图）</strong></li>
</ul>
<p>一个<strong>computational graph（用于计算的图）</strong>是一系列排列在graph的节点上的TensorFlow操作单元。让我们来构建一个简单的<strong>computational graph</strong>。每个节点接受0个或多个tensor作为输入，并且产生一个tensor作为输出。<strong>常量类型</strong>是节点的一种类型。正如所有的TensorFlow常量一样，它是不接收输入的，并且输出一个它内部存储的值。我们可以按照下面的方式来创建两个浮点Tensor节点<code>node1</code>和<code>node2</code>：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">node1 = <span class="keyword">tf</span>.constant(<span class="number">3.0</span>, <span class="keyword">tf</span>.float32)</div><div class="line">node2 = <span class="keyword">tf</span>.constant(<span class="number">4.0</span>) # also <span class="keyword">tf</span>.float32 implicitly</div><div class="line"><span class="keyword">print</span>(node1, node2)</div></pre></td></tr></table></figure>
<p>执行结果如下：</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Tensor(<span class="string">"Const:0"</span>, shape=(), dtype=float32) Tensor(<span class="string">"Const_1:0"</span>, shape=(), dtype=float32)</div></pre></td></tr></table></figure>
<p>你会注意到，打印节点并不会如你所想的输出<code>3.0</code>和<code>4.0</code>。相反，这些节点会在计算时分别产生<code>3.0</code>和<code>4.0</code>。为了实际评估这些节点，我们必须以一个 <strong>session（会话）</strong> 来运行 <strong>computational graph</strong>。<strong>session（会话）</strong> 封装了TensorFlow运行时的控件和状态。</p>
<p>下面的代码创建了一个<code>Session</code>对象，并且执行了它的<code>run</code>方法来运行包含了<code>node1</code>和<code>node2</code>的<strong>computational graph</strong>的计算结果。通过在<strong>session</strong>中运行<strong>computational graph</strong>的代码如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sess = tf.Session()</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(sess.run([node1, node2])</span></span>)</div></pre></td></tr></table></figure>
<p>我们看到了我们期望看到的<code>3.0</code>和<code>4.0</code>的输出:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="number">3.0</span>, <span class="number">4.0</span>]</div></pre></td></tr></table></figure>
<p>我们可以通过将<code>Tensor</code>节点与操作节点（操作也是一种节点）组合起来的方式来构建更复杂的计算。例如，我们可以将两个常量节点执行加法操作，并且产生一个新的graph，代码如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">node3 = tf.add(node1, node2)</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"node3: "</span>, node3)</span></span></div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"sess.run(node3): "</span>,sess.run(node3)</span></span>)</div></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node3:  Tensor(<span class="string">"Add_2:0"</span>, shape=(), dtype=float32)</div><div class="line">sess.run(node3):  7.0</div></pre></td></tr></table></figure>
<p>TensorFlow提供了一个叫做<strong>TensorBoard</strong>的很实用的程序，它可以将computational graph可视化的展示出来。下面是通过TensorBoard来可视化一个graph的效果：</p>
<p><img src="/img/17_02_20/001.png" alt=""></p>
<p>由于我们用到的是常量，因此这个图看起来并不是特别有趣，因为它总是产生一个恒定的结果。graph可以被参数化，并且通过<strong>placeholders（占位符）</strong>来接受外部的输入。<strong>placeholders（占位符）</strong>表示对稍后所提供的值的一个承诺。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="attr">a</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="attr">b</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="attr">adder_node</span> = a + b  # + 是tf.add(a, b)的缩写形式</div></pre></td></tr></table></figure>
<p>上面三行的表达形式看起来有点像一个方法，或lambda表达式：其中我们定义两个输入参数（<code>a</code>和<code>b</code>），然后对它们执行一个操作。我们可以通过多个输入来计算这个graph的执行结果，其中我们的输入是通过<code>feed_dict</code>参数来指定对这些<strong>placeholders（占位符）</strong>提供具体值的<code>Tensors</code>的输入的：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">print</span>(<span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">adder_node</span>, &#123;<span class="attribute">a</span>: <span class="number">3</span>, b:<span class="number">4.5</span>&#125;))</div><div class="line"><span class="selector-tag">print</span>(<span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">adder_node</span>, &#123;<span class="attribute">a</span>: [<span class="number">1</span>,<span class="number">3</span>], b: [<span class="number">2</span>, <span class="number">4</span>]&#125;))</div></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="number">7.5</span></div><div class="line">[ <span class="number">3.</span>  <span class="number">7.</span>]</div></pre></td></tr></table></figure>
<p>在TensorBoard中，graph看起来是这个样子：</p>
<p><img src="/img/17_02_20/002.png" alt=""></p>
<p>我们可以通过添加其他操作，来让我们的<strong>computational graph</strong>看起来更复杂。例如：</p>
<figure class="highlight armasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">add_and_triple </span>= <span class="keyword">adder_node </span>* <span class="number">3</span>.</div><div class="line"><span class="symbol">print</span>(sess.run(<span class="keyword">add_and_triple, </span>&#123;a: <span class="number">3</span>, <span class="keyword">b:4.5&#125;))</span></div></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">22<span class="selector-class">.5</span></div></pre></td></tr></table></figure>
<p>上面的computational graph在TensorBoard中看起来是这样的：</p>
<p><img src="/img/17_02_20/003.png" alt=""></p>
<p>在机器学习中，我们通常需要一个可以接受任意输入的模型，例如上面的模型。为了使模型可训练，我们需要能够修改<code>graph</code>以获得具有相同输入的新输出。<strong>Variables（变量）</strong>允许我们向graph中添加可训练的参数。它们由一个类型和初始值组成：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="attr">W</span> = tf.Variable([.<span class="number">3</span>], tf.float32)</div><div class="line"><span class="attr">b</span> = tf.Variable([-.<span class="number">3</span>], tf.float32)</div><div class="line"><span class="attr">x</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="attr">linear_model</span> = W * x + b</div></pre></td></tr></table></figure>
<p>当调用<code>tf.constant</code>时，常量被初始化，它们的值永远不会改变。相比之下，变量<code>tf.Variable</code>在调用时不会被初始化。要初始化TensorFlow程序中的所有变量，必须显式调用特殊的初始化操作，如下所示：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">init</span> = tf.global_variables_initializer()</div><div class="line">sess.run(<span class="keyword">init</span>)</div></pre></td></tr></table></figure>
<p><code>init</code>是TensorFlow的sub-graph的一个重要的操作，它用于初始化所有的全局变量。在这里直到我们调用<code>sess.run</code>之前，变量是未初始化的。</p>
<p>由于<code>x</code>是一个占位符，因此我们可以同时计算<code>linear_model</code>几个值，如下所示：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">print</span>(<span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">linear_model</span>, &#123;<span class="attribute">x</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]&#125;))</div></pre></td></tr></table></figure>
<p>产生如下输出：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[ <span class="number">0.</span>          <span class="number">0.30000001</span>  <span class="number">0.60000002</span>  <span class="number">0.90000004</span>]</div></pre></td></tr></table></figure>
<p>我们创建了一个模型，但目前我们还不知道它是好是坏。为了评估训练数据的模型，我们需要一个<strong>loss function（损失函数）</strong>，我们可以用一个<code>y</code>占位符来提供所需的值。</p>
<p>损失函数会计算出当前训练出的模型和所提供的数据之间的距离。我们将使用用于线性回归的标准损失模型，其原理是将当前模型和提供的数据之间的增量的平方求和。<code>linear_model - y</code>创建一个向量，其中每个元素是相应的样本的误差增量。我们称之为<code>tf.square</code>平方误差。然后，我们使用<code>tf.reduce_sum</code>将所有平方误差求和，以创建一个单一的标量，用于提取出表示所有样本的总误差值：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">y</span> = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.float32)</div><div class="line">squared_deltas = <span class="keyword">tf</span>.square(linear_model - <span class="keyword">y</span>)</div><div class="line">loss = <span class="keyword">tf</span>.reduce_sum(squared_deltas)</div><div class="line"><span class="keyword">print</span>(sess.run(loss, &#123;<span class="keyword">x</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], <span class="keyword">y</span>:[<span class="number">0</span>,-<span class="number">1</span>,-<span class="number">2</span>,-<span class="number">3</span>]&#125;))</div></pre></td></tr></table></figure>
<p>输出损失值：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">23<span class="selector-class">.66</span></div></pre></td></tr></table></figure>
<p>我们可以通过手动的将<code>W</code>和<code>b</code>的值重新赋值为<code>-1</code>和<code>1</code>的方式来提高我们的算法的效果。变量可以初始化后将数据提供给<code>tf.Variable</code>对象，也可以使用像<code>tf.assign</code>这样的操作来更改。例如，<code>W=-1</code>和<code>b=1</code>是我们的模型中的最佳参数。因此我们可以更改<code>W</code>和<code>b</code>的值：</p>
<figure class="highlight accesslog"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">fixW = tf.assign(W, <span class="string">[-1.]</span>)</div><div class="line">fixb = tf.assign(b, <span class="string">[1.]</span>)</div><div class="line">sess.run(<span class="string">[fixW, fixb]</span>)</div><div class="line">print(sess.run(loss, &#123;x:<span class="string">[1,2,3,4]</span>, y:<span class="string">[0,-1,-2,-3]</span>&#125;))</div></pre></td></tr></table></figure>
<p>最终输出结果的损失是0：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">0<span class="selector-class">.0</span></div></pre></td></tr></table></figure>
<p>我们猜到了“最完美”的参数<code>W</code>和<code>b</code>的值，但机器学习的目标是<strong>自动</strong>找到正确的模型参数。我们将在下一节中说明如何完成这一任务。</p>
<h2 id="tf-train_API">tf.train API</h2><p>机器学习的完整讨论超出了本教程的范围。然而，TensorFlow提供了缓慢地改变每个变量以便<strong>最小化损失函数</strong>的<strong>optimizers（优化器）</strong>。其中最简单的优化器是<strong>gradient descent（梯度下降）</strong>。其原理是根据相对于该变量的损失导数的大小修改每个变量的值。一般来说，人工计算导数是繁琐的并且容易出错。因此，TensorFlow可以使用<code>tf.gradients</code>函数，来自动的产生当前所给模型描述的导数。为了简化操作，优化器通常会自动地为您执行此操作。例如：</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="attr">optimizer</span> = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</div><div class="line"><span class="attr">train</span> = optimizer.minimize(loss)</div></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">init</span>) # 将值重置为不正确的默认值</div><div class="line"><span class="selector-tag">for</span> <span class="selector-tag">i</span> <span class="selector-tag">in</span> <span class="selector-tag">range</span>(1000):</div><div class="line">  <span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-tag">train</span>, &#123;<span class="attribute">x</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], y:[<span class="number">0</span>,-<span class="number">1</span>,-<span class="number">2</span>,-<span class="number">3</span>]&#125;)</div><div class="line"></div><div class="line"><span class="selector-tag">print</span>(<span class="selector-tag">sess</span><span class="selector-class">.run</span>(<span class="selector-attr">[W, b]</span>))</div></pre></td></tr></table></figure>
<p>最终训练得出的模型参数：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[array([<span class="number">-0.9999969</span>], dtype=float32), array([ <span class="number">0.99999082</span>],</div><div class="line"> dtype=float32)]</div></pre></td></tr></table></figure>
<p>现在我们已经完成了实际的机器学习！完成这个简单的线性回归不需要太多的TensorFlow核心代码，但是更复杂的学习模型和方法通常需要更多的代码。因此，TensorFlow为通用模式、结构和功能提供了一套更高级别的抽象实现。我们将在下一节中学习如何使用这些抽象实现。</p>
<h3 id="完整的程序">完整的程序</h3><p>完成的可训练线性回归模型程序如下所示：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">import</span> numpy as np</div><div class="line"><span class="built_in">import</span> tensorflow as tf</div><div class="line"></div><div class="line"><span class="comment"># Model parameters</span></div><div class="line"><span class="attr">W</span> = tf.Variable([.<span class="number">3</span>], tf.float32)</div><div class="line"><span class="attr">b</span> = tf.Variable([-.<span class="number">3</span>], tf.float32)</div><div class="line"><span class="comment"># Model input and output</span></div><div class="line"><span class="attr">x</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="attr">linear_model</span> = W * x + b</div><div class="line"><span class="attr">y</span> = tf.placeholder(tf.float32)</div><div class="line"><span class="comment"># loss</span></div><div class="line"><span class="attr">loss</span> = tf.reduce_sum(tf.square(linear_model - y)) <span class="comment"># sum of the squares</span></div><div class="line"><span class="comment"># optimizer</span></div><div class="line"><span class="attr">optimizer</span> = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</div><div class="line"><span class="attr">train</span> = optimizer.minimize(loss)</div><div class="line"><span class="comment"># training data</span></div><div class="line"><span class="attr">x_train</span> = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]</div><div class="line"><span class="attr">y_train</span> = [<span class="number">0</span>,-<span class="number">1</span>,-<span class="number">2</span>,-<span class="number">3</span>]</div><div class="line"><span class="comment"># training loop</span></div><div class="line"><span class="attr">init</span> = tf.global_variables_initializer()</div><div class="line"><span class="attr">sess</span> = tf.Session()</div><div class="line">sess.run(init) <span class="comment"># reset values to wrong</span></div><div class="line">for i <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">  sess.run(train, &#123;x:x_train, y:y_train&#125;)</div><div class="line"></div><div class="line"><span class="comment"># evaluate training accuracy</span></div><div class="line">curr_W, curr_b, <span class="attr">curr_loss</span>  = sess.run([W, b, loss], &#123;x:x_train, y:y_train&#125;)</div><div class="line">print(<span class="string">"W: %s b: %s loss: %s"</span>%(curr_W, curr_b, curr_loss))</div></pre></td></tr></table></figure>
<p>当执行它时，会产生如下结果：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="selector-tag">W</span>: <span class="selector-attr">[-0.9999969]</span> <span class="selector-tag">b</span>: <span class="selector-attr">[ 0.99999082]</span> <span class="selector-tag">loss</span>: 5<span class="selector-class">.69997e-11</span></div></pre></td></tr></table></figure>
<p>这个更复杂的程序也可以在TensorBoard中可视化：</p>
<p><img src="/img/17_02_20/004.png" alt=""></p>
<h2 id="tf-contrib-learn">tf.contrib.learn</h2><p><code>tf.contrib.learn</code>是一个高级别的TensorFlow库，它简化了机器学习的机制，包括：</p>
<ul>
<li>运行训练循环</li>
<li>运行评估循环</li>
<li>管理数据集</li>
<li>管理数据导入</li>
</ul>
<p><code>tf.contrib.learn</code>定义了许多常见的模型。</p>
<h3 id="基本用法">基本用法</h3><p>请注意，线性回归在使用<code>tf.contrib.learn</code>的情况下变得更简单了：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">import</span> tensorflow as tf</div><div class="line"><span class="comment"># NumPy is often used to load, manipulate and preprocess data.</span></div><div class="line"><span class="built_in">import</span> numpy as np</div><div class="line"></div><div class="line"><span class="comment"># Declare list of features. We only have one real-valued feature. There are many</span></div><div class="line"><span class="comment"># other types of columns that are more complicated and useful.</span></div><div class="line"><span class="attr">features</span> = [tf.contrib.layers.real_valued_column(<span class="string">"x"</span>, <span class="attr">dimension=1)]</span></div><div class="line"></div><div class="line"><span class="comment"># An estimator is the front end to invoke training (fitting) and evaluation</span></div><div class="line"><span class="comment"># (inference). There are many predefined types like linear regression,</span></div><div class="line"><span class="comment"># logistic regression, linear classification, logistic classification, and</span></div><div class="line"><span class="comment"># many neural network classifiers and regressors. The following code</span></div><div class="line"><span class="comment"># provides an estimator that does linear regression.</span></div><div class="line"><span class="attr">estimator</span> = tf.contrib.learn.LinearRegressor(<span class="attr">feature_columns=features)</span></div><div class="line"></div><div class="line"><span class="comment"># TensorFlow provides many helper methods to read and set up data sets.</span></div><div class="line"><span class="comment"># Here we use `numpy_input_fn`. We have to tell the function how many batches</span></div><div class="line"><span class="comment"># of data (num_epochs) we want and how big each batch should be.</span></div><div class="line"><span class="attr">x</span> = np.array([<span class="number">1</span>., <span class="number">2</span>., <span class="number">3</span>., <span class="number">4</span>.])</div><div class="line"><span class="attr">y</span> = np.array([<span class="number">0</span>., -<span class="number">1</span>., -<span class="number">2</span>., -<span class="number">3</span>.])</div><div class="line"><span class="attr">input_fn</span> = tf.contrib.learn.io.numpy_input_fn(&#123;<span class="string">"x"</span>:x&#125;, y, <span class="attr">batch_size=4,</span></div><div class="line">                                              <span class="attr">num_epochs=1000)</span></div><div class="line"></div><div class="line"><span class="comment"># We can invoke 1000 training steps by invoking the `fit` method and passing the</span></div><div class="line"><span class="comment"># training data set.</span></div><div class="line">estimator.fit(<span class="attr">input_fn=input_fn,</span> <span class="attr">steps=1000)</span></div><div class="line"></div><div class="line"><span class="comment"># Here we evaluate how well our model did. In a real example, we would want</span></div><div class="line"><span class="comment"># to use a separate validation and testing data set to avoid overfitting.</span></div><div class="line">estimator.evaluate(<span class="attr">input_fn=input_fn)</span></div></pre></td></tr></table></figure>
<p>当执行它时，会产生如下结果：</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">'global_step'</span>: <span class="number">1000</span>, <span class="string">'loss'</span>: <span class="number">1.9650059</span>e-<span class="number">11</span>&#125;</div></pre></td></tr></table></figure>
<h3 id="定制模型">定制模型</h3><p><code>tf.contrib.learn</code>不会将你锁定在预定义模型中。假设我们想创建一个未内置到TensorFlow中的自定义模型。我们仍然可以保留<code>tf.contrib.learn</code>的数据集、馈送、训练等的高级抽象。为了说明，我们将演示如何使用我们的较低级别TensorFlow API的知识来实现​​我们自己的等效模型到<code>LinearRegressor</code>。</p>
<p>要定义与<code>tf.contrib.learn</code>一起使用的自定义模型，我们需要使用<code>tf.contrib.learn.Estimator</code>。 <code>tf.contrib.learn.LinearRegressor</code>实际上是<code>tf.contrib.learn.Estimator</code>的子类。替代子类<code>Estimator</code>，我们只是提供<code>Estimator</code>一个<code>model_fn</code>函数，用于告诉<code>tf.contrib.learn</code>如何评估预测、训练步骤和损失。代码如下：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">import</span> numpy as np</div><div class="line"><span class="built_in">import</span> tensorflow as tf</div><div class="line"><span class="comment"># Declare list of features, we only have one real-valued feature</span></div><div class="line">def model(features, labels, mode):</div><div class="line">  <span class="comment"># Build a linear model and predict values</span></div><div class="line">  <span class="attr">W</span> = tf.get_variable(<span class="string">"W"</span>, [<span class="number">1</span>], <span class="attr">dtype=tf.float64)</span></div><div class="line">  <span class="attr">b</span> = tf.get_variable(<span class="string">"b"</span>, [<span class="number">1</span>], <span class="attr">dtype=tf.float64)</span></div><div class="line">  <span class="attr">y</span> = W*features['x'] + b</div><div class="line">  <span class="comment"># Loss sub-graph</span></div><div class="line">  <span class="attr">loss</span> = tf.reduce_sum(tf.square(y - labels))</div><div class="line">  <span class="comment"># Training sub-graph</span></div><div class="line">  <span class="attr">global_step</span> = tf.train.get_global_step()</div><div class="line">  <span class="attr">optimizer</span> = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</div><div class="line">  <span class="attr">train</span> = tf.group(optimizer.minimize(loss),</div><div class="line">                   tf.assign_add(global_step, <span class="number">1</span>))</div><div class="line">  <span class="comment"># ModelFnOps connects subgraphs we built to the</span></div><div class="line">  <span class="comment"># appropriate functionality.</span></div><div class="line">  return tf.contrib.learn.ModelFnOps(</div><div class="line">      <span class="attr">mode=mode,</span> <span class="attr">predictions=y,</span></div><div class="line">      <span class="attr">loss=</span> loss,</div><div class="line">      <span class="attr">train_op=train)</span></div><div class="line"></div><div class="line"><span class="attr">estimator</span> = tf.contrib.learn.Estimator(<span class="attr">model_fn=model)</span></div><div class="line"><span class="comment"># define our data set</span></div><div class="line"><span class="attr">x=np.array([1.,</span> <span class="number">2</span>., <span class="number">3</span>., <span class="number">4</span>.])</div><div class="line"><span class="attr">y=np.array([0.,</span> -<span class="number">1</span>., -<span class="number">2</span>., -<span class="number">3</span>.])</div><div class="line"><span class="attr">input_fn</span> = tf.contrib.learn.io.numpy_input_fn(&#123;<span class="string">"x"</span>: x&#125;, y, <span class="number">4</span>, <span class="attr">num_epochs=1000)</span></div><div class="line"></div><div class="line"><span class="comment"># train</span></div><div class="line">estimator.fit(<span class="attr">input_fn=input_fn,</span> <span class="attr">steps=1000)</span></div><div class="line"><span class="comment"># evaluate our model</span></div><div class="line">print(estimator.evaluate(<span class="attr">input_fn=input_fn,</span> <span class="attr">steps=10))</span></div></pre></td></tr></table></figure>
<p>当执行它时，会产生如下结果：</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&#123;<span class="string">'loss'</span>: <span class="number">5.9819476</span>e-<span class="number">11</span>, <span class="string">'global_step'</span>: <span class="number">1000</span>&#125;</div></pre></td></tr></table></figure>
<p>注意，自定义<code>model()</code>函数的内容与低版本API的手册中的模型训练循环非常相似。</p>
<h2 id="下一步">下一步</h2><p>现在你了解到了TensorFlow的基本运作的知识。我们还有几个教程，您可以查看以了解更多。如果你是机器学习的初学者，请参阅<a href="/2017/02/22/【Tensorflow%20r1.0%20文档翻译】机器学习的HelloWorld%20--%20MNIST手写数字识别/">【深度学习的HelloWorld – MNIST手写数字识别】</a>，否则请参阅<a href="/2017/02/26/【Tensorflow%20r1.0%20文档翻译】深入MNIST--专家级/">【深入MNIST – 专家级】</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/">&raquo;</a>
  </nav>

 </div>

        

        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="http://dannylee1991.github.io/images/avatar.jpg" alt="DannyLee佳楠" itemprop="image"/>
          <p class="site-author-name" itemprop="name">DannyLee佳楠</p>
        </div>
        <p class="site-description motion-element" itemprop="description">一只在迈向机器学习道路上狂奔的程序猿.</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">101</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">18</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DannyLee1991" target="_blank">GitHub</a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DannyLee佳楠</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"dannylee1991"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>
    
     
  	<script src="/js/ua-parser.min.js"></script>
  	<script src="/js/hook-duoshuo.js"></script>
  

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
