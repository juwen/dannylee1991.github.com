<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






  <link rel="stylesheet" type="text/css" href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5"/>




<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.1"/>


    <meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿." />



  <meta name="keywords" content="Hexo,next" />





  <link rel="shorticon icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.1" />


<meta name="description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta property="og:type" content="website">
<meta property="og:title" content="DannyLee">
<meta property="og:url" content="http://dannylee1991.github.io/index.html">
<meta property="og:site_name" content="DannyLee">
<meta property="og:description" content="一只在迈向机器学习道路上狂奔的程序猿.">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DannyLee">
<meta name="twitter:description" content="一只在迈向机器学习道路上狂奔的程序猿.">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post'
  };
</script>

<!--baidu统计-->
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2f967e5ec4f276411160d27aeace7722";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

  <title> DannyLee </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  



  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><h1 class="site-meta">
  <span class="logo-line-before"><i></i></span>
  <a href="/" class="brand" rel="start">
      <span class="logo">
        <i class="icon-next-logo"></i>
      </span>
      <span class="site-title">DannyLee</span>
  </a>
  <span class="logo-line-after"><i></i></span>
</h1>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu menu-left">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            <i class="menu-item-icon icon-next-home"></i> <br />
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            <i class="menu-item-icon icon-next-categories"></i> <br />
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            <i class="menu-item-icon icon-next-archives"></i> <br />
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            <i class="menu-item-icon icon-next-tags"></i> <br />
            标签
          </a>
        </li>
      

      
      
        <li class="menu-item menu-item-search">
          <a href="#" class="st-search-show-outputs">
            <i class="menu-item-icon icon-next-search"></i> <br />
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'ss9-_Hsd4DyhyGw4m99P','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content"> 
  <section id="posts" class="posts-expand">
    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/05/12/斯坦福机器学习课程 第八周 (2)降维/" itemprop="url">
                斯坦福机器学习课程 第八周 (2)降维
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-05-12T07:51:58+08:00" content="2017-05-12">
            2017-05-12
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/05/12/斯坦福机器学习课程 第八周 (2)降维/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/05/12/斯坦福机器学习课程 第八周 (2)降维/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><blockquote>
<p>在这个模块中，我们将介绍<strong>主成分分析（PCA）</strong>，并显示它可以用于数据压缩，加快学习算法，以及可视化的复杂数据集。</p>
</blockquote>
<h1 id="动机">动机</h1><h2 id="动机I：数据压缩">动机I：数据压缩</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/0EJ6A/motivation-i-data-compression" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>本节我将开始介绍第二种无监督学习问题，它叫<strong>降维(dimensionality reduction)</strong>。</p>
<p>我们希望使用降维的一个主要原因是数据压缩。我们会在后几节中看到，数据压缩不仅通过压缩数据使得数据占用更少的计算机内存和硬盘空间，它还能给算法提速。</p>
</blockquote>
<p>首先我们来介绍什么是降维。</p>
<h3 id="例子">例子</h3><p>举一个例子，假如我们有一个有很多很多很多特征变量的数据集：</p>
<p><img src="/img/17_05_12/001.png" alt=""></p>
<p>这里为了方便展示，只画了其中两个。</p>
<p>假设我们不知道这两个特征量。其中$x_1$是某个物体的长度，以厘米为单位；另一个$x_2$是它以英寸为单位的长度。所以这是一个非常冗余的数据，与其用两个特征变量$x_1$和$x_2$，它们都是测量到的长度，或许我们应该把这个数据降到一维，只用一个长度的数据。</p>
<p>这个例子可能看起来好像是我生造的，但这个厘米英寸的例子其实还真不是那么无聊。我在工业界看到的情况也是大同小异。</p>
<blockquote>
<p>如果你有上百或者上千的特征变量，很容易就会忘记你到底有什么特征变量，而且有时候可能有几个不同的工程师团队。一队工程师可能给你200个特征变量，第二队工程师可能再给你300个特征变量，然后第三队工程师给你500个特征变量。所以你一共有1000个特征变量，这样就很难搞清哪个队给了你什么特征变量。实际上得到这样冗余的特征变量并不难。</p>
</blockquote>
<p>所以如果以厘米计的长度被取整到最近的厘米整数，以英寸计的长度被取整到最近的英寸整数。这就是为什么这些样本没有完美地在一条直线上。就是因为取整所造成的误差。</p>
<p><img src="/img/17_05_12/002.png" alt=""></p>
<p>这种情况下，如果我们可以把数据降到一维而不是二维，就可以减少冗余。</p>
<h3 id="降维含义">降维含义</h3><p>让我们再详细讲讲从二维降到一维到底意味着什么。</p>
<h4 id="二维降到一维">二维降到一维</h4><p>让我给这些样本涂上不同的颜色涂上不同的颜色：</p>
<p><img src="/img/17_05_12/003.png" alt=""></p>
<p>在这个例子中降低维度的意思是：我希望找到一条线，基本所有数据映射到这条线上。这样做之后，我就可以直接测量这条线上每个样本的位置。我想把这个新特征叫做$z_1$。</p>
<p><img src="/img/17_05_12/004.png" alt=""></p>
<p>要确定这条线上的位置，我只需要一个数字。这就是说新特征变量$z_1$能够表示这条绿线上每一个点的位置。</p>
<p>在之前如果想要表示一个样本点，我需要一个二维向量$(x_1,x_2)$，但是现在我可以用一个一维向量$z_1$来表示这个样本点：</p>
<p><img src="/img/17_05_12/005.png" alt=""></p>
<p>总结一下，在把所有训练样本映射到一条线上之后，我就能做到只用一个数字来表示每个训练样本的位置。这是一个对原始训练样本的近似。相对于之前需要用两个数字来表示一个样本而言，现在我只需要一个数字就可以表示了。这样就减少了一半的内存需求或者硬盘需求。</p>
<p>更重要的是，数据压缩还会让我们的学习算法运行地更快。</p>
<h4 id="三维降到二维">三维降到二维</h4><p>现在，我展示一个把三维数据降到二维的例子。</p>
<p><img src="/img/17_05_12/006.png" alt=""></p>
<blockquote>
<p>顺便说一下，在更典型的降维例子中，我们可能有1000维的数据，我们可能想降低到100维，但是因为我在这里能可视化的展示数据的维度是有限制的，所以我要用的例子是三维到二维的。</p>
</blockquote>
<p>我们有一个图上这样的数据集，我有一个样本$x^{(i)}$的集合，$x^{(i)}$是一个三维实数的点，所以我的样本是三维的：</p>
<p>$$<br>x^{(i)} \in R^3<br>$$</p>
<p>实际上，这些样本点，差不多都处于同一平面上。降维在这里的作用，就是把所有的数据，都投影到一个二维的平面内。所以，我们要对所有的数据进行投影，使得它们落在这个平面上：</p>
<p><img src="/img/17_05_12/007.png" alt=""></p>
<p>最后为了表示一个点在平面上的位置，我们需要两个数来表示平面上一个点的位置。这两个数可能叫做$z_1$和$z_2$：</p>
<p><img src="/img/17_05_12/008.png" alt=""></p>
<p>这也意味着我们现在可以用一个二维向量$z$来表示每一个训练样本了：</p>
<p><img src="/img/17_05_12/009.png" alt=""></p>
<p>$$<br>z^{(i)} \in R^2<br>$$</p>
<hr>
<p>为了更好的理解降维的过程，现在让我们用3D绘图来重现上面的整个过程：</p>
<p><img src="/img/17_05_12/010.png" alt=""></p>
<p>我们走的过程是这样的：左边是原始数据集，中间是投影到2D的数据集，右边是以$z_1$和$z_2$为坐标轴的2D数据集。</p>
<p>我们来更详细地看一下：</p>
<p>原始数据集是这样的：</p>
<p><img src="/img/17_05_12/011.gif" alt=""></p>
<p>可以看出来，大部分数据差不多可能都落在某个2D平面上，或者说距离某个2D平面不远。</p>
<p>所以我们可以把它们投影到2D平面上。下面是投影后的效果：</p>
<p><img src="/img/17_05_12/012.gif" alt=""></p>
<p>你可以看到所有的数据落在一个平面上，因为我们把所有的东西都投影到一个平面上了。所以我们现在只需要两个数:$z_1$和$z_2$来表示点在平面上的位置即可：</p>
<p><img src="/img/17_05_12/013.png" alt=""></p>
<p>这就是把数据从三维降到二维的过程。</p>
<p>这就是降维以及如何使用它来压缩数据的过程。</p>
<h2 id="动机II：可视化数据">动机II：可视化数据</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/t6pYD/motivation-ii-visualization" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在上节中，我们讲到一种通过数据降维来进行数据压缩的方法。在本节我将会讲到第二种数据降维的应用，那就是<strong>可视化数据</strong>。</p>
<p>对于大多数的机器学习应用，它真的可以帮助我们来开发高效的学习算法，但前提是我们能更好地理解数据。降维就是数据可视化的一种方法。</p>
</blockquote>
<p>假如我们已经收集了大量的有关全世界不同国家的统计数据集：</p>
<p><img src="/img/17_05_12/014.png" alt=""></p>
<p>第一个特征$x_1$是国家的国内生产总值；第二个特征$x_2$是一个百分比，表示人均占有的GDP；第三个特征$x_3$是人类发展指数；第四个特征$x_4$是预期寿命；…直到$x_{50}$</p>
<p>在这里我们有大量的国家的数据，对于每个国家有50个特征。我们有这样的众多国家的数据集，为了使得我们能更好地来理解数据，我们需要对数据进行可视化展示。这里我们有50个特征，但绘制一幅50维度的图是异常困难的，因此我们需要对数据进行降维，然后再可视化。</p>
<p>具体做法如下：</p>
<p>我们使用特征向量$x^{(i)}$来表示每个国家。$x^{(i)}$有着50个维度。我们需要对这50个特征降维之后，我们可以用另一种方式来代表$x^{(i)}$：使用一个二维的向量$z$来代替之前50维的$x$。</p>
<p><img src="/img/17_05_12/015.png" alt=""></p>
<p>$$<br>z^{(i)} \in R^2<br>$$</p>
<p>我们用$z_1$和$z_2$这两个数来总结50个维度的数据，我们可以使用这两个数来绘制出这些国家的二维图，使用这样的方法尝试去理解二维空间下不同国家在不同特征的差异会变得更容易。</p>
<p>在降维处理时，我们用$z_1$来表示那些象征着国家整体情况的数据，例如”国家总面积”、”国家总体经济水平”等；用$z_2$来表示象征着人均情况的数据，例如”人均GDP”，”人均幸福感”等。</p>
<p>降维处理之后，将数据按照这两个维度展示如下：</p>
<p><img src="/img/17_05_12/016.png" alt=""></p>
<p>在图中，右侧的点，象征着国家整体经济比较好的国家；上方的点，象征着人均经济比较好、人均幸福感较高、人均寿命较长…的国家。</p>
<hr>
<p>那么具体我们要如何去压缩数据达到降维的效果呢？在下一节视频中我们将会开始开发一种特别的算法。简称<strong>PCA</strong>或者<strong>主成分分析 </strong>。这个算法允许我们进行数据可视化，同时可以进行早先我们提到的一些有关数据压缩方面的应用。</p>
<h1 id="PCA">PCA</h1><h2 id="主成分分析（PCA）相关概念">主成分分析（PCA）相关概念</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/GBFTt/principal-component-analysis-problem-formulation" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>对于降维问题来说，目前最流行最常用的算法是<strong>主成分分析法(Principal Componet Analysis, PCA）</strong>。</p>
<p>在本节中，我想首先开始讨论PCA问题的公式描述，也就是说，我们用公式准确地精确地描述：我们想让PCA来做什么。</p>
</blockquote>
<h3 id="PCA的执行过程2D_-&gt;_1D">PCA的执行过程2D -&gt; 1D</h3><p>假设我们有这样的一个数据集:</p>
<p><img src="/img/17_05_12/017.png" alt=""></p>
<p>这个数据集含有二维实数空间内的样本X。</p>
<p>假设我想对数据进行降维，从二维降到一维。也就是说我想找到一条直线将数据投影到这条直线上，那怎么找到一条好的直线来投影这些数据呢？ </p>
<p>这样的一条直线也许是个不错的选择：</p>
<p><img src="/img/17_05_12/018.png" alt=""></p>
<p>你认为这是一个不错的选择的原因是：如果你观察投影到直线上的点的位置，我们发现每个点到它们对应的投影到直线上的点之间的距离非常小。（也就是说这些蓝色的线段非常的短）：</p>
<p><img src="/img/17_05_12/019.png" alt=""></p>
<p>所以，正式的说<strong>PCA</strong>所做的就是<strong>寻找一个低维的面(在这个例子中，其实是一条直线）数据投射在上面，使得这些蓝色小线段的平方和达到最小值</strong>。这些蓝色线段的长度被叫做<strong>投影误差</strong>。</p>
<p>所以<strong>PCA</strong>所做的就是寻找一个投影平面，对数据进行投影，使得这个能够最小化。</p>
<p>另外在应用<strong>PCA</strong>之前，通常的做法是先进行<strong>均值归一化</strong>和<strong>特征规范化</strong>，使得特征$x_1$和$x_2$均值为0，数值在可比较的范围之内。</p>
<blockquote>
<p>在这个例子里，我已经这么做了。但是在后面我还将回过来讨论更多有关PCA背景下的特征规范化和均值归一化问题。</p>
</blockquote>
<hr>
<p>我们正式一点地写出<strong>PCA</strong>的目标是这样的：</p>
<p>如果我们将数据从二维降到一维的话，我们需要试着寻找一个向量$u^{(i)}$，该向量属于$n$维空间中的向量（在这个例子中是二维的），我们将寻找一个对数据进行投影的方向，使得<strong>投影误差能够最小</strong>（在这个例子里，我们把PCA寻找到这个向量记做$u^{(1)}$）：</p>
<p><img src="/img/17_05_12/020.png" alt=""></p>
<p>所以当我把数据投影到这条向量所在的直线上时，最后我将得到非常小的重建误差。</p>
<blockquote>
<p>另外需要说明的时无论PCA给出的是这个$u^{(1)}$是正还是负都没关系。因为无论给的是正的还是负的$u^{(1)}$它对应的直线都是同一条，也就是我将投影的方向。</p>
</blockquote>
<p>这就是将二维数据降到一维的例子。</p>
<p>更一般的情况是我们有$n$维的数据想降到$k$维。在这种情况下我们不仅仅只寻找单个的向量（$u^{(1)}$）来对数据进行投影，我们要找到$k$个方向($u^{(k)}$)来对数据进行投影，从而最小化投影误差。</p>
<h3 id="PCA的执行过程3D_-&gt;_2D">PCA的执行过程3D -&gt; 2D</h3><p>下面的例子中，假设我有一些三维数据点：</p>
<p><img src="/img/17_05_12/021.png" alt=""></p>
<p>我想要做的是是寻找两个向量$u^{(1)}$和$u^{(2)}$：</p>
<p><img src="/img/17_05_12/022.png" alt=""></p>
<p>这两个向量一起定义了一个二维平面，我将把数据投影到这个二维平面上。</p>
<blockquote>
<p>如果你精通线性代数，那么这里更正式的定义是：我们将寻找一组向量$u^{(1)}$，$u^{(2)}$，…，$u^{(k)}$，我们将要做的是将数据投影到这$k$个向量展开的线性子空间上。</p>
<p>但是如果你不熟悉线性代数，那就想成是寻找$k$个方向（而不是之寻找一个方向）对数据进行投影。</p>
</blockquote>
<p>所以对于3D降维到2D的这个例子来说，寻找一个$k$维的平面，就是在寻找二维的平面。</p>
<hr>
<p>因此<strong>PCA</strong>做的就是：<strong>寻找一组$k$维向量(一条直线、或者平面、或者诸如此类等等)对数据进行投影，来最小化正交投影误差。</strong></p>
<h3 id="PCA和线性回归的关系">PCA和线性回归的关系</h3><p>最后一个我有时会被问到的问题是：<strong>PCA和线性回归有怎么样的关系？</strong></p>
<p>因为当我解释<strong>PCA</strong>的时候，我有时候会画出这样看上去有点像线性回归的图：</p>
<p><img src="/img/17_05_12/023.png" alt=""></p>
<p>但是，事实上<strong>PCA不是线性回归</strong>。尽管看上去有一些相似，但是它们确实是两种不同的算法。</p>
<h4 id="不同点_之一">不同点 之一</h4><p>如果我们做线性回归，我们做的是在给定某个输入特征$x$的情况下预测某个变量$y$的数值。因此对于线性回归，我们想做的是拟合一条直线，来最小化点和直线之间的平方误差：</p>
<p><img src="/img/17_05_12/024.png" alt=""></p>
<p>所以我们要最小化的是，上图中蓝线幅值的平方。注意我画的这些蓝色的垂直线，这是垂直距离。它是某个点与通过假设的得到的其预测值之间的距离。</p>
<p>与此想反，PCA要做的是最小化这些样本点与直线的最短距离(直角距离)：</p>
<p><img src="/img/17_05_12/025.png" alt=""></p>
<p>这是一种非常不同的效果。</p>
<h4 id="不同点_之二">不同点 之二</h4><p>更更更一般的是，当你做线性回归的时候，有一个特别的变量$y$作为我们即将预测的值，线性回归所要做的就是用$x$的所有的值来预测$y$。然而在PCA中，没有这么一个特殊的变量$y$是我们要预测的。我们所拥有的是特征$x_1$,$x_2$,…,$x_n$，所有的这些特征都是被同样地对待。</p>
<p>在上面那个从3维降到2维的例子中，原先的3个特征$x_1$,$x_2$,$x_3$都是被同样地对待的，没有特殊的变量$y$需要被预测。</p>
<hr>
<p>因此，PCA不是线性回归。尽管有一定程度的相似性，使得它们看上去是有关联的，但它们实际上是非常不同的算法。</p>
<p>因此，希望你们能理解PCA是做什么的：它是寻找到一个低维的平面，对数据进行投影，以便最小化投影误差平方的（最小化每个点与投影后的对应点之间的距离的平方值）。</p>
<h2 id="PCA算法_实现过程">PCA算法 实现过程</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/GBFTt/principal-component-analysis-problem-formulation" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>本节，将介绍<strong>PCA</strong>算法的具体细节，学完本节后，你就应该知道<strong>PCA</strong>的实现过程，并且应用PCA来给你的数据降维了。</p>
</blockquote>
<h3 id="数据预处理">数据预处理</h3><p>在使用PCA之前，我们通常会有一个数据预处理的过程。</p>
<p>拿到某组有m个无标签样本的训练集，一般先进行<strong>均值归一化(mean normalization)</strong>。这一步很重要。然后还可以进行<strong>特征缩放(feature scaling)</strong>，这根据你的数据而定。</p>
<blockquote>
<p>这跟我们之前在<strong>监督学习</strong>中提到的<strong>均值归一</strong>和<strong>特征缩放</strong>是一样的。</p>
</blockquote>
<h4 id="数据预处理第一步：均值归一化(mean_normalization)">数据预处理第一步：均值归一化(mean normalization)</h4><p>对于<strong>均值归一</strong>，我们首先应该计算出每个特征的均值$μ$，然后我们用$x-μ$来替换掉$x$。这样就使得所有特征的均值为0。</p>
<p><strong>举例说明：</strong></p>
<p>比如说，如果$x_1$表示房子的面积，$x_2$表示房屋的卧室数量，然后我们可以把每个特征进行缩放，使其处于同一可比的范围内。</p>
<p>同样地，跟之前的监督学习类似，我们可以首先计算出每个特征的均值：</p>
<p>$$<br>μ_j=\frac{1}{m}\sum_{i=1}^{m}x_j^{(i)}<br>$$</p>
<p>然后每个样本值对应的特征减去其对应的均值：</p>
<p>$$<br>x_j^{(i)} ← x_j^{(i)}-μ_j<br>$$</p>
<p>将所有的特征替换为这种形式的结果。这样就保证了所有特征的均值为0。</p>
<h4 id="数据预处理第二步：特征缩放(feature_scaling)">数据预处理第二步：特征缩放(feature scaling)</h4><p>然后，由于不同特征的取值范围都很不一样，我们还需要进行<strong>特征缩放</strong>。</p>
<p>我们需要将每个特征的取值范围都划定在同一范围内，因此对于均值化处理之后的特征值$x_j^{(i)}-μ_j$，我们还需要做进一步处理：</p>
<p>$$<br>x_j^{(i)} ← \frac{x_j^{(i)}-μ_j}{s_j}<br>$$</p>
<p>这里$s_j$表示特征$j$度量范围，即该特征的最大值减去最小值。</p>
<h3 id="PCA算法">PCA算法</h3><p>接下来就正式进入PCA的算法部分。</p>
<p>在之前的视频中，我们已经知道了PCA的原理。PCA是在试图找到一个低维的子空间，然后把原数据投影到子空间上，并且最小化平方投影误差的值（投影误差的平方和，即下图中蓝色线段长度的平方和）：</p>
<p><img src="/img/17_05_12/026.png" alt=""></p>
<p>那么应该怎样来计算这个子空间呢? 实际上这个问题有完整的数学证明来解释如何找到这样的子空间，不过这个数学证明过程是非常复杂的，同时也超出了本课程的范围。但如果你推导一遍这个数学证明过程，你就会发现要找到$u^{(1)}$的值，也不是一件很难的事。但在这里，我不会给出证明，我只是简单描述一下实现PCA所需要进行的步骤。</p>
<p>假如说我们想要把数据从$n$维降低到$k$维，我们首先要做的是计算出下面这个协方差矩阵(通常用$∑$来表示)：</p>
<p>$$<br>∑=\frac{1}{m}\sum_{i=1}^n(x^{(i)})(x^{(i)})^T<br>$$</p>
<blockquote>
<p>很不幸的是，这个希腊符号$∑$和求和符号重复了。希望你对这里不要产生混淆。</p>
</blockquote>
<p>计算出这个协方差矩阵后，假如我们把它存为Octave中的一个名为<code>Sigma</code>的变量，我们需要做的是计算出<code>Sigma</code>矩阵的<strong>特征向量(eigenvectors)</strong>。</p>
<p>在Octave中，你可以使用如下命令来实现这一功能：</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="name">U</span>,S,V] = svd(<span class="name">Sigma</span>)<span class="comment">;</span></div></pre></td></tr></table></figure>
<blockquote>
<p>顺便说一下，<code>svd</code>表示<strong>奇异值分解(singular value decomposition)</strong>，这是某种更高级的奇异值分解，这是比较高级的线性代数的内容。你不必掌握这些，但实际上<code>Sigma</code>是一个协方差矩阵。有很多种方法来计算它的特征向量。</p>
<p>如果你线性代数学得很好，或者你之前听说过特征向量的话，那也许知道在Octave中还有另一个<code>eig</code>命令，可以用来计算特征向量。实际上<code>svd</code>命令和<code>eig</code>命令将得到相同的结果。但<code>svd</code>其实要更稳定一些，所以我一般选择用<code>svd</code>，不过我也有一些朋友喜欢用<code>eig</code>函数。</p>
<p>在这里对协方差矩阵<code>Sigma</code>使用<code>eig</code>和<code>svd</code>时，你会得到同样的答案。这是因为协方差均值总满足一个数学性质，称为<strong>对称正定(symmetric positive definite)</strong>，其实你不必细究这个具体是什么意思，只要知道这种情况下，使用<code>eig</code>和<code>svd</code>结果是一样的就可以了。</p>
</blockquote>
<p>好了，这就是你需要了解的一点线性代数知识，如果有任何地方不清楚的话不必在意。你只需要知道上面这行Octave代码就行了。</p>
<p>如果你用除了Octave或者MATLAB之外的其他编程环境，你要做的是找到某个可以计算svd，即奇异值分解的函数库文件。在主流的编程语言中，应该有不少这样的库文件。我们可以用它们来计算出协方差矩阵的$U$ $S$ $V$矩阵。</p>
<hr>
<p>我再提几个细节问题。</p>
<p>这个协方差矩阵<code>Sigma</code>应该是一个$n×n$的矩阵，通过定义可以发现这是一个$n×1$的向量，和它自身的转置（一个$1×n$的向量）相乘得到的结果，这个结果自然是一个$n×n$的矩阵。</p>
<p>然后把这n个$n×n$的矩阵加起来，当然还是$n×n$矩阵。</p>
<p>然后svd将输出三个矩阵，分别是$U$ $S$ $V$。你真正需要的是$U$矩阵。</p>
<p>$U$矩阵也是一个$n×n$矩阵：</p>
<p><img src="/img/17_05_12/027.png" alt=""></p>
<p>实际上$U$矩阵的列元素就是我们需要的$u^{(1)}$,$u^{(1)}$等等。</p>
<p>如果我们想将数据的维度从$n$降低到$k$的话，我们只需要提取前$k$列向量。这样我们就得到了$u^{(1)}$到$u^{(k)}$，也就是我们用来投影数据的$k$个方向。</p>
<p>我们取出$U$矩阵的前$k$列得到一个新的，由$u^{(1)}$到$u^{(k)}$组成的矩阵$U_{reduce}$：</p>
<p>$$<br>\begin{equation}<br>U_{reduce}=\left[<br>\begin{matrix}<br>|&amp;|&amp;|&amp;…&amp;|\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>u^{(1)}&amp;u^{(2)}&amp;u^{(3)}&amp;…&amp;u^{(k)}\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>\end{matrix}<br>\right]<br>\end{equation}<br>$$</p>
<p>这是一个$n × k$维的矩阵。</p>
<p>然后我们用这个$U_{reduce}$来对我的数据进行<strong>降维</strong>。我们定义：</p>
<p>$$<br>\begin{equation}<br>z=\left[<br>\begin{matrix}<br>|&amp;|&amp;|&amp;…&amp;|\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>u^{(1)}&amp;u^{(2)}&amp;u^{(3)}&amp;…&amp;u^{(k)}\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>|&amp;|&amp;|&amp;…&amp;|\\<br>\end{matrix}<br>\right]<br>^{T}x<br>\\<br>=<br>\left[<br>\begin{matrix}<br>-&amp;-&amp;u^{(1)}&amp;…&amp;-\\<br>-&amp;-&amp;u^{(2)}&amp;…&amp;-\\<br>-&amp;-&amp;u^{(3)}&amp;…&amp;-\\<br>.&amp;.&amp;.&amp;…&amp;.\\<br>-&amp;-&amp;u^{(k)}&amp;…&amp;-\\<br>\end{matrix}<br>\right]<br>x<br>\end{equation}<br>$$</p>
<p>$$<br>z \in R^k<br>$$</p>
<p>其中$\left[<br>\begin{matrix}<br>-&amp;-&amp;u^{(1)}&amp;…&amp;-\\<br>-&amp;-&amp;u^{(2)}&amp;…&amp;-\\<br>-&amp;-&amp;u^{(3)}&amp;…&amp;-\\<br>.&amp;.&amp;.&amp;…&amp;.\\<br>-&amp;-&amp;u^{(k)}&amp;…&amp;-\\<br>\end{matrix}<br>\right]$是$k×n$的矩阵，$x$是$n×1$的矩阵，因此$z$是$k×1$的矩阵。</p>
<p>这里的$x$可以是训练集中的样本，也可以是交叉验证集中的样本，也可以是测试集样本。</p>
<h3 id="总结">总结</h3><p>总结一下，这就是PCA的全过程：</p>
<ul>
<li><p>首先进行均值归一化</p>
<ul>
<li>保证所有的特征量都是均值为0的。</li>
</ul>
</li>
<li><p>然后可以选择进行特征缩放</p>
<ul>
<li>如果不同特征量的范围跨度很大的话，你确实需要进行特征缩放这一步。</li>
</ul>
</li>
<li><p>在以上的预处理之后，我们计算出这个协方差<code>Sigma</code>矩阵：</p>
</li>
</ul>
<p>$$<br>Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)})(x^{(i)})^T<br>$$</p>
<ul>
<li>然后我们可以应用<code>svd</code>函数来计算出<code>U S V</code>矩阵:</li>
</ul>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="name">U</span>,S,V] = svd(<span class="name">Sigma</span>)<span class="comment">;</span></div></pre></td></tr></table></figure>
<ul>
<li>然后，我们取出$U$矩阵的前$k$列元素组成新的$U_{reduce}$矩阵：</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">Ureduce</span> = U(:,<span class="number">1</span>:k);</div></pre></td></tr></table></figure>
<ul>
<li>最后这个式子给出了我们从原来的特征$x$变成降维后的$z$的过程:</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">z</span> = Ureduce`*x;</div></pre></td></tr></table></figure>
<blockquote>
<p>另外，跟<strong>k均值算法</strong>类似，如果你使用<strong>PCA</strong>的话，你的$x$应该是$n$维实数。所以没有$x_0 = 1$这一项。</p>
<p>有一件事儿我没做：$u^{(1)},u^{(2)}…u^{(k)}$通过将数据投影到$k$维的子平面上确实使得投影误差的平方和为最小值，但是我并没有证明这一点，因为这已经超出了这门课的范围。</p>
<p>幸运的是PCA算法能够用不多的几行代码就能实现它。</p>
</blockquote>
<h1 id="应用PCA">应用PCA</h1><h2 id="对压缩数据的还原">对压缩数据的还原</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/X8JoQ/reconstruction-from-compressed-representation" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在前面的视频中我们介绍了<strong>PCA (主成分分析)</strong>作为压缩数据的算法，你会发现它能将高达一千维度的数据压缩到只有一百个维度；或者将三维数据压缩到两个维度的情况。</p>
<p>如果有一个这样的压缩算法，那么也应该有一种方法可以从压缩过的数据近似地回到原始高维度的数据。</p>
<p>假设有一个已经被压缩过的$z^{(i)}$它有100个维度，怎样使它回到其最初的表示$x^{(i)}$也就是压缩前的1000维的数据呢？ </p>
<p>在本节，我将会告诉你如何做到。</p>
</blockquote>
<p>在PCA算法中，我们有下面这些样本：</p>
<p><img src="/img/17_05_12/028.png" alt=""></p>
<p>我们让这些样本投影在一维平面$z_1$上，并且明确地指定其位置：</p>
<p><img src="/img/17_05_12/029.png" alt=""></p>
<p>那么给出一个一维实数点$z$我们能否，让$z$重新变成原来的二维实数点$x$呢？</p>
<p>即做到：</p>
<p>$$<br>z \in R → x \in R^2<br>$$</p>
<hr>
<p>我们知道:</p>
<p>$$<br>z = U^T_{reduce}x<br>$$</p>
<p>如果想得到相反的情形，方程应这样变化:</p>
<p>$$<br>x_{approx} = U_{reduce}z<br>$$</p>
<p>为了检查维度，在这里$U_{reduce}$是一个$n×k$矩阵，$z$就是一个$k×1$维向量。将它们相乘得到的就是$n×1$维。</p>
<p>所以$x_{approx}$是一个$n$维向量。</p>
<p>同时根据PCA的意图，投影的平方误差不能很大。也就是说$x_{approx}$将会与最开始用来导出$z$的原始$x$很接近。用图表示出来就是这样：</p>
<p><img src="/img/17_05_12/030.png" alt=""></p>
<p>这已经与原始数据非常近似了。</p>
<p>这就是用低维度的特征数据$z$还原到未被压缩的特征数据的过程。我们找到一个与原始数据$x$近似的$x_{approx}$。我们也称这一过程为<strong>原始数据的重构(reconstruction)</strong>。</p>
<h2 id="选择主成分的数量k">选择主成分的数量k</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/S1bq1/choosing-the-number-of-principal-components" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在PCA算法中，我们把n维特征变量降维到k维特征变量。这个数字k是PCA算法的一个参数。这个数字k也被称作<strong>主成分的数量</strong>。在本节中我会给你们一些参考，告诉你们人们是怎样思考如何选择PCA的参数k的。</p>
</blockquote>
<h3 id="算法原理：最小化平均平方映射误差">算法原理：最小化平均平方映射误差</h3><p>为了选择参数k（也就是要选择<strong>主成分的数量</strong>），这里有几个有用的概念：</p>
<p>PCA所做的是尽量最小化<strong>平均平方映射误差 (Average Squared Projection Error) </strong>。</p>
<p>因此PCA就是要将下面这个量最小化：</p>
<p>$$<br>\frac{1}{m}\sum_{i=1}^m||x^{i}-x_{approx}^{(i)}||^2<br>$$</p>
<p>即最小化$x$和其在低维表面上的映射点之间的距离的平方。这就是平均平方映射误差。</p>
<p>同时我们还要定义一下<strong>数据的总变差(Total Variation)</strong>：</p>
<p>$$<br>\frac{1}{m}\sum_{1=m}^m||x^{(i)}||^2<br>$$</p>
<p>数据的总变差 (Total Variation) 是这些样本的长度的平方的均值。它的意思是 “平均来看，我的训练样本距离零向量（原点）多远？”。</p>
<p>当我们去选择k值的时候，我们通过平均平方映射误差除以数据的总变差来表示数据的变化有多大。我们想要这个比值能够小于1%：</p>
<p>$$<br>\frac{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2<br>}{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}||^2<br>}<br>\le0.01<br>$$</p>
<p>大部分人在考虑，选择k的方法时，不是直接选择k值，而是这里的数字应该设置为多少：</p>
<p><img src="/img/17_05_12/031.png" alt=""></p>
<p>它应该是0.01还是其它的数？如果选择了0.01，那么用PCA的语言说就是保留了99%的差异性。</p>
<p>数字0.01是人们经常用的一个值，另一个常用的值是0.05。如果选择了0.05，就意味着95%的差异性被保留了。从95到99是人们最为常用的取值范围。</p>
<p>你可能会惊讶的发现，对于许多数据集，即使保留了99%的差异性，可以大幅地降低数据的维度。因为大部分现实中的数据，许多特征变量都是高度相关的。所以实际上大量压缩数据是可能的，而且仍然会保留99%或95%的差异性。</p>
<h3 id="具体实现">具体实现</h3><p>那么你该如何实现它呢？</p>
<h4 id="原始的算法">原始的算法</h4><p>有一种方式是从1开始，依次递增k的值，尝试检查差异性是否达到预设值。</p>
<p>例如：</p>
<ul>
<li>尝试$k=1$时的PCA。</li>
<li>计算出$U_{reduce}，z^{(1)}，z^{(2)}，…，z^{(m)}，x^{(1)}_{approx}，…，x^{(m)}_{approx}$</li>
<li>检查是否满足：</li>
</ul>
<p>$$<br>\frac{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2<br>}{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}||^2<br>}<br>\le0.01<br>$$</p>
<p>如果满足条件，我们就用$k=1$；但如果不满足，那么我们接下来尝试$k=2$，然后我们要重新走一遍这整个过程。</p>
<p>以此类推一直试到上面不等式成立为止。</p>
<h4 id="一种更快的算法">一种更快的算法</h4><p>可以想象，上面这种方式非常低效。每次尝试使用新的$k$值带入计算时，整个计算过程都需要重新执行一遍，还好我没有一种更快捷方便的计算方式。</p>
<p>当你调用<code>svd</code>来计算PCA时，你会得到三个矩阵<code>[U,S,V]</code>:</p>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="name">U</span>,S,V]=svd(<span class="name">Sigma</span>)</div></pre></td></tr></table></figure>
<p>除了之前提到的<code>U</code>矩阵之外，当你对协方差的矩阵<code>Sigma</code>调用<code>svd</code>时，我没还会得到中间的这个<code>S</code>矩阵。<code>S</code>矩阵是一个$n×n$的对角矩阵，它只有在对角线上的元素不为0，其余的元素都是0。并且显而易见，它是一个方阵：</p>
<p>$$<br>\begin{equation}<br>S=\left[<br>\begin{matrix}<br>s_{11}&amp;0&amp;0&amp;…&amp;0\\<br>0&amp;s_{22}&amp;0&amp;…&amp;0\\<br>0&amp;0&amp;s_{33}&amp;…&amp;0\\<br>┋&amp;┋&amp;┋&amp;…&amp;┋\\<br>0&amp;0&amp;0&amp;…&amp;s_{nn}\\<br>\end{matrix}<br>\right]<br>\end{equation}<br>$$</p>
<p>可以证明的是（我不会在此证明）实际上对于一个给定的k值，可以通过这个$S$矩阵方便的计算出差异性那一项的值：</p>
<p>$$<br>\frac{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2<br>}{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}||^2<br>}<br>=<br>1-\frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br>$$</p>
<hr>
<p>例如，假设差异性要满足小于$0.01$，那么可以得出：</p>
<p>$$<br>\frac{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2<br>}{<br>\frac{1}{m}\sum_{i=1}^m||x^{(i)}||^2<br>}<br>=<br>1-\frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br>\le0.01<br>$$</p>
<p>即：</p>
<p>$$<br>\frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br>\ge0.99<br>$$</p>
<p>那么你可以从1开始，慢慢增大$k$的值，来计算上面这个不等式，直到满足为止即可（得到满足上面不等式的最小$k$值）。</p>
<hr>
<p>通过这种方式，你只需要<strong>调用一次<code>svd</code>函数</strong>，通过<code>svd</code>给出的<code>S</code>矩阵你就可以通过依次增加$k$值的方式来求解了。这样以来就大幅的提升了计算效率。</p>
<h3 id="总结-1">总结</h3><p>总结一下，使用PCA算法时寻找合适$k$值的方法：</p>
<ul>
<li>首先对协方差矩阵<code>Sigma</code>调用一次<code>svd</code>：</li>
</ul>
<figure class="highlight scheme"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[<span class="name">U</span>,S,V] = svd(<span class="name">Sigma</span>)</div></pre></td></tr></table></figure>
<ul>
<li>然后使用下面的不等式求得满足条件的最小$k$值：</li>
</ul>
<p>$$<br>\frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br>\ge0.99<br>$$</p>
<hr>
<p>顺便说一下，即使你想要手动挑选$k$值，如果你想要向别人解释你实现的PCA的性能具体如何，那么一个好方法就是算出这个值：</p>
<p>$$<br>\frac{\sum_{i=1}^k S_{ii}}{\sum_{i=1}^n S_{ii}}<br>$$</p>
<p>它会告诉你百分之多少的差异性被保留了下来。</p>
<p>如果你把这个数值展现出来，那么熟悉PCA的人们就可以通过它来更好地理解你用来代表原始数据的压缩后的数据近似得有多好。因为有99%的差异性被保留了。</p>
<p>这就是一个<strong>平方投影误差的测量指标</strong>。它可以带给你对于数据压缩后是否与原始数据相似带来一种很好的直观感受。</p>
<h2 id="应用PCA的建议">应用PCA的建议</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/RBqQl/advice-for-applying-pca" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在之前的课程中，我已经提到过<strong>PCA</strong>有时可以用来提高机器学习算法的速度。在本节，我将讲解如何在实际操作中来实现。同时列举一些例子来说明PCA在具体应用过程中的使用建议。</p>
</blockquote>
<h3 id="PCA应用场景总结">PCA应用场景总结</h3><p>迄今为止我们讨论过的有关PCA的应用中有如下应用场景：</p>
<ul>
<li>数据压缩<ul>
<li>减少内存或者磁盘空间的使用</li>
<li>提升学习算法的效率（k值的选择是关键）</li>
</ul>
</li>
<li>数据可视化<ul>
<li>将数据降维到二/三维度进行可视化展示</li>
</ul>
</li>
</ul>
<h3 id="通过PCA来提高学习算法的速度">通过PCA来提高学习算法的速度</h3><p>举例说明，假如你正在用机器学习来处理图片数据。假设每张输入的图片尺寸是$100×100$的，那么对于每张图片来说，都有10000个像素点。假设样本$x^{(i)}$是包含了10000像素强度值的特征向量，即：</p>
<p>$$<br>x^{(i)}\in R<br>$$</p>
<p>那么对于我们的样本数据集来说：</p>
<p>$$<br>(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})<br>$$</p>
<p>每个样本中，对应的$x^{(i)}$都是10000维的特征向量。</p>
<p>可想而知，这么高维度的数据带入到逻辑回归、神经网络、支持向量机或者任何别的算法中，学习算法运行的都会很慢。</p>
<p>幸运的是，通过使用PCA，我们能够<strong>降低数据的维数，从而使得算法能够更加高效地运行</strong>。这就是PCA提高算法运算效率的原理。</p>
<h4 id="降维步骤">降维步骤</h4><p>首先我们需要检查带标签的训练数据集，并提取出输入数据。我们只需要提取出$x$并暂时把$y$放在一边。这一步我们会得到一组无标签的训练集：</p>
<p>$$<br>x^{(1)},x^{(2)},…,x^{(m)}\in R^{10000}<br>$$</p>
<p>从$x^{(1)}$到$x^{(m)}$，每个样本都是10000维的数据。然后我们应用PCA降维，我们会得到一个降维后的1000维的数据集：</p>
<p>$$<br>z^{(1)},z^{(2)},…,z^{(m)}\in R^{1000}<br>$$</p>
<p>这样我们就得到了一个新的训练集：</p>
<p>$$<br>(z^{(1)},y^{(1)}),(z^{(2)},y^{(2)}),…,(z^{(m)},y^{(m)})<br>$$</p>
<p>现在，我可以将这个已经降维的数据集输入到学习算法中，来得出假设函数，并把降维后的数据作为输入带入，做出预测。</p>
<p>以<strong>逻辑回归</strong>为例：</p>
<p>逻辑回归中，我们得到的假设函数如下：</p>
<p>$$<br>h_{\theta}(z) = \frac{1}{1+e^{-\theta^{T}z}}<br>$$</p>
<p>我们将$z$向量作为输入带入，并得出一个预测值。</p>
<p>最后，如果你有一个新的样本$x$，那么你所要做的是将你的测试样本$x$通过同样的PCA降维之后，你会得到这个样本所对应的$z$。然后将这个$z$值带入到这个假设函数中进行预测。</p>
<blockquote>
<p><strong>注意（重要）：</strong></p>
<p>最后要注意一点，PCA定义了从$x$到$z$的对应关系，这种对应关系只可以通过在训练集上运行PCA定义出来。</p>
<p>具体来讲，这种PCA所学习出的对应关系，所做的就是计算出一系列的参数。这些参数这就是<strong>特征缩放</strong>和<strong>均值归一化</strong>以及降维矩阵$U_{reduce}$。但是对于降维矩阵$U_{reduce}$中的数据，我们需要使我们的参数唯一地适应<strong>训练集</strong>，而不是适应交叉验证或者测试集。因此我们通过在训练集中找到了降维矩阵$U_{reduce}$，我们就可以将同样的对应关系应用到其他样本中了，比如交叉验证数集样本，或者用在测试数据集中。</p>
<p>总结一下，当你在运行PCA的时候，只是在训练集那一部分来进行的，而不是在交叉验证的数据集或者测试集上运行。在训练集上运行PCA后，得到了从$x$到$z$的映射，然后你就可以将这个映射应用到交叉验证数据集，和测试数据集中。</p>
</blockquote>
<p>通过这个例子中的这种方式，我们讨论了将数据从上万维降到千维。在实际应用场景中，我们经常发现，将数据降维到原有维度的五分之一或者十分之一，就分类的精确度而言，降维后的数据对学习算法几乎没有什么影响。如果我们将降维用在低维数据上，我们的学习算法会运行得更快。</p>
<h3 id="PCA的错误使用">PCA的错误使用</h3><p>有一个值得提醒的频繁被误用的PCA应用场景，那就是使用它来避免过拟合。</p>
<p>具体原因是将高维度数据降维处理后，相较于原先的数据，会更不容易出现过拟合的现象。例如我们将10000维的数据降到了1000维，那么降维后的1000维数据相较于降维前的10000维数据更不容易产生过拟合。</p>
<p>因此有人认为PCA是一种避免过拟合的方法，但在这里，我需要强调一下，<strong>为了解决过拟合问题而使用PCA是不适合的！并且我不建议这么做。</strong></p>
<p>如果你比较担心过拟合问题，那么你应该使用正则化方法，而不是使用PCA来对数据进行降维。</p>
<blockquote>
<p><strong>PCA会丢失信息：</strong>如果你仔细想想PCA的工作原理，你会发现它并不需要使用数据的标签，你只需要设定好输入数据$x^{(i)}$，同时使用这个方法来寻找更低维度的数据近似，在这个过程中，PCA实际上已经把某些信息舍弃掉了。</p>
</blockquote>
<p>舍弃掉一些数据，并在你对数据标签$y$值毫不知情的情况下对数据进行降维，所以这或许是一个使用PCA方法的可行之路。如果保留99%的方差，即保留绝大部分的方差，那也是舍弃了某些有用的信息。事实证明，当你在保留99%或者95%或者其它百分比的方差时，结果表明只使用正则化对于避免过拟合，会带来比较好的效果。</p>
<p>同时对于过拟合问题，正则化效果也会比PCA更好，因为当你使用线性回归或者逻辑回归或其他的方法配合正则化时，这个最小化问题实际就变成了y值是什么，才不至于将有用的信息舍弃掉。然而PCA不需要使用到这些标签，它更容易将有价值信息舍弃。</p>
<p>总之，<strong>使用PCA的目的是加速学习算法，但不应该用它来避免过拟合</strong>。</p>
<h3 id="两个建议">两个建议</h3><h4 id="真的需要PCA吗？">真的需要PCA吗？</h4><p>有时候人们正在设计机器学习系统，或许会写下像这样的计划：</p>
<p><strong>设计一个机器学习系统：</strong></p>
<ul>
<li>收集训练数据集$｛(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})｝$</li>
<li>运行PCA将数据$x^{(i)}$降维到$z^{(i)}$</li>
<li>对降维后的数据训练逻辑回归算法$｛(z^{(1)},y^{(1)}),(z^{(2)},y^{(2)}),…,(z^{(m)},y^{(m)})｝$</li>
<li>在测试集上测试结果：将$x_{test}^{(i)}$映射到$z_{test}^{(i)}$。对映射后的数据集$｛(z_{test}^{(1)},y_{test}^{(1)}),…,(z_{test}^{(m)},y_{test}^{(m)})｝$运行假设函数$h_{\theta}(z)$</li>
</ul>
<p>通常在一个项目的初期，有些人便直接写出这样的项目计划。</p>
<p>在写下这样一个使用PCA方法的项目计划前，一个非常好的问题是：<strong>如果我们在整个项目中不使用PCA效果会怎样？</strong> </p>
<p>通常人们不会去思考这个问题，尤其是当人们提出一个复杂的项目并且其中使用了PCA或其它方法时，我经常建议大家在使用PCA之前，首先要想清楚你自己做的是什么，以及你想要做什么。这也是你首先需要在原始数据$x^{(i)}$上考虑的问题。并且根据具体情况来分析是否适合使用PCA，还是直接将原始数据带入到学习算法中。</p>
<h4 id="不要一开始就带入PCA">不要一开始就带入PCA</h4><p>同时我也建议一开始不要将PCA方法就直接放到算法里，先使用原始数据$x^{(i)}$看看效果。只有一个原因让我们相信算法出现了问题，那就是你的学习算法收敛地非常缓慢，占用内存或者硬盘空间非常大，所以你想来压缩数据。只有当你的$x^{(i)}$效果不好的时候，那么就考虑用PCA来进行压缩数据。</p>
<p>因为我常常看到某些人在项目开始时便将PCA考虑进去，有时他们并没有仔细思考他们做了什么使得结果表现地好，更没有考虑在不用PCA下的情景会是什么样的效果。如果某个数据不使用PCA也可以工作的很好，但我们对于这些数据使用PCA耗费了大量时间，这是不值得的。</p>
<p>然而，尽管有这些需要注意的地方，PCA仍旧是一种不可思议的有用的算法。PCA的使用频率也很高，大部分时候我都用它来加快学习算法。但我认为PCA通常都是被用来压缩数据以减少内存使用或硬盘空间占用的、或者用来可视化数据的。</p>
<p>同时PCA也是一种强有力的无监督学习算法。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/26/【翻译】TextRank-对文本排序/" itemprop="url">
                【翻译】TextRank:对文本排序
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-26T22:12:58+08:00" content="2017-04-26">
            2017-04-26
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/26/【翻译】TextRank-对文本排序/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/26/【翻译】TextRank-对文本排序/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><blockquote>
<p>本文翻译自：<a href="http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" target="_blank" rel="external">http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf</a></p>
</blockquote>
<h2 id="摘要">摘要</h2><p>本篇论文中，我们将介绍TextRank算法，这是一种针对于文本处理的基于图的排序模型算法，并且展示这个模型是如何能够被成功的应用在自然语言应用中。特别的，我们提出了两个创新的无监督方法用于关键词和句子提取，并且展示我们得到的测试结果与先前公布的基准结果的对比。</p>
<h2 id="1_介绍">1 介绍</h2><p>基于图的排序算法，像Kleinberg的HITS算法（Kleinberg，1999）或Google的PageRank算法（Brin和Page，1998）已成功应用于引文分析，社交网络和万维网链接结构分析。可以说，这些算法通过提供一种依靠Web架构师的集体知识而不是网页的单独内容分析的网页排名机制,可以作为网页搜索技术领域触发的范式转换的关键要素。简而言之，基于图的排序算法是通过考虑从整个图形递归计算的全局信息，而不是仅依赖于局部顶点特定信息来决定图中的顶点的重要性的一种方式。</p>
<p>对从自然语言文档中提取的词汇或语义图，使用类似的思路，可以得出一种基于图形的排名模型，这种模型可以应用于各种自然语言处理的应用程序中，其中从整个文本中获取的知识用于得出本地 排名/选择 的决策。 这种面向文本的排序方法，可以应用于关键短语的自动提取，摘要提取，以及词义消歧的任务（Mihalcea et等等，2004）。</p>
<p>在这篇论文中，我们会介绍基于从自然语言文本中提取的图形，来介绍TextRank图的排序模型。我们调查并评估了TextRank对于由无监督关键词和句子提取，这两种语言处理任务的应用，并展示使用TextRank获得的结果与在这些领域开发的最先进的系统进行比较。</p>
<h2 id="2_TextRank模型">2 TextRank模型</h2><p>基于图的排序算法本质上是基于从整个图形递归绘制的全局信息，来决定图中顶点的重要性的一种方式。基于图表的排名模式实现的基本思想是“投票”或“推荐”。当一个顶点链接到另一个顶点时，它主要是在为另一个顶点投票。顶点投射的投票数越多，顶点的重要性就越高。此外，顶点投票的重要性决定了投票本身的重要性，而这一信息也被排名模型考虑在内。因此，与顶点相关联的分数，取决于为其投的票，以及投射这些投票的顶点的分数来确定。</p>
<p>正式的，令集合$G=(V,E)$是具有顶点$V$和边$E$集合的有向图，其中$E$是$V×V$的子集。对于给定的顶点$V_i$，令$In(V_i)$是指向它的顶点集（前辈），并且令$Out(V_i)$是顶点$V_i$指向（后继）的顶点集合。顶点$V_i$的分数定义如下（Brin和Page，1998）：</p>
<p><img src="/img/17_04_26/001.png" alt=""></p>
<p>其中$d$是0和1之间的阻尼因子，它作用于将从给定顶点跳转到图中的另一个随机顶点的概率集成到模型中。在网页浏览的上下文中，这种基于图表的排名算法实现了“随机冲浪者模型”，其中用户以概率$d$随机点击链接，并以概率$1-d$跳转到一个全新的页面。因子$d$通常设置为0.85（Brin和Page，1998），这也是我们在具体实现中所使用的值。</p>
<p>从图中分配给每个节点的任意值开始，迭代计算直到达到低于给定的阈值。运行算法之后，得到一个与每个顶点相关联的分数，这表示图中顶点的“重要性”。请注意，TextRank运行到完成后获得的最终值，不受初始值的选择的影响，初始值的选择只会影响到收敛的迭代次数。</p>
<p>重要的是要注意，尽管本文中描述的TextRank应用程序依赖于从Google的PageRank（Brin和Page，1998）导出的算法，但是其他基于图表的排序算法，例如 HITS（Kleinberg，1999）或位置函数（Herings等，2001）也可以轻松地整合到TextRank模型中（Mihalcea，2004）。</p>
<h3 id="2-1_无向图">2.1 无向图</h3><p>虽然传统上应用于有向图，但是也可以将基于递归图的排序算法应用于无向图，在这种情况下，顶点的出度（out-degree）等于顶点的入度（in-degree）。对于松散连接的图形，随着边缘数量与顶点数量成比例，无向图趋向于具有更多的逐渐收敛曲线。</p>
<p>图1绘制了具有250个顶点和250个边缘的随机生成图的收敛曲线，收敛阈值为0.0001。随着图形的连通性增加（即较大数量的边缘），通常在较少迭代之后实现收敛，并且有向和无向图的收敛曲线实际上是重叠的。</p>
<p><img src="/img/17_04_26/002.png" alt=""></p>
<p>图1：基于图的收敛曲线排名：有向/无向，加权/未加权图，250个顶点，250个边。</p>
<h3 id="2-2_权重图">2.2 权重图</h3><p>在网页浏览的上下文中，页面中包含多个或部分链接到另一个页面是不寻常的，因此，基于图的原始PageRank定义是假设未加权的图。</p>
<p>然而，在我们的模型中的图是由自然语言文本构造的，并且也可以由包括从文本中提取的单元（顶点）之间的多个或部分链接构造。因此，可以在模型中指示并将两个顶点$V_i$和$V_j$之间的连接的“强度”作为加到连接两个顶点的对应边缘的权重$w_{ij}$来指示并合并到该模型中。因此，我们引入了一个新的基于图的排名公式，在计算与图中顶点相关的分数时考虑了边权重。请注意，可以定义类似的公式来整合顶点权重。</p>
<p><img src="/img/17_04_26/003.png" alt=""></p>
<p>图1绘制了2.1节中相同样本图的收敛曲线，其中对边进行了0到10的随机加权。尽管与未加权相比，最终顶点得分（因此排名）显着不同，但是对于加权和未加权图，收敛次数和收敛曲线的形状几乎相同。</p>
<h3 id="2-3_文本作为图">2.3 文本作为图</h3><p>为了使基于图的排序算法能够应用于自然语言文本，我们必须构建一个表示文本的图形，并将具有有意义关系的单词或其他文本实体进行互连。 根据手头的应用，各种尺寸和特征的文本单位可以作为图中的顶点添加，例如。 单词，搭配，整个句子或其他。 类似地，它是指示用于绘制任何两个这样的顶点之间的连接的关系的类型，例如。 词汇或语义关系，语境重叠等。</p>
<p>无论添加到图形中的元素的类型和特征如何，将基于图的排序算法应用于自然语言文本包括以下主要步骤：</p>
<ul>
<li>1.识别最佳定义手头任务的文本单位，并将其作为顶点添加到图形中。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/" itemprop="url">
                斯坦福机器学习课程 第八周 (1)聚类
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-20T22:32:58+08:00" content="2017-04-20">
            2017-04-20
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/20/斯坦福机器学习课程 第八周 (1)聚类/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h2 id="无监督学习介绍">无监督学习介绍</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/czmip/unsupervised-learning-introduction" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>接下来，我将介绍<strong>聚类</strong>这一概念。保证精彩！因为这是我们第一个<strong>无监督学习算法</strong>。我们要从未标记的数据中进行学习, 而不是从已标记的数据。 </p>
</blockquote>
<p>什么是无监督学习算法呢？</p>
<p>之前，在本课程的开始阶段，我曾简短介绍过无监督学习算法。现在，我想将<strong>无监督学习算法</strong>与<strong>监督学习算法</strong>做个对照。</p>
<h3 id="无监督学习算法与监督学习算法对比">无监督学习算法与监督学习算法对比</h3><p>下面是一个监督学习的例子：</p>
<p><img src="/img/17_04_20/001.png" alt=""></p>
<p>$$<br>训练集：｛(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),(x^{(3)},y^{(3)}),…,(x^{(m)},y^{(m)})｝<br>$$</p>
<p>这是一组附有标记的训练数据集，我们想要找出一个决策边界，来将两者分开：</p>
<p><img src="/img/17_04_20/002.png" alt=""></p>
<p>在这种监督式学习中，我们针对一组标记的训练数据提出一个适当的假设。</p>
<hr>
<p>相比之下，在无监督学习案例中，我们面对的是一组<strong>无标记</strong>的训练数据，数据之间不具任何关联的标记。</p>
<p>所以我们得到的数据看起来是下面这样的：</p>
<p><img src="/img/17_04_20/003.png" alt=""></p>
<p>$$<br>训练集：｛x^{(1)},x^{(2)},x^{(3)},…,x^{(m)}｝<br>$$</p>
<p>所以，在无监督学习中，我们将这种未标记的训练数据送入特定的算法，然后我们要求算法替我们分析出数据的结构。</p>
<p>就此数据而言，其中一种可能的结构是所有的数据大致地划分成两个类（或组），这种划分的算法称为<strong>聚类算法()</strong>：</p>
<p><img src="/img/17_04_20/004.png" alt=""></p>
<p>除此之外，无监督学习还包含其他各式各样的算法，用以寻找其他类型的结构。我们下面将会一一介绍。目前，我们先介绍聚类。</p>
<h3 id="聚类">聚类</h3><p>稍早前，我已经提到几个应用实例：</p>
<p><img src="/img/17_04_20/005.png" alt=""></p>
<ul>
<li>图1是细分市场，将所有用户划分至不同的细分市场组，以便于营销或服务。</li>
<li>图2是社交分析体系，比如在社交网络中观察一群人，看他们和谁有电子邮件来往，或者查找一群相互有联系的人。</li>
<li>图3是用聚类来组织运算集群或组织数据中心，因为，如果你知道在集群中，哪些计算机的数据中心倾向于一起工作，你可以用它重新组织你的资源，网络的布局，以及数据中心和通信。</li>
<li>图4是使用聚类算法来试图理解星系的形成，和其中的天文细节。</li>
</ul>
<p>总之，聚类是我们学到的第一个无监督学习算法。在接下来的内容中，我将谈论聚类的具体实现方式。</p>
<h2 id="K-Means_算法">K-Means 算法</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/93VPG/k-means-algorithm" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在聚类问题中，我们有未加标签的数据。我们希望有一个算法能够自动的把这些数据分成<strong>有紧密关系的子集</strong>，或是<strong>簇</strong>。<strong>K均值 (K-means)算法</strong>是现在最为广泛使用的聚类方法。那么在这个视频中，我将会告诉你，什么是K均值算法以及它是怎么运作的。</p>
</blockquote>
<p>K均值算法最好用图来表达。如图所示：</p>
<p><img src="/img/17_04_20/006.png" alt=""></p>
<p>现在有一些<strong>没加标签</strong>的数据，而我想将这些数据分成两个<strong>簇</strong>。</p>
<p>现在我执行K均值算法 方法是这样的 </p>
<p>首先我随机选择两个点，这两个点叫做<strong>聚类中心 (cluster centroids) </strong>:</p>
<p><img src="/img/17_04_20/007.png" alt=""></p>
<p>为什么要两个点呢？因为我希望聚出两个类。</p>
<p>K均值是一个迭代方法，它要做两件事情：</p>
<ul>
<li>第一是<strong>簇分配</strong>。</li>
<li>第二个是<strong>移动聚类中心</strong>。</li>
</ul>
<p>接下来介绍这两个步骤具体是在做什么。</p>
<h3 id="K-Means_第一步：簇分配">K-Means 第一步：簇分配</h3><p>在K均值算法的每次循环中，第一步是要进行<strong>簇分配</strong>。这就是说，我要遍历所有的样本（就是图上所有的绿色的点），然后依据每一个点是更接近红色的这个中心、还是蓝色的这个中心，来将每个数据点分配到两个不同的聚类中心中。</p>
<p>具体来讲，就是对数据集中的所有点，依据他们更接近红色这个中心、还是蓝色这个中心，进行染色。染色之后的结果如图所示：</p>
<p><img src="/img/17_04_20/008.png" alt=""></p>
<p>以上就是簇分配的步骤。</p>
<h3 id="K-Means_第二步：移动聚类中心">K-Means 第二步：移动聚类中心</h3><p>K均值的另一部分，是要<strong>移动聚类中心</strong>。</p>
<p>具体的操作方法是这样的：我们将两个聚类中心（也就是红色的叉和蓝色的叉）移动到和它一样颜色的那堆点的均值处。</p>
<p>那么我们要做的是找出所有红色的点，计算出它们的均值位置，然后我们就把红色点的聚类中心移动到这里。对蓝色的点也同样计算平均位置，然后移动蓝色聚类中心到该平均位置处。</p>
<p><img src="/img/17_04_20/009.png" alt=""></p>
<h3 id="K-Means_第三步：重复执行上面两步">K-Means 第三步：重复执行上面两步</h3><p>然后我们就会进入下一个<strong>簇分配</strong>。我们重新检查所有没有标签的样本，依据它离红色中心还是蓝色中心更近一些，重新将它染成红色或是蓝色。</p>
<p><img src="/img/17_04_20/010.png" alt=""></p>
<p>然后我们再次<strong>移动聚类中心</strong>。计算蓝色点的均值，以及红色点的均值，然后移动两个聚类中心：</p>
<p><img src="/img/17_04_20/011.png" alt=""></p>
<p>然后再做一遍<strong>簇分配</strong>和<strong>移动聚类中心</strong>操作：</p>
<p><img src="/img/17_04_20/012.png" alt=""></p>
<p>实际上，如果你从这一步开始，一直迭代下去，聚类中心是不会变的；并且 那些点的颜色也不会变。在这时，我们就能说<strong>K均值方法已经收敛了</strong>。</p>
<h3 id="K-Means的规范化描述">K-Means的规范化描述</h3><p>我们来用更加规范的格式描述K均值算法。</p>
<p>K均值算法接受两个输入：</p>
<ul>
<li>第一个是参数$K$，表示你想从数据中聚类出的簇的个数。</li>
</ul>
<blockquote>
<p>稍后会讲到选择$K$的方法</p>
</blockquote>
<ul>
<li>第二个输入参数是训练集$｛x^{(1)},x^{(2)},…,x^{(m)}｝$</li>
</ul>
<blockquote>
<p>因为这是非监督学习，我们的数据集中不需要$y$，同时在非监督学习的 K均值算法里，我们约定$x^{(i)}$是一个$n$维向量，这就是“训练样本是$n$维而不是$n+1$维”的原因（按照惯例，排除$x_0=1$这一项）。</p>
</blockquote>
<p><strong>K均值算法：</strong></p>
<p><img src="/img/17_04_20/013.png" alt=""></p>
<ul>
<li><p>第一步：随机初始化$K$个<strong>聚类中心</strong>，记作$μ_1$,$μ_2$一直到$μ_K$。 </p>
</li>
<li><p>第二步：</p>
<ul>
<li><p>K均值内部循环执行以下步骤：</p>
<ul>
<li><p>簇分配</p>
<p> 首先对于每个训练样本，我们用变量$c^{(i)}$表示$K$个聚类中心中最接近$x^{(i)}$的那个中心的下标（具体的类别），这就是簇分配。</p>
<blockquote>
<p>大写的$K$表示所有聚类中心的个数，小写的$k$则表示某个聚类中心的下标。</p>
</blockquote>
<p>  我们希望的是：<strong>在所有K个中心中，找到一个$k$使得$x_i$到$μ_k$的距离是$x^{(i)}$到所有的聚类中心的距离中最小的那个</strong>，这就是计算$c_i$的方法。</p>
<p>  这里还有另外的表示$c_i$的方法：我用<strong>范数</strong>的形式$||x^{(i)}-μ_k||$来表示，这是第$i$个训练样本到聚类中心$μ_k$的距离。</p>
<p>  接下来我要做的是找出$k$的值，让这个式子$||x^{(i)}-μ_k||$最小，然后将 $c^{(i)}$ 赋值为$k$。</p>
<p>  出于惯例，人们更喜欢用距离的平方$||x^{(i)}-μ_k||^2$来表示$x^{(i)}$距聚类中心$μ_k$的距离。所以我们可以认为 $c^{(i)}$ 的类别是属于距样本$x^{(i)}$的距离的平方最小的那个聚类中心的。 当然使距离的平方最小或是距离最小，都能让我们得到相同的$c^{(i)}$，但是我们通常还是使用距离的平方，因为这是约定俗成的。</p>
</li>
<li><p>移动聚类中心</p>
<p>  对于每个聚类中心：$k$从1循环到$K$，将$μ_k$赋值为这个簇的均值。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>举个栗子：</strong></p>
<p>某一个聚类中心，比如说是$μ_2$被分配了一些训练样本：1,5,6,10 这个表明$c^{(1)}=2$，$c^{(5)}=2$，$c^{(6)}=2$，$c^{(10)}=2$。如果我们从<strong>簇分配</strong>那一步得到了这些结果，这表明，样本1,5,6,10被分配给了聚类中心2；然后在移动聚类中心这一步中，我们计算出这四个的平均值，即计算$x_{(1)}+x_{(5)}+x_{(6)}+x_{(10)}$，然后计算它们的平均值。这时$μ_2$就是一个$n$维的向量，因为$x^{(1)}$，$x^{(5)}$，$x^{(6)}$，$x^{(10)}$ 都是$n$维的向量。这样聚类中心$μ_2$的移动就结束了。</p>
<h3 id="异常情况">异常情况</h3><p>现在，我要问的问题是：</p>
<p>既然我们要让$μ_k$移动到分配给它的那些点的均值处，那么如果存在一个没有点分配给它的聚类中心，那怎么办? </p>
<p>通常在这种情况下，我们就直接移除那个聚类中心。如果这么做了，最终将会得到$K-1$个簇，而不是$K$个簇。</p>
<p>但如果你就是需要$K$个簇，尽管存在没有点分配给它的聚类中心，你所要做的是，重新随机找一个聚类中心。（但是直接移除那个中心，是更为常见的方法。不过在实际过程中，这个问题不会经常出现。）</p>
<hr>
<p>在这个视频结束之前，我还想告诉你<strong>K均值算法</strong>的另外一个常见应用：<strong>应对没有很好分开的簇(non-separated clusters)</strong>。</p>
<p>到目前为止，我们的K均值算法都是基于一些像图中所示的数据：</p>
<p><img src="/img/17_04_20/014.png" alt=""></p>
<p>有很好的隔离开来的三个簇，但是事实情况是，K均值经常会用于一些这样的数据：</p>
<p><img src="/img/17_04_20/015.png" alt=""></p>
<p>看起来并没有很好的分开几个簇。</p>
<p>这是一个关于T恤的大小的应用的例子。假设你是T恤制造商，你找到了一些人，想把T恤卖给他们，然后你搜集了一些这些人的身高和体重的数据。我猜，身高体重更重要一些。然后你可能收集到了上图中一些关于人们身高和体重的样本，然后你想确定一下T恤的大小。</p>
<p>假设我们要设计三种不同大小的t恤：小号、中号、和大号，那么小号应该是多大的?中号呢?大号呢?</p>
<p>使用K均值算法进行聚类，是一种解决这个问题的方法。就像我展示的那样，而且K均值可能将这些数据聚成三个簇：</p>
<p><img src="/img/17_04_20/016.png" alt=""></p>
<p>所以说，尽管这些数据原本看起来并没有三个分开的簇，但是从某种程度上讲，K均值仍然能将数据分成几个类。你能做的就是看这第一群人，然后查看他们的身高和体重，试着去设计对这群人来说比较合身的小号衣服；以及设计一个中号的衣服；设计一个大号的衣服。</p>
<p>这就是一种<strong>市场细分</strong>的例子。当你用K均值方法将你的市场分为三个不同的部分，你就能够区别对待你三类不同的顾客群体，从而更好的适应他们不同的需求。就像大、中、小，三种不同大小的衣服那样。</p>
<p><img src="/img/17_04_20/017.png" alt=""></p>
<p>这就是K均值算法，而且你现在应该已经知道如果去实现，K均值算法并且利用它解决一些问题。在下面的视频中，我想把K均值算法 研究的更深入一些，然后讨论一下如何能让K均值表现得更好一些的问题。</p>
<h2 id="优化目标">优化目标</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/G6QWt/optimization-objective" target="_blank" rel="external">视频地址</a></p>
<p>在大多数我们已经学到的<strong>监督学习</strong>算法中(例如线性回归，逻辑回归，以及更多的算法）都有一个优化目标函数，即需要通过算法进行最小化的代价函数。</p>
<p>事实上，<strong>K均值</strong>也有这样一个<strong>优化目标函数</strong>（或者说是代价函数）。</p>
<p>了解和使用这个<strong>K均值</strong>的优化目标函数有两方面的目的：</p>
<ul>
<li>首先这将能帮助我们调试学习算法，确保K均值算法是在正确运行中。</li>
<li>第二个也是最重要的一个目的是，<strong>K均值</strong>优化目标函数将帮助我们找到更好的簇，并且避免局部最优解。（后面会讲到）</li>
</ul>
<hr>
<p>另外顺便提一下，当K均值正在运行时，我们将对两组变量进行跟踪：</p>
<p>首先是$c^{(i)}$:</p>
<p>$$<br>c^{(i)}=表示 K 个聚类中心中最接近x^{(i)}的那个中心的索引（即当前样本x^{(i)}所归为的那个簇的索引）<br>$$</p>
<p>其次是$μ_k$:</p>
<p>$$<br>μ_k=表示 第k个簇的聚类中心 （μ_k\in R^n）<br>$$</p>
<p>顺便再提一句，K均值中我们用大写$K$来表示<strong>簇的总数</strong>，用小写$k$来表示<strong>聚类中心的序号</strong>。因此，小写$k$的范围如下：</p>
<p>$$<br>k\in｛1,2,…,K｝<br>$$</p>
<p>除此以外，还有另一个符号，我们用$μ_c^{(i)}$：</p>
<p>$$<br>μ_c^{(i)}=表示x^{(i)}所属的那个簇的聚类中心<br>$$</p>
<p>举个例子来解释：</p>
<p>假如说$x^{(i)}$被划为了第5个簇，这就是说$x^{(i)}$被分配到了第5个簇，也就是$c^{(i)}=5$。因此$μ_c^{(i)}=μ_5$。所以这里的 $μ_c^{(i)}$就是第5个簇的聚类中心。</p>
<p>而也正是我的样本$x^{(i)}$所属的第5个簇有了这样的符号表示，现在我们就能写出K均值聚类算法的优化目标了。</p>
<h3 id="K均值的代价函数">K均值的代价函数</h3><p>以下便是K均值算法需要最小化的<strong>代价函数</strong>：</p>
<p>$$<br>J(c^{(1)},…,c^{(m)},μ_1,…,μ_K)=\frac{1}{m}\sum_{i=1}^m||x^{(i)}-μ_c^{(i)}||^2<br>$$</p>
<p>代价函数$J$的参数$c^{(1)},…,c^{(m)}$以及$μ_1,…,μ_K$，随着算法的执行过程，这些参数将不断变化。</p>
<p>函数的右边给出了优化目标，即每个样本$x^{(i)}$到它所属的聚类中心距离的平方值。$x^{(i)}$就是训练样本的位置，$μ_c^{(i)}$是$x^{(i)}$样本所属的聚类中心的位置。</p>
<p>例如:</p>
<p><img src="/img/17_04_20/018.png" alt=""></p>
<p>如图，图中$x^{(i)}$样本被划分到了$μ_5$这个聚类中心，那么$||x^{(i)}-μ_c^{(i)}||^2$这个距离的平方，也就是在求样本点$x^{(i)}$到$μ_5$之间的距离的平方。</p>
<hr>
<p>K均值的目标就是要最小化代价函数：</p>
<p>$$<br>\min\limits_{c^{(1)},…,c^{(m)},\\μ_1,…,μ_K}<br>J(c^{(1)},…,c^{(m)},μ_1,…,μ_K)<br>$$</p>
<p>在K均值算法中，有时候也叫做<strong>失真代价函数(distortion cost function)</strong>。</p>
<hr>
<p>现在，我们已经理解了K均值算法的原理就是最小化代价函数$J$的过程。我们也可以用这个原理，来试着调试我们的学习算法，保证我们对K均值算法的实现过程是正确的。</p>
<p>在下一节视频中，我们将一起看看如何帮助K均值找到更好的簇，同时避免局部最优解。</p>
<h2 id="随机初始化">随机初始化</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/drcBh/random-initialization" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在本节课中，我们讨论一下如何初始化K均值聚类方法。</p>
<p>更重要的是，这将引导我们讨论<strong>如何避开局部最优来构建K均值聚类方法</strong>。</p>
</blockquote>
<p>对于我们之前讨论过的K均值聚类算法：</p>
<p><img src="/img/17_04_20/019.png" alt=""></p>
<p>其中我们之前没有讨论得太多的是这一步：</p>
<p><img src="/img/17_04_20/020.png" alt=""></p>
<p>即随机初始化聚类中心$μ_1,μ_2,…,μ_{K} \in R^n$。</p>
<p>如何初始化聚类中心这一步，有几种不同的方法可以用来随机初始化聚类中心。但是，事实证明，有一种可能是效果最好的方法。接下来我就将这个方法介绍给你。</p>
<hr>
<p>这里展示了我通常是如何初始化我的聚类中心的。</p>
<ul>
<li><p>1.确保$K&lt;m$</p>
<ul>
<li>当运行K均值方法时，你需要有一个聚类中心数值$K$，$K$值要比训练样本的数量$m$小，即$K&lt;m$。</li>
</ul>
</li>
<li><p>2.随机初始化</p>
<ul>
<li>随机挑选$K$个训练样本，然后我要做的是设定$μ_1,…,μ_k$让它们等于这$K$个样本。</li>
</ul>
</li>
</ul>
<hr>
<p>下面用一个具体例子来说明：</p>
<p>我们假设$K=2$，那么我们就需要找到两个聚类中心。为了初始化聚类中心，我要做的是随机挑选几个样本。比如说，我挑选了下面这两个点作为聚类中心：</p>
<p><img src="/img/17_04_20/021.png" alt=""></p>
<p>此时的这个例子看起来划分的相当不错，但是有时候我可能不会那么幸运。也许我最后会挑选到下面这样的两个点作为聚类中心：</p>
<p><img src="/img/17_04_20/022.png" alt=""></p>
<p>通过对上面两种初始化情况的对比，你可能会猜到K均值算法在它们两种情况下，会得到不同的结果。这取决于聚类簇的随机初始化方法。K均值方法最后可能得到不同的结果，尤其是如果K均值方法落在局部最优的时候。</p>
<p>如果给你一些这样的数据：</p>
<p><img src="/img/17_04_20/023.png" alt=""></p>
<p>这看起来好像有3个聚类：</p>
<p><img src="/img/17_04_20/024.png" alt=""></p>
<p>那么，如果你运行K均值方法，如果它最后得到一个局部最优，这可能是真正的全局最优，你可能会得到这样的聚类结果：</p>
<p><img src="/img/17_04_20/025.png" alt=""></p>
<p>但是如果你运气特别不好，随机初始化K均值方法也可能会卡在不同的局部最优上面：</p>
<p><img src="/img/17_04_20/026.png" alt=""></p>
<p>对于左边的这种情况，相当于将左下方和上方的样本分为了一类，将右下方的样本分了两类：</p>
<p><img src="/img/17_04_20/027.png" alt=""></p>
<p>对于右边的这种情况，相当于将下面的样本整体的分为了一类，将上方的样本分为了两类。</p>
<p>因此，如果你担心K均值方法会遇到上面这种局部最优的问题，并且你想提高K均值方法找到最有可能的聚类的几率的话，我们能做的就是尝试多次随机的初始化，而不是仅仅初始化一次K均值方法就希望它会得到很好的结果。</p>
<p>我们能做的是：<strong>初始化K均值很多次，并运行K均值方法很多次，通过多次尝试来保证我们最终能得到一个足够好的结果。一个尽可能局部或全局最优的结果。</strong></p>
<p>这才是正确的随机初始化聚类中心的方法。</p>
<h3 id="具体介绍">具体介绍</h3><p>具体来说，假如我决定运行K均值方法一百次，那么我就需要执行这个循环100次。这是一个相当典型的次数数字，有时会是从50到1000之间的数字。</p>
<p>假设说有决定运行K均值方法100次，那么这就意味着我们要随机初始化K均值方法100次。对于这100次随机初始化的每一次，我们都需要运行K均值方法。我们会得到一系列聚类结果和一系列聚类中心之后，我们可以计算<strong>失真函数</strong>$J$。用我们得到的这些聚类结果和聚类中心来计算这样一个结果函数。</p>
<p>完成整个100次迭代之后，你会得到这100种聚类数据的这些方法。最后你要做的是，在所有这100种用于聚类的方法中，选取能够给我们代价最小的一个，给我们最低畸变值的一个。</p>
<p>事实证明，如果你运行K均值方法时，所用的聚类数相当小。比如聚类数是从2到10之间的任何数的话，做多次的随机初始化，通常能够保证你能有一个较好的局部最优解，保证你能找到更好的聚类数据。但是如果K非常大的话，比如K比10大很多，就不太可能会有太大的影响。事实上，这种情况下有可能你的第一次随机初始化就会给你相当好的结果。</p>
<p>做多次随机初始化可能会给你稍微好一点的结果，但是不会好太多。但是在这样一个聚类数相对较小的体系里，特别是如果你有2个或者3个或者4个聚类的话，随机初始化会有较大的影响。可以保证你在最小化失真函数的时候，得到一个很小的值。并且能得到一个很好的聚类结果。</p>
<p>这就是K均值的随机初始化的方法。</p>
<h2 id="选择簇的数量">选择簇的数量</h2><p><a href="https://www.coursera.org/learn/machine-learning/lecture/Ks0E9/choosing-the-number-of-clusters" target="_blank" rel="external">视频地址</a></p>
<blockquote>
<p>在本节中，我想讨论一下K-均值聚类的最后一个细节，就是确定聚类的数目，即如何去选择$K$的值。</p>
<p>说实话，这个问题没有一个非常标准的解答。目前用来决定聚类数目的最常用的方法，仍然是通过看可视化的图，或者看聚类算法的输出结果，或者其他一些东西来手动地决定聚类的数目。</p>
<p>但是，我确实经常被别人问到这样的问题：“你是如何来选择聚类的数目的？” 我只能告诉你一些人们现在对这个问题的思考，人们现在对这个问题的最为常见的做法，实际上仍是手动选择聚类的数目。</p>
</blockquote>
<hr>
<p>选择聚类的数目可能不总是那么容易，大部分情况下，对于数据集中有多少个聚类中心通常是模棱两可的。</p>
<p>看到这样一个数据集：</p>
<p><img src="/img/17_04_20/028.png" alt=""></p>
<p>有些人可能会看到四个聚类，那么这就意味着需要使用$K=4$：</p>
<p><img src="/img/17_04_20/029.png" alt=""></p>
<p>或者有些人可能会看到两个聚类，这就意味着$K=2$：</p>
<p><img src="/img/17_04_20/030.png" alt=""></p>
<p>可能其他人会看到3个聚类。</p>
<p>在我看来它的真实的类别数实际上确实是模棱两可的，所以我并不认为这里有一个正确答案。这就是无监督学习的一部分。没有给我们标签，所以不会总有一个清晰的答案。这就是为什么，做一个能够自动选择聚类数目的算法，是非常困难的原因之一。</p>
<h3 id="肘部法则_(Elbow_Method)">肘部法则 (Elbow Method)</h3><p>当人们讨论选择聚类数目的方法时，可能会提及一个叫做<strong>肘部法则 (Elbow Method)</strong>的方法。现在我来介绍一下它，之后会提及到它的一些优点和缺点。</p>
<h4 id="肘部法则引入">肘部法则引入</h4><p>那么对于肘部法则，我们所需要做的是改变K的值（也就是聚类类别的总数）。</p>
<p>我们用K值为1来运行K-均值聚类算法。这就意味着所有的数据都会分到一个类里。然后计算代价函数（或者说计算畸变）$J$，并将其画在这儿：</p>
<p><img src="/img/17_04_20/031.png" alt=""></p>
<p>然后我们选用两个聚类来运行K-均值聚类算法。可能用了多个随机的初始中心，也可能没用。那么有两个聚类的话，我们很可能得到一个较小的畸变值，把它画在这儿：</p>
<p><img src="/img/17_04_20/032.png" alt=""></p>
<p>然后用三个聚类来运行K-均值聚类。你很有可能得到更小的畸变值，把它画在这儿：</p>
<p><img src="/img/17_04_20/033.png" alt=""></p>
<p>之后再让聚类数目等于4、5来运行K-均值聚类，最后我们就能得到一条曲线，它展示了随着聚类数量的增多，畸变值是如何下降的。我们可能会得到一条这样的曲线：</p>
<p><img src="/img/17_04_20/034.png" alt=""></p>
<p>看到这条曲线，肘部法则会说：“我们来看这个图，这里看起来像是一个很清楚的肘点”。</p>
<p><img src="/img/17_04_20/035.png" alt=""></p>
<p>这就类比于人的手臂。这就是肘部法则。</p>
<p>在这里，你会发现这样一种模式：K从1变化到2、再从2到3时，畸变值迅速下降；然后在3的时候，到达一个肘点。此后畸变值就下降得非常慢。这样看起来，也许使用3个类是聚类数目的正确选择。这是因为那个点是曲线的肘点。就是说畸变值快速地下降，直到$K=3$这个点，在这之后就下降得非常慢，那么我们就选$K=3$。</p>
<h4 id="肘部法则局限性">肘部法则局限性</h4><p>当你应用肘部法则的时候，如果你得到了一个像上面这样的图，那么这非常好，这是一种用来选择聚类个数的合理方法。而事实证明肘部法则并不那么常用，其中一个原因是如果你把这种方法用到一个聚类问题上，事实上你最后得到的曲线通常看起来是更加模棱两可的，就像这样：</p>
<p><img src="/img/17_04_20/036.png" alt=""></p>
<p>如果你看到这条曲线，也许没有一个清晰的肘点，而畸变值像是连续下降的，也许3是一个好选择，也许4是一个好选择，也许5也不差。如果实际情况中，你遇到的肘点的位置并不明确，这使得用这个方法来选择聚类数目变得较为困难。</p>
<h4 id="肘部法则小结">肘部法则小结</h4><p>简单小结一下肘部法则：它是一个值得尝试的方法，但是我不会期待它在任何问题上都有很高的表现。</p>
<h3 id="通过下游来决定聚类数量">通过下游来决定聚类数量</h3><p>最后，有另外一种方法来考虑如何选择K的值。</p>
<p>通常人们使用K-均值聚类算法是为了某些后面的用途，或者说某种下游的目的。而要求得一些聚类也许你会用K-均值聚类算法来做市场分割。例如我们之前谈论的T恤尺寸的例子，也许你会用K-均值聚类来让电脑的聚类变得更好，或者可能为了某些别的目的学习聚类，等等。如果那个后续下游的目的（比如市场分割）能给你一个评估标准，那么通常来说决定聚类数量的 更好的办法是，看不同的聚类数量能为后续下游的目的提供多好的结果。</p>
<p>我们来看一个具体的例子：</p>
<p>我们再看一下T恤尺寸这个例子。我想要决定“我是需要3种T恤尺寸么吗？”</p>
<p>所以我选择$K=3$。我可能有小号、中号、大号三类T恤，或者我可以选择$K=5$，那么我可能有特小号、小号、中号、大号和特大号尺寸的T恤。所以，你可能有3种、4种或者5种T恤尺寸。</p>
<p>因此如果我用$K=3$来运行K-均值聚类，我得到的结果可能是这样的：</p>
<p><img src="/img/17_04_20/037.png" alt=""></p>
<p>然而，果我用$K=5$来运行K-均值聚类的话，我得到的结果可能是这样的：</p>
<p><img src="/img/17_04_20/038.png" alt=""></p>
<p>这个例子给了我们对于选择聚类数目问题的另一种方法。</p>
<p>具体来说，你要做的是从T恤生意的角度来思考这个事情，然后问“如果我有5个分段 ，那么我的T恤有多适合我的顾客？那么我的T恤有多适合我的顾客？我可以卖出多少T恤？我的顾客将会有多高兴呢？”</p>
<p>从T恤生意的角度去考虑，其中真正有意义的是：我是需要更多的T恤尺寸 来更好地满足我的顾客？还是说我需要更少的T恤尺寸，我制造的T恤尺码就更少，我就可以将它们更便宜地卖给顾客？因此T恤的销售业务的观点 可能会提供给你一个决定采用3个类还是5个类的方法。</p>
<h3 id="簇数量选择_总结">簇数量选择 总结</h3><p>总结一下：大部分时候聚类数目仍然是通过手动人工输入或我们的洞察力来决定，一种可以尝试的方法是使用肘部法则，使用肘部法则但是我不会总是 期望它能表现得好。选择聚类数目的更好方法是去问一下你运行K-均值聚类是为了什么目的？然后想一想聚类的数目是多少才适合你运行K-均值聚类的后续目的。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/" itemprop="url">
                斯坦福机器学习课程 第七周 (3)使用SVM
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-04-11T22:47:58+08:00" content="2017-04-11">
            2017-04-11
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/11/斯坦福机器学习课程 第七周 (3)使用SVM/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><h2 id="使用SVM">使用SVM</h2><blockquote>
<p>这段视频中，我们将介绍使用SVM时，我们实际上需要做些什么。</p>
</blockquote>
<p><strong>支持向量机</strong>是一个特定的优化问题，但是我不建议你自己去手动实现这一算法来求解参数$\theta$。就像如今只有很少的人，或者说根本没有人会考虑自己写代码，来实现对矩阵求逆，或求一个数的平方根等。我们只需要调用库函数来实现这些功能即可。</p>
<p>同样，可以用于解决SVM优化问题的软件很复杂，而且已经有专门研究数值优化很多年的学者在做这个，因此你需要使用好的软件库来做这个。我强烈建议使用一个高度优化的软件库，而不是尝试自己去实现它。</p>
<p>这里推荐两个我最常用到的库：liblinear和libsvm。</p>
<p>尽管你不需要自己去实现SVM，但你也需要做以下几件事：</p>
<ul>
<li>选择参数$C$</li>
<li>选择<strong>核函数</strong>（相似度函数）</li>
</ul>
<h3 id="核函数的选择">核函数的选择</h3><h4 id="线性核函数（无核函数）">线性核函数（无核函数）</h4><p>关于<strong>核函数</strong>其中一个选择是<strong>不用任何核函数</strong>（不用任何核函数也叫作<strong>线性核函数</strong>）:</p>
<p>即对于预测结果$y=1$，满足$\theta^Tx\ge0$。</p>
<blockquote>
<p>例如这种情况下当$\theta_0 + \theta_1x_1 + … + \theta_nx_n \ge 0$时，预测$y=1$。</p>
</blockquote>
<p>对<strong>线性核函数</strong>这个术语，你可以把它理解为这个版本的SVM。它只是给你一个标准的线性分类器，因此对某些问题来说，它是一个合理的选择：</p>
<p>具体来说，当你的特征数量$n$很大，但数据量$m$很小时，由于数据量不足，在这种情况下如果使用其他核函数，你可能会<strong>过拟合</strong>，因此，此时<strong>线性核函数</strong>是一个合理的选择。</p>
<h4 id="高斯核函数">高斯核函数</h4><p>$$<br>f_i=exp(-\frac{||x-l^{(i)}||^2}{2\sigma^2}),<br>$$</p>
<p>这是我们之前见过的高斯核函数。如果你选择这个核函数，那么你需要选择一个$$\sigma^2$$。</p>
<p>我们之前讨论如何权衡偏差、方差的时候谈论过：</p>
<ul>
<li>如果$\sigma^2$很大，那么你就有可能得到一个<strong>较高偏差较低方差</strong>的分类器。</li>
<li>如果$\sigma^2$很小，那么你就有可能得到一个<strong>较低偏差较高方差</strong>的分类器。</li>
</ul>
<p>那么，什么时候选择高斯核函数呢？</p>
<p>如果你原来的特征变量$x$是$n$维的，而且<strong>$n$很小，样本数量$m$很大时</strong>，高斯核函数会是一个不错的选择。</p>
<h5 id="如何使用高斯核函数">如何使用高斯核函数</h5><p>在很多SVM的软件包中，如果你需要使用SVM时，你需要提供一个核函数。</p>
<p>具体地说，如果你决定使用高斯核函数，那么你需要做的就是根据你所用的SVM软件包，来提供一个用于计算核函数的特定特征的方法:</p>
<p><img src="/img/17_04_11/001.png" alt=""></p>
<p>然后它将自动地生成所有特征变量。</p>
<blockquote>
<p><strong>注意</strong>：如果你有大小很不一样的特征变量，在使用高斯核函数之前，对它们进行<strong>归一化</strong>是很重要的。</p>
</blockquote>
<p>假设你在计算$x$和$l$之间的范数(就是高斯核函数的分子项)：</p>
<p>$||x-l||^2$</p>
<p>这个式子所表达的含义如下：</p>
<p>$$<br>v=x-l<br>$$</p>
<p>$$<br>\begin{align*}<br>||v||^2 &amp;= v_1^2 + v_2^2 + … + v_n^2 \\<br>&amp;= (x_1-l_1)^2 + (x_2-l_2)^2 + … + (x_n-l_n)^2<br>\end{align*}<br>$$</p>
<p>其中$v$、$x$、$l$都是向量，由于$x$是$n$维的，所以$v$也是$n$维的。</p>
<p>现在如果你的特征变量取值范围很不一样。例如房价预测中，$x_1$表示1000平方英尺，$x_2$表示卧室数量为2，那么$(x_1-l_1)$可能相较于$(x_2-l_2)$大很多。</p>
<p>因此，为了让SVM更好的工作，我们需要对特征变量进行<strong>归一化</strong>处理。这将会保证SVM能够同等地关注到所有不同的特征变量。</p>
<h4 id="选择其他核函数">选择其他核函数</h4><p>当你尝试使用SVM时，目前你能用到的核函数就是<strong>线性核函数</strong>和<strong>高斯核函数</strong>，这里有一个警告：</p>
<p>不是所有你可能提出来的相似度函数都是有效的核函数。线性核函数，高斯核函数，以及其他人有时会用到的其他的核函数，他们全部需要满足一个技术条件，这个条件叫做<strong>摩赛尔定理(Mercer`s Theorem)</strong>。</p>
<p>因为支持向量机算法的实现有许多巧妙的数值优化技巧，为了有效地求解参数$\theta$，在最初的设想里，有一个这样的决定，将我们的注意力仅仅限制在可以满足<strong>摩赛尔定理</strong>的核函数上，这个定义做的是：确保所有的SVM包能够使用大量的优化方法，并且快速地得到参数$\theta$。所以，大多数人最后要么使用线性核函数、要么使用高斯核函数。也有一些其他的核函数是满足<strong>摩赛尔定理</strong>的，而我个人是很少很少使用其他核函数的。</p>
<p>所以，我只是简单提及一下你可能会遇到的其他核函数，他们有：</p>
<ul>
<li><p><strong>多项式核函数（Polynomial kernel）</strong>：</p>
<ul>
<li><p>将$x$和$l$之间的相似度，定义为$(x^Tl)^2$：</p>
<p>$$<br>k(x,l)=(x^Tl)^2<br>$$</p>
<p>这就是一个$x$和$l$相似度的估量，如果$x$和$l$每一项很接近，那么这个内积就会很大。</p>
<p>这是一个有些不寻常的核函数，它并不常用，但你可能会见到有人使用它的变体形式，比如：</p>
<p>$$<br>k(x,l)=(x^Tl)^3<br>$$</p>
<p>$$<br>k(x,l)=(x^Tl + 1)^3<br>$$</p>
<p>$$<br>k(x,l)=(x^Tl + 5)^4<br>$$</p>
<p>这些都是多项式核函数的变形形式。</p>
<p>多项式核函数实际上有两个参数，一个是加在后面的常数项，如上面最后式子中的5；另一个是多项式的次数，如上面最后式子中的4。</p>
<p>因此，多项式核函数的更一般的形式是：</p>
<p>$$<br>k(x,l)=(x^Tl + constant)^{degree}<br>$$</p>
<p>这种核函数并不像高斯核函数那样频繁的使用，通常他只用在当$x$和$l$都是严格的非负数时。这样以确保内积值永远不会是负数。</p>
<p>这捕捉到了这样一个直观感觉：如果$x$和$l$之间非常相似，也许它们之间的内积会很大。</p>
<p>它们也有其他的一些性质，但是人们通常用得不多。</p>
</li>
</ul>
</li>
</ul>
<p>你也有可能会碰到其他一些更难懂的核函数，比如：</p>
<ul>
<li><strong>字符串核函数（String kernel）</strong>:<ul>
<li>如果你的输入数据是文本字符串，或者其他类型的字符串，有时会用到这个核函数。</li>
</ul>
</li>
<li><strong>卡方核函数（chi-square kernel）</strong></li>
<li><strong>直方图交叉核函数（histogram intersection kernel）</strong></li>
<li>…</li>
</ul>
<p>你可以用它们来度量不同对象之间的相似性。</p>
<p>例如，你在做一些文本分类问题，在这个问题中，输入变量$x$是一个字符串，我们想要通过字符串核函数来找到两个字符串间的相似度（但是我个人很少用这些更加难懂的核函数，我想我平生可能用过一次卡方核函数，可能用过一次或两次直方图交叉核函数，我甚至没用过字符串核函数）。</p>
<hr>
<h3 id="两个细节">两个细节</h3><p>我想要在这个视频里讨论最后两个细节。</p>
<h4 id="多类分类">多类分类</h4><p>在多类分类中，你有K个类别：</p>
<p>$$<br>y \in ｛1,2,3,…,K｝<br>$$</p>
<p>对应下图：</p>
<p><img src="/img/17_04_11/002.png" alt=""></p>
<p>很明显，这里$K=4$。</p>
<p>那么怎样让SVM输出下面这种各个类别间合适的判定边界呢？</p>
<p><img src="/img/17_04_11/003.png" alt=""></p>
<p>大部分SVM软件包已经内置了多类分类的函数了，因此，如果你用的是这种软件包，你可以直接使用内置函数。</p>
<p>另一种方式就是使用<strong>一对多(one-vs-all)方法</strong>。这个我们在讲逻辑回归的时候讨论过，所以，你要做的就是要训练$K$个SVM，每一个SVM把一个类同其他类区分开。这种操作会给你$K$个参数向量：</p>
<p>$$<br>\theta^{(1)},\theta^{(2)},…,\theta^{(K)}<br>$$</p>
<p>最后，这就与我们在逻辑回归中用到的一对多方法一样，选取使得$(\theta^{(i)})^Tx$最大的类$i$即可。</p>
<blockquote>
<p>其实大多数软件包都已经内置了多类分类的函数，因此你不必重新造轮子。</p>
</blockquote>
<h4 id="逻辑回归_vs_SVM">逻辑回归 vs SVM</h4><p>关于<strong>逻辑回归</strong>和<strong>SVM</strong>，我想讨论的是，你什么时候应该用哪个呢？</p>
<p>假设$n$是特征变量的个数，$m$是训练样本数：</p>
<ul>
<li>如果$n$(相对于$m$)大很多时，使用<strong>逻辑回归</strong>，或者使用<strong>无核函数的SVM（线性核函数）</strong>。<br>  比如你有一个文本分类的问题，特征数量$n=10000$，而且如果你的训练集大小为$m=10$，在这个问题中，你有10000个特征变量，对应10000个词，但是你只有10个训练样本。这种情况下就比较适合使用逻辑回归或者线性核函数的SVM了。</li>
<li>如果$n$较小，$m$是中等大小，（例如$n$为1到1000之间的值，$m$为10到10000之间的值）那么使用<strong>高斯核函数的SVM</strong>效果好一些。</li>
<li>如果$n$很小，$m$很大时（例如$n=1000$,$m=100000+$），那么高斯核函数的SVM运行起来会很慢，这种情况下，需要<strong>尝试手动地创建更多的特征变量，然后使用逻辑回归或者无核函数的SVM（线性核函数）</strong>。</li>
</ul>
<p>逻辑回归和不带核函数的SVM它们都是非常相似的算法，他们会做相似的事情，并且表现也相似，但是根据你实现的具体情况，其中一个可能会比另一个更加有效。</p>
<p>但是SVM的威力会随着你用不同的核函数而发挥出来。</p>
<h4 id="什么时候使用神经网络？">什么时候使用神经网络？</h4><p>最后，神经网络应该在什么时候使用呢？</p>
<p>对于上面所有的情况，一个设计得很好的神经网络也很可能会非常有效，它的一个缺点（或者说不使用神经网络的原因）是：神经网络训练起来可能会很慢。但是如果你有一个非常好的SVM实现包，它会运行得比较快，比神经网络快很多。</p>
<blockquote>
<p>SVM的优化问题，实际上是一个<strong>凸优化</strong>问题。因此好的SVM优化软件包总是会找到全局最小值，或者接近它的值。<br>对于SVM，你不需要担心局部最优。在实际应用中，局部最优对神经网络来说不是非常大，但是也不小。所以使用SVM，你不用考虑这部分问题。</p>
</blockquote>
<hr>
<h3 id="总结">总结</h3><p>最后，如果你觉得上面这些使用参考有一些模糊，在面临实际问题时，仍然不能完全确定具体使用哪个算法更好，这个其实很正常。</p>
<p>当我遇到机器学习问题时，有时确实不清楚具体使用哪个算法更好，但是正如你在之前的视频中看到的，算法确实很重要，但是通常更重要的是：<strong>你有多少数据</strong>，<strong>你有多熟练</strong>，<strong>是否擅长做误差分析和调试学习算法</strong>，<strong>想出如何设计新的特征变量</strong>，<strong>想出如何设计新的特征变量</strong>，以及<strong>找出应该输入给学习算法的其它特征变量</strong>等方面。通常这些方面会比你使用<strong>逻辑回归</strong>还是<strong>SVM</strong>更加重要。</p>
<p>但是<strong>SVM</strong>仍然被广泛认为是<strong>最强大的学习算法之一</strong>，最强大的学习算法之一，而且SVM在一个区间内是一个非常有效地学习复杂非线性函数的方法。因此，有了<strong>逻辑回归</strong>、<strong>神经网络</strong>、<strong>SVM</strong>这三个学习算法，我想你已经具备了在广泛的应用里构建最前沿的机器学习系统的能力。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/" itemprop="url">
                通过AspectJ代码注入来实现scheme跳转条件的检查判断
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-21T22:48:58+08:00" content="2017-03-21">
            2017-03-21
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/Android/" itemprop="url" rel="index">
                  <span itemprop="name">Android</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/21/通过AspectJ代码注入来实现scheme跳转条件的检查判断/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>scheme跳转是Android通过外部链接打开APP指定页面的一种常见的实现方式，如果只是简单的跳转，那么不需要做什么额外的判断就可以打开指定页面了，但我们的产品中有一个需求就是：在通过scheme跳转打开某一个页面的时候，需要判断一些前置条件，如果前置条件满足的情况下，才能执行跳转，如果前置条件不满足，那么需要缓存本次跳转，直到需要满足的条件被触发时，才去执行跳转。</p>
<p>简单说来就是下面这张图：</p>
<p><img src="/img/17_03_21/001.png" alt=""></p>
<p>一开始我想到的处理方式是通过在Activity的基类里的<code>onCreate()</code>方法之前做判断逻辑，如果符合条件，则正常执行，如果条件不满足，则执行<code>finish()</code>。</p>
<p>虽然可以满足需求，但这样的代码侵入性太高，逻辑必须侵入到Activity的基类中，容易与基类中其他逻辑产生耦合。</p>
<p>因此为了解决这个方式，我想到的解决方式就是使用AOP的方式，在<code>onCreate()</code>之前注入我们的判断逻辑的代码，最后的使用方式可以简化到仅仅使用一行注解来添加判断条件：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@SchemeCheck</span>(conditions = &#123;Condition.LOGIN&#125;)</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TargetActivityA</span> <span class="keyword">extends</span> <span class="title">Activity</span> </span>&#123;</div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</div><div class="line">        <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">    &#125;</div><div class="line">    ...</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这样一来，我们就不用考虑在Activity的基类中写这些可能产生冗余的逻辑了。</p>
<p>最终实现效果如下：</p>
<ul>
<li>判断<strong>登录</strong>条件</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/002.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断<strong>下载</strong>条件</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/003.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断<strong>登录并且下载</strong></li>
</ul>
<video width="300px" align="center" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/004.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<ul>
<li>判断登录或者下载</li>
</ul>
<video width="300px" autoplay="autoplay" loop="loop" id="video" controls preload="none"><br>  <source id="mp4" src="/img/17_03_21/005.mp4" type="video/mp4"><br>  <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<p>接下来介绍一下我是如何实现的。</p>
<h2 id="如何实现">如何实现</h2><p>首先关于<strong>依赖注入</strong>以及<strong>AspectJ</strong>的相关使用，我参考了以下文章以及代码，具体使用方式我就不再赘述：</p>
<ul>
<li><a href="http://www.jianshu.com/p/0fa8073fd144" target="_blank" rel="external">【翻译】Android中的AOP编程</a>  这一篇对AOP概念进行了介绍，并且通过AspectJ仿照<a href="https://github.com/JakeWharton/hugo" target="_blank" rel="external">Hugo</a>实现了一个AOP的Demo。</li>
<li>JakeWharton大神的<a href="https://github.com/JakeWharton/hugo" target="_blank" rel="external">hugo</a> 项目，通过AspectJ实现的日志工具。</li>
<li><a href="http://blog.csdn.net/crazy__chen/article/details/52014672" target="_blank" rel="external">使用AspectJ在Android中实现Aop</a>这一篇文章是对上面的文章和hugo项目的总结。</li>
</ul>
<hr>
<p>下面是我的实现：</p>
<p>首先，定义注解：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="variable">@Retention</span>(RetentionPolicy.RUNTIME)</div><div class="line"><span class="variable">@Target</span>(&#123;ElementType.TYPE&#125;)</div><div class="line">public <span class="variable">@interface</span> SchemeCheck &#123;</div><div class="line">    Condition<span class="selector-attr">[]</span> <span class="selector-tag">conditions</span>();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>值得提醒的是，这里<code>@Retention</code>要定义为<code>RetentionPolicy.RUNTIME</code>，因为我们要在运行时检查注解的参数，来判断scheme的触发条件。如果你写成了<code>RetentionPolicy.CLASS</code>或者<code>RetentionPolicy.SOURCE</code>就检查不到了。</p>
<p><code>Condition</code>是我们定义的需要判断的条件枚举：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">public <span class="class"><span class="keyword">enum</span> <span class="title">Condition</span> &#123;</span></div><div class="line">    NULL(null),</div><div class="line">    LOGIN(new LoginCondition()),</div><div class="line">    DOWNLOAD_BOOK(new BookDownloadCondition()),</div><div class="line">    LOGIN_OR_DOWNLOAD_BOOK(new LoginOrBookDownloadCondition());</div><div class="line"></div><div class="line">    BaseCondition condition;</div><div class="line">    Condition(BaseCondition condition) &#123;</div><div class="line">        this.condition = condition;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public BaseCondition getCondition() &#123;</div><div class="line">        <span class="keyword">return</span> condition;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>Condition</code>可以通过<code>getCondition()</code>来获取到具体的继承自<code>BaseCondition</code>的Condition对象：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">BaseCondition</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">boolean</span> <span class="title">isSatisfied</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> String <span class="title">unSatisfiedInfo</span><span class="params">()</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>由于是Demo，我们的登录条件暂时写死，到时候换成你具体的业务逻辑即可：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LoginCondition</span> <span class="keyword">extends</span> <span class="title">BaseCondition</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> isLogin = <span class="keyword">false</span>;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSatisfied</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> isLogin;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">unSatisfiedInfo</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">return</span> <span class="string">"请先登录"</span>;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>有了这些，我们就可以写注入代码了：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Aspect</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SchemeCheckAspect</span> </span>&#123;</div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"within(@demo.com.aj.anno.SchemeCheck *)"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">withinAnnotatedClass</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(!synthetic * *(..)) &amp;&amp; withinAnnotatedClass()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">methodInsideAnnotatedType</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Pointcut</span>(<span class="string">"execution(@demo.com.aj.anno.SchemeCheck * *(..)) || methodInsideAnnotatedType()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">method</span><span class="params">()</span> </span>&#123;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Around</span>(<span class="string">"method()"</span>)</div><div class="line">    <span class="keyword">public</span> <span class="function">Object <span class="title">weaveJoinPoint</span><span class="params">(ProceedingJoinPoint joinPoint)</span> <span class="keyword">throws</span> Throwable </span>&#123;</div><div class="line">        Signature signature = joinPoint.getSignature();</div><div class="line">        String methodName = signature.getName();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (TextUtils.equals(methodName, <span class="string">"onCreate"</span>)) &#123;</div><div class="line">            SchemeCheck anno = (SchemeCheck) signature.getDeclaringType().getAnnotation(SchemeCheck.class);</div><div class="line">            <span class="keyword">if</span> (anno != <span class="keyword">null</span>) &#123;</div><div class="line">                Condition[] conditions = anno.conditions();</div><div class="line">                Object point = joinPoint.getThis();</div><div class="line">                <span class="keyword">if</span> (point != <span class="keyword">null</span> &amp;&amp; point <span class="keyword">instanceof</span> Activity) &#123;</div><div class="line">                    Activity activity = (Activity) point;</div><div class="line">                    handleScheme(activity, conditions);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="function"><span class="keyword">return</span> joinPoint.<span class="title">proceed</span><span class="params">()</span></span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 检查前置条件</div><div class="line">     *</div><div class="line">     * <span class="doctag">@return</span> 是否通过检查</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">checkCondition</span><span class="params">(Condition[] conditions)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (conditions != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="keyword">for</span> (Condition condition : conditions) &#123;</div><div class="line">                BaseCondition conditionObj = condition.getCondition();</div><div class="line">                <span class="keyword">if</span> (conditionObj != <span class="keyword">null</span></div><div class="line">                        &amp;&amp; !conditionObj.isSatisfied()) &#123;</div><div class="line">                    Toast.makeText(App.getContext(), conditionObj.unSatisfiedInfo(), Toast.LENGTH_SHORT).show();</div><div class="line">                    SchemeManager.Cache.save(condition);</div><div class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 通过验证</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">void</span> <span class="title">passSatisfy</span><span class="params">()</span> </span>&#123;</div><div class="line">        SchemeManager.Cache.clear();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 处理前置条件的检查结果</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> isPass 检查是否通过</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">void</span> <span class="title">handleCheck</span><span class="params">(Activity activity, <span class="keyword">boolean</span> isPass)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (isPass) &#123;</div><div class="line">            passSatisfy();</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            <span class="keyword">if</span> (activity != <span class="keyword">null</span>) &#123;</div><div class="line">                activity.finish();</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     *</div><div class="line">     * 处理scheme相关的事情</div><div class="line">     *</div><div class="line">     * <span class="doctag">@param</span> activity</div><div class="line">     * <span class="doctag">@param</span> conditions</div><div class="line">     * <span class="doctag">@return</span> 是否通过验证</div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">handleScheme</span><span class="params">(Activity activity, Condition[] conditions)</span> </span>&#123;</div><div class="line">        <span class="keyword">boolean</span> passCheck = <span class="keyword">true</span>;</div><div class="line">        <span class="keyword">if</span> (isStartByScheme(activity)) &#123;</div><div class="line">            passCheck = checkCondition(conditions);</div><div class="line">            handleCheck(activity, passCheck);</div><div class="line">        &#125; <span class="keyword">else</span> &#123;</div><div class="line">            passCheck = <span class="keyword">true</span>;</div><div class="line">            passSatisfy();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> passCheck;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * 检查是否是由scheme开启</div><div class="line">     *</div><div class="line">     * <span class="doctag">@return</span></div><div class="line">     */</div><div class="line">    <span class="keyword">private</span> <span class="function"><span class="keyword">boolean</span> <span class="title">isStartByScheme</span><span class="params">(Activity activity)</span> </span>&#123;</div><div class="line">        <span class="keyword">boolean</span> isScheme = <span class="keyword">false</span>;</div><div class="line">        <span class="keyword">if</span> (activity != <span class="keyword">null</span>) &#123;</div><div class="line">            Intent intent = activity.getIntent();</div><div class="line">            <span class="keyword">if</span> (intent != <span class="keyword">null</span>) &#123;</div><div class="line">                isScheme = intent.getBooleanExtra(KEY_IS_SCHEME, <span class="keyword">false</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> isScheme;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>可以看到，我们在<code>onCreate()</code>方法开始之前，我们注入了scheme的判断逻辑，当条件满足时，直接执行了后面的逻辑；当条件不满足时，将不满足的条件进行缓存，并且<code>finish()</code>当前Activity。当正常执行了scheme跳转之后，清空缓存。</p>
<p>其中<code>SchemeManager</code>的逻辑如下：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SchemeManager</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String KEY_IS_SCHEME = <span class="string">"isScheme"</span>;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Cache</span> </span>&#123;</div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> String next = <span class="string">""</span>;</div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> Condition unSatisfiedCondition;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">save</span><span class="params">(Condition condition)</span> </span>&#123;</div><div class="line">            unSatisfiedCondition = condition;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">clear</span><span class="params">()</span></span>&#123;</div><div class="line">            next = <span class="string">""</span>;</div><div class="line">            unSatisfiedCondition = <span class="keyword">null</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">reExecuteScheme</span><span class="params">(Activity activity, Condition condition)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (Cache.unSatisfiedCondition != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="comment">// 当缓存的条件与当前重复执行时触发的条件一致时，再次执行scheme</span></div><div class="line">            <span class="keyword">if</span> (Cache.unSatisfiedCondition == condition) &#123;</div><div class="line">                String scheme = Cache.next;</div><div class="line">                executeScheme(activity, scheme);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="function"><span class="keyword">void</span> <span class="title">executeScheme</span><span class="params">(Activity activity, String schemeStr)</span> </span>&#123;</div><div class="line">        Cache.next = schemeStr;</div><div class="line">        Class&lt;? <span class="keyword">extends</span> Activity&gt; <span class="keyword">target</span> = <span class="keyword">null</span>;</div><div class="line">        <span class="keyword">switch</span> (schemeStr) &#123;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startA"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityA.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startB"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityB.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startC"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityC.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            <span class="keyword">case</span> <span class="string">"startD"</span>:</div><div class="line">                <span class="keyword">target</span> = TargetActivityD.class;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (<span class="keyword">target</span> != <span class="keyword">null</span>) &#123;</div><div class="line">            <span class="comment">// 如果当前页和目标页面是同一个页面  则清空缓存  防止递归调用产生死循环</span></div><div class="line">            <span class="keyword">if</span> (<span class="keyword">target</span>.equals(activity.getClass())) &#123;</div><div class="line">                Cache.clear();</div><div class="line">                <span class="keyword">return</span>;</div><div class="line">            &#125;</div><div class="line">            Intent intent = <span class="keyword">new</span> Intent(activity, <span class="keyword">target</span>);</div><div class="line">            intent.putExtra(KEY_IS_SCHEME, <span class="keyword">true</span>);</div><div class="line">            activity.startActivity(intent);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>这里包含有缓存管理的逻辑，以及<strong>执行scheme</strong>和<strong>重复执行scheme</strong>的逻辑。</p>
<p>其中，由于是Demo，执行scheme的逻辑用固定的字符串来代表scheme链接，这里需要你来替换为你自己的业务逻辑，因为你可能有解析scheme参数并且传递到目标Activity的逻辑。</p>
<p>scheme缓存保存了scheme链接和最后一次没有通过的条件枚举值，当下一次条件被触发时，通过<code>reExecuteScheme</code>来执行缓存中的scheme，达到继续跳转的效果。</p>
<p>例如，在登录成功的地方，可以执行:</p>
<figure class="highlight kotlin"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">reExecuteScheme(<span class="keyword">this</span>, Condition.LOGIN);</div></pre></td></tr></table></figure>
<p>来达到登录成功时继续触发<strong>因未登录导致的scheme跳转失败的scheme跳转</strong>（好绕啊…）。</p>
<h2 id="愉快的调用">愉快的调用</h2><p>接下来我们在需要加入scheme跳转判断的Activity的类上加入注解判断即可，例如我们在下面的Activity上加入<strong>登录</strong>以及<strong>词书下载</strong>的条件判断：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="variable">@SchemeCheck</span>(conditions = &#123;Condition.LOGIN, Condition.DOWNLOAD_BOOK&#125;)</div><div class="line">public class TargetActivityC extends Activity &#123;</div><div class="line"></div><div class="line">    <span class="selector-tag">public</span> <span class="selector-tag">static</span> <span class="selector-tag">void</span> <span class="selector-tag">start</span>(Activity activity) &#123;</div><div class="line">        activity<span class="selector-class">.startActivity</span>(new Intent(activity, TargetActivityC.class));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="variable">@Override</span></div><div class="line">    protected void onCreate(Bundle savedInstanceState) &#123;</div><div class="line">        super<span class="selector-class">.onCreate</span>(savedInstanceState);</div><div class="line">        setContentView(R<span class="selector-class">.layout</span><span class="selector-class">.activity_c</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>是不是很简单呢？</p>
<h2 id="注意！这里有坑">注意！这里有坑</h2><p>目前发现的一个坑就是我们的加入scheme跳转判断的子类Activity中必须有<code>onCreate</code>方法才可以正常执行，因为<code>AspectJ</code>只能判断当前子类中所触发的子类的方法。也就是说如果即使你对Activity的基类的<code>onCreate</code>进行了一层封装，完成了<code>onCreate</code>的所有工作，子类也需要复写一下<code>onCreate</code>。就像这样：</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line">   <span class="keyword">protected</span> <span class="function"><span class="keyword">void</span> <span class="title">onCreate</span><span class="params">(Bundle savedInstanceState)</span> </span>&#123;</div><div class="line">       <span class="keyword">super</span>.onCreate(savedInstanceState);</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
<p>否则会crash。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/" itemprop="url">
                【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-09T00:07:58+08:00" content="2017-03-09">
            2017-03-09
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/09/【Tensorflow r1.0 文档翻译】使用tf.contrib.learn记录和监视的基本知识/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>在训练模型时，实时跟踪和评估进度通常很有价值。在本教程中，您将学习如何使用TensorFlow的日志记录功能和<code>Monitor</code> API来审计用于分类鸢尾花的神经网络分类器的正在进行中的训练。本教程基于在<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>中开发的代码，所以如果你还没有完成该教程，你可能想先探索它， 特别是如果你正在寻找一个tf.contrib.learn基础介绍/复习文章时。</p>
<h2 id="创建">创建</h2><p>在本教程中，你将在从<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>中的下面的代码来进行构建：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">from __future__ <span class="built_in">import</span> absolute_import</div><div class="line">from __future__ <span class="built_in">import</span> division</div><div class="line">from __future__ <span class="built_in">import</span> print_function</div><div class="line"></div><div class="line"><span class="built_in">import</span> os</div><div class="line"></div><div class="line"><span class="built_in">import</span> numpy as np</div><div class="line"><span class="built_in">import</span> tensorflow as tf</div><div class="line"></div><div class="line"><span class="comment"># Data sets</span></div><div class="line"><span class="attr">IRIS_TRAINING</span> = os.path.join(os.path.dirname(__file__), <span class="string">"iris_training.csv"</span>)</div><div class="line"><span class="attr">IRIS_TEST</span> = os.path.join(os.path.dirname(__file__), <span class="string">"iris_test.csv"</span>)</div><div class="line"></div><div class="line">def main(unused_argv):</div><div class="line">    <span class="comment"># Load datasets.</span></div><div class="line">    <span class="attr">training_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">        <span class="attr">filename=IRIS_TRAINING,</span> <span class="attr">target_dtype=np.int,</span> <span class="attr">features_dtype=np.float32)</span></div><div class="line">    <span class="attr">test_set</span> = tf.contrib.learn.datasets.base.load_csv_with_header(</div><div class="line">        <span class="attr">filename=IRIS_TEST,</span> <span class="attr">target_dtype=np.int,</span> <span class="attr">features_dtype=np.float32)</span></div><div class="line"></div><div class="line">    <span class="comment"># Specify that all features have real-value data</span></div><div class="line">    <span class="attr">feature_columns</span> = [tf.contrib.layers.real_valued_column(<span class="string">""</span>, <span class="attr">dimension=4)]</span></div><div class="line"></div><div class="line">    <span class="comment"># Build 3 layer DNN with 10, 20, 10 units respectively.</span></div><div class="line">    <span class="attr">classifier</span> = tf.contrib.learn.DNNClassifier(<span class="attr">feature_columns=feature_columns,</span></div><div class="line">                                                <span class="attr">hidden_units=[10,</span> <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">                                                <span class="attr">n_classes=3,</span></div><div class="line">                                                <span class="attr">model_dir="/tmp/iris_model")</span></div><div class="line"></div><div class="line">    <span class="comment"># Fit model.</span></div><div class="line">    classifier.fit(<span class="attr">x=training_set.data,</span></div><div class="line">                   <span class="attr">y=training_set.target,</span></div><div class="line">                   <span class="attr">steps=2000)</span></div><div class="line"></div><div class="line">    <span class="comment"># Evaluate accuracy.</span></div><div class="line">    <span class="attr">accuracy_score</span> = classifier.evaluate(<span class="attr">x=test_set.data,</span></div><div class="line">                                         <span class="attr">y=test_set.target)["accuracy"]</span></div><div class="line">    print('Accuracy: &#123;<span class="number">0</span>:f&#125;'.format(accuracy_score))</div><div class="line"></div><div class="line">    <span class="comment"># Classify two new flower samples.</span></div><div class="line">    <span class="attr">new_samples</span> = np.array(</div><div class="line">        [[<span class="number">6.4</span>, <span class="number">3.2</span>, <span class="number">4.5</span>, <span class="number">1.5</span>], [<span class="number">5.8</span>, <span class="number">3.1</span>, <span class="number">5.0</span>, <span class="number">1.7</span>]], <span class="attr">dtype=float)</span></div><div class="line">    <span class="attr">y</span> = list(classifier.predict(new_samples, <span class="attr">as_iterable=True))</span></div><div class="line">    print('Predictions: &#123;&#125;'.format(str(y)))</div><div class="line"></div><div class="line"><span class="keyword">if</span> <span class="attr">__name__</span> == <span class="string">"__main__"</span>:</div><div class="line">  tf.app.run()</div></pre></td></tr></table></figure>
<p>将上述代码复制到一个文件中，并将相应的<a href="http://download.tensorflow.org/data/iris_training.csv" target="_blank" rel="external">训练</a>和<a href="https://www.tensorflow.org/api_docs/python/tf/test" target="_blank" rel="external">tf.test</a>数据集下载到同一目录。</p>
<p>在以下部分中，您将逐步更新上述代码以添加日志记录和监视功能。包含所有更新的最终代码可在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/monitors/iris_monitors.py" target="_blank" rel="external">此处</a>下载。</p>
<h2 id="概述">概述</h2><p><a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门</a>教程中通过如何实现一个神经网络分类器实现了将鸢尾花的样本分为三种类型之一。</p>
<p>但是，当运行本教程的<a href="https://www.tensorflow.org/get_started/monitors#setup" target="_blank" rel="external">代码</a>时，输​​出并不包含日志记录跟踪模型训练如何进行 - 仅包含打印语句的结果：</p>
<figure class="highlight avrasm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="symbol">Accuracy:</span> <span class="number">0.933333</span></div><div class="line"><span class="symbol">Predictions:</span> [<span class="number">1</span> <span class="number">2</span>]</div></pre></td></tr></table></figure>
<p>没有任何日志记录，模型训练感觉就像一个黑盒子;你不能看到发生了什么，因此TensorFlow通过逐步的梯度下降，了解模型是否适当的收敛、或者确定是否可以提前停止训练是有必要的。</p>
<p>解决这个问题的一种方法是将模型训练分成具有较少步骤的多个<code>fit</code>(拟合)调用，以便逐步评估准确性。然而，这不是推荐的做法，因为它大大减慢了模型的训练过程。幸运的是，tf.contrib.learn提供了另一个解决方案：一个<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/monitors" target="_blank" rel="external">Monitor API</a>，旨在帮助您在训练正在进行时记录指标并评估模型。在以下部分中，您将学习如何在TensorFlow中启用日志记录，设置ValidationMonitor进行流评估，以及使用TensorBoard可视化您的度量。</p>
<h2 id="启用TensorFlow的日志记录">启用TensorFlow的日志记录</h2><p>TensorFlow对日志消息使用五个不同的级别。按照严重性递增的顺序，它们是<code>DEBUG</code>，<code>INFO</code>，<code>WARN</code>，<code>ERROR</code>和<code>FATAL</code>。当您在配置任何这些级别的日志记录时，TensorFlow将输出与该级别以及所有严重性级别高于该级别的相对应的所有日志消息。例如，如果您设置为<code>ERROR</code>的日志级别，您将获得包含<code>ERROR</code>和<code>FATAL</code>消息的日志输出，如果设置为<code>DEBUG</code>级别，则将获取所有五个级别的日志消息。</p>
<p>默认情况下，TensorFlow的日志级别为<code>WARN</code>，但是在跟踪模型训练时，您需要将级别调整为<code>INFO</code>，这将在适配操作正在进行时提供其他反馈。</p>
<p>将以下行添加到代码的开头（在<code>import</code>之后）：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf<span class="selector-class">.logging</span><span class="selector-class">.set_verbosity</span>(tf<span class="selector-class">.logging</span><span class="selector-class">.INFO</span>)</div></pre></td></tr></table></figure>
<p>现在当你运行代码，你会看到额外的日志输出，如下所示：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">1.18812</span>, step = <span class="number">1</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">0.210323</span>, step = <span class="number">101</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>loss = <span class="number">0.109025</span>, step = <span class="number">201</span></div></pre></td></tr></table></figure>
<p>使用<code>INFO</code>级别日志记录，tf.contrib.learn每100步后自动向标准错误（stderr）输出<a href="https://en.wikipedia.org/wiki/Loss_function" target="_blank" rel="external">训练损失指标</a>。</p>
<h2 id="为流式处理评估配置验证监视器">为流式处理评估配置验证监视器</h2><p>记录训练损失有助于了解您的模型是否收敛，但如果您想进一步了解训练期间发生的情况怎么办？tf.contrib.learn提供了几个高级监视器，您可以附加到您的合适的操作中，以进一步在模型训练期间跟踪指标和/或调试较低级别的TensorFlow操作，包括：</p>
<table>
<thead>
<tr>
<th style="text-align:left">Monitor</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>CaptureVariable</code></td>
<td style="text-align:left">在训练的每n个步骤中将指定变量的值保存到集合中</td>
</tr>
<tr>
<td style="text-align:left"><code>PrintTensor</code></td>
<td style="text-align:left">在训练的每n个步骤记录指定的tensor的值</td>
</tr>
<tr>
<td style="text-align:left"><code>SummarySaver</code></td>
<td style="text-align:left">在每n个训练步骤使用<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>保存给定tensor的<a href="https://www.tensorflow.org/api_docs/python/tf/Summary" target="_blank" rel="external"><code>tf.Summary</code></a><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="external">protocol buffers</a></td>
</tr>
<tr>
<td style="text-align:left"><code>ValidationMonitor</code></td>
<td style="text-align:left">在训练的每n个步骤记录指定的一组评估度量，并且如果需要，可以在某些条件下实现提前停止训练</td>
</tr>
</tbody>
</table>
<h3 id="评估每N个步骤">评估每N个步骤</h3><p>对于鸢尾花神经网络分类器，在记录训练损失时，您可能还需要同时评估测试数据，以了解模型的泛化程度。您可以通过使用测试数据（<code>test_set.data</code>和<code>test_set.target</code>）配置一个<code>ValidationMonitor</code>并设置使用<code>every_n_steps</code>进行求值的频率来实现此目的。<code>every_n_steps</code>的默认值为<code>100</code>;这里，设置<code>every_n_steps</code>为<code>50</code>，以评估后每50步的模型训练：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>)</div></pre></td></tr></table></figure>
<p>将此代码放置在实例化<code>classifier</code>的行之前。</p>
<p><code>ValidationMonitor</code>依赖于保存的检查点来执行评估操作，因此您需要通过修改分类器的实例化，来添加包含<code>save_checkpoints_secs</code>的来指定在训练运行期间每个checkpoint之间消耗了多少秒的<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/RunConfig" target="_blank" rel="external"><code>tf.contrib.learn.RunConfig</code></a>。由于鸢尾花数据集非常小，因此可以快速进行训练，将<code>save_checkpoints_secs</code>设置为1（每秒保存一个检查点）以确保有足够数量的检查点：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">classifier = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.DNNClassifier</span>(</div><div class="line">    feature_columns=feature_columns,</div><div class="line">    hidden_units=[<span class="number">10</span>, <span class="number">20</span>, <span class="number">10</span>],</div><div class="line">    n_classes=<span class="number">3</span>,</div><div class="line">    model_dir=<span class="string">"/tmp/iris_model"</span>,</div><div class="line">    config=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.RunConfig</span>(save_checkpoints_secs=<span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>注意：<code>model_dir</code>参数为要存储的模型数据指定显式目录（<code>/tmp/iris_model</code>）;此目录路径将比后面自动生成的路径更容易引用。每次运行代码时，在<code>/tmp/iris_model</code>目录下的任何的数据都会被加载，并且模型训练将会在上次停止的位置继续进行（例如，连续运行两次2000步<code>fit</code>操作的脚本将在训练期间执行4000步操作）。如果想要从头开始模型训练，那么需要在执行训练前删除<code>/tmp/iris_model</code>目录。</p>
<p>最后，为了附加您的<code>validation_monitor</code>，更新<code>fit</code>调用，来包含一个包含在模型训练期间运行的所有监视器的列表的监视器参数：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">x=training_set.data,</span></div><div class="line">               <span class="attr">y=training_set.target,</span></div><div class="line">               <span class="attr">steps=2000,</span></div><div class="line">               <span class="attr">monitors=[validation_monitor])</span></div></pre></td></tr></table></figure>
<p>现在，当您重新运行代码时，您应该会在日志输出中看到验证指标，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">INFO:tensorflow:Validation (step <span class="number">50</span>): <span class="attr">loss</span> = <span class="number">1.71139</span>, <span class="attr">global_step</span> = <span class="number">0</span>, <span class="attr">accuracy</span> = <span class="number">0.266667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">300</span>): <span class="attr">loss</span> = <span class="number">0.0714158</span>, <span class="attr">global_step</span> = <span class="number">268</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1750</span>): <span class="attr">loss</span> = <span class="number">0.0574449</span>, <span class="attr">global_step</span> = <span class="number">1729</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div></pre></td></tr></table></figure>
<h3 id="使用MetricSpec自定义评估指标">使用MetricSpec自定义评估指标</h3><p>默认情况下，如果未指定评估指标，<code>ValidationMonitor</code>将同时记录loss和accuracy精确度，但您可以自定义将每隔50个步骤运行的指标列表。要指定要在每个评估传递中运行的确切指标，您可以向<code>ValidationMonitor</code>构造函数添加一个<code>metrics</code>参数。<code>metrics</code>接受一个key/value的字典，其中字典的每个键是您要为该指标记录的名称，对应的值是<a href="https://www.tensorflow.org/code/tensorflow/contrib/learn/python/learn/metric_spec.py" target="_blank" rel="external"><code>MetricSpec</code></a>对象。</p>
<p><code>MetricSpec</code>构造函数接受四个参数：</p>
<ul>
<li><p><code>metric_fn</code> 计算和返回指标值的函数。这可以是<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics" target="_blank" rel="external">tf.contrib.metrics</a>模块中可用的预定义函数，例如<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_precision" target="_blank" rel="external">tf.contrib.metrics.streaming_precision</a>或<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_recall" target="_blank" rel="external">tf.contrib.metrics.streaming_recall</a>。或者，您可以定义自己的自定义指标函数，必须将<code>predictions</code>和<code>labels</code>tensor作为参数(还可以可选地提供<code>weights</code>参数)。函数必须以以下两种格式之一返回度量的值：</p>
<ul>
<li>单个的tensor </li>
<li>一对操作(<code>value_op</code>, <code>update_op</code>)，其中<code>value_op</code>返回度量值，<code>update_op</code>执行相应的操作以更新内部模型状态。</li>
</ul>
</li>
<li><p><code>prediction_key</code> 包含模型返回的预测的tensor的key。如果模型返回单个tensor或带有单个条目的字典，则可以省略此参数。对于<code>DNNClassifier</code>模型，类别预测将在带有关键字<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/learn/PredictionKey#CLASSES" target="_blank" rel="external"><code>tf.contrib.learn.PredictionKey.CLASSES</code></a>的tensor中返回。</p>
</li>
<li><code>label_key</code> tensor的键包含模型返回的标签，由模型的<a href="https://www.tensorflow.org/get_started/input_fn" target="_blank" rel="external"><code>input_fn</code></a>指定。与<code>prediction_key</code>一样，如果<code>input_fn</code>返回单个tensor或具有单个条目的字典，则可以省略此参数。在本教程的鸢尾花样本中，<code>DNNClassifier</code>没有<code>input_fn</code>（<code>x</code>，<code>y</code>数据直接传递给<code>fit</code>），因此没有必要提供<code>label_key</code>。</li>
<li><code>weights_key</code> 可选参数。tensor的键（由<a href="https://www.tensorflow.org/get_started/input_fn" target="_blank" rel="external"><code>input_fn</code></a>返回），包含<code>metric_fn</code>的权重输入。</li>
</ul>
<p>以下代码创建了一个<code>validation_metrics</code>字典，它定义了在模型评估期间要记录的三个指标：</p>
<ul>
<li><code>&quot;accuracy&quot;(准确性)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_accuracy" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_accuracy</code></a>作为<code>metric_fn</code>。</li>
<li><code>&quot;precision&quot;(精确)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_precision" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_precision</code></a>作为<code>metric_fn</code>。</li>
<li><code>&quot;recall&quot;(召回)</code>,使用<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/metrics/streaming_recall" target="_blank" rel="external"><code>tf.contrib.metrics.streaming_recall</code></a>作为<code>metric_fn</code>。</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">validation_metrics = &#123;</div><div class="line">    <span class="string">"accuracy"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_accuracy</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES),</div><div class="line">    <span class="string">"precision"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_precision</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES),</div><div class="line">    <span class="string">"recall"</span>:</div><div class="line">        tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.metric_spec</span><span class="selector-class">.MetricSpec</span>(</div><div class="line">            metric_fn=tf<span class="selector-class">.contrib</span><span class="selector-class">.metrics</span><span class="selector-class">.streaming_recall</span>,</div><div class="line">            prediction_key=tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.prediction_key</span><span class="selector-class">.PredictionKey</span>.</div><div class="line">            CLASSES)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在<code>ValidationMonitor</code>构造函数之前添加上面的代码。然后按如下所示修改<code>ValidationMonitor</code>构造函数，以添加度量参数以记录<code>validation_metrics</code>中指定的accuracy，precision和recall指标（loss是始终被记录的，不需要显示的设定）：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>,</div><div class="line">    metrics=validation_metrics)</div></pre></td></tr></table></figure>
<p>重新运行代码，您应该会在日志输出中看到precision和recall，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">INFO:tensorflow:Validation (step <span class="number">50</span>): <span class="attr">recall</span> = <span class="number">0.0</span>, <span class="attr">loss</span> = <span class="number">1.20626</span>, <span class="attr">global_step</span> = <span class="number">1</span>, <span class="attr">precision</span> = <span class="number">0.0</span>, <span class="attr">accuracy</span> = <span class="number">0.266667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">600</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.0530696</span>, <span class="attr">global_step</span> = <span class="number">571</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1500</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.0617403</span>, <span class="attr">global_step</span> = <span class="number">1452</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div></pre></td></tr></table></figure>
<h3 id="通过ValidationMonitor来提前停止">通过ValidationMonitor来提前停止</h3><p>注意，在上述日志输出中，通过600步训练，模型已经实现了1.0的精确度和召回率。这体现出了一个问题，即模型训练是否可以从<a href="https://en.wikipedia.org/wiki/Early_stopping" target="_blank" rel="external">提前停止</a>中受益。</p>
<p>除了记录eval指标外，<code>ValidationMonitor</code>还可以通过三个参数轻松实现提前停止：</p>
<table>
<thead>
<tr>
<th style="text-align:left">参数</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>early_stopping_metric</code></td>
<td style="text-align:left">在<code>early_stopping_rounds</code>和<code>early_stopping_metric_minimize</code>中指定的条件下触发提前停止的指标（例如，loss或accuracy）。默认为“loss”。</td>
</tr>
<tr>
<td style="text-align:left"><code>early_stopping_metric_minimize</code></td>
<td style="text-align:left">如果期望的模型行为是最小化<code>early_stopping_metric</code>的值，则为<code>True</code>;如果期望的模型行为是最大化<code>early_stopping_metric</code>的值，则为<code>False</code>。默认值是<code>True</code></td>
</tr>
<tr>
<td style="text-align:left"><code>early_stopping_rounds</code></td>
<td style="text-align:left">设置如果<code>early_stopping_metric</code>不减小（如果<code>early_stopping_metric_minimize</code>为<code>True</code>）或增加（如果<code>early_stopping_metric_minimize</code>为<code>False</code>）的步骤数，训练将会停止。默认值为<code>None</code>，这意味着永远不会发生提前停止。</td>
</tr>
</tbody>
</table>
<p>对<code>ValidationMonitor</code>的构造函数进行以下修改，其指定如果在200个步骤（<code>early_stopping_rounds = 200</code>）的时段内loss（<code>early_stopping_metric =“loss”</code>）不减小（<code>early_stopping_metric_minimize = True</code>），模型训练将在该点立即停止，并且不会完成<code>fit</code>中指定的2000步训练：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">validation_monitor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.monitors</span><span class="selector-class">.ValidationMonitor</span>(</div><div class="line">    test_set<span class="selector-class">.data</span>,</div><div class="line">    test_set<span class="selector-class">.target</span>,</div><div class="line">    every_n_steps=<span class="number">50</span>,</div><div class="line">    metrics=validation_metrics,</div><div class="line">    early_stopping_metric=<span class="string">"loss"</span>,</div><div class="line">    early_stopping_metric_minimize=True,</div><div class="line">    early_stopping_rounds=<span class="number">200</span>)</div></pre></td></tr></table></figure>
<p>重新运行代码以查看模型训练是否提前停止：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">INFO:tensorflow:Validation (step <span class="number">1150</span>): <span class="attr">recall</span> = <span class="number">1.0</span>, <span class="attr">loss</span> = <span class="number">0.056436</span>, <span class="attr">global_step</span> = <span class="number">1119</span>, <span class="attr">precision</span> = <span class="number">1.0</span>, <span class="attr">accuracy</span> = <span class="number">0.966667</span></div><div class="line">INFO:tensorflow:Stopping. Best step: <span class="number">800</span> <span class="keyword">with</span> <span class="attr">loss</span> = <span class="number">0.048313818872</span>.</div></pre></td></tr></table></figure>
<p>实际上，这里的训练在第1150步时停止，这说明对于过去的200步，损失没有减少，并且总体上，第800步针对测试数据集产生最小损失值。这表明通过减少步数来额外校准超参数可以进一步改善模型。</p>
<h2 id="使用TensorBoard可视化日志数据">使用TensorBoard可视化日志数据</h2><p>通过<code>ValidationMonitor</code>生成的日志读取提供了大量关于模型在训练期间的性能的原始数据，这也对数据可视化以进一步了解趋势是有帮助的 - 例如，精确度是如何随着步数变化而变化的。您可以使用TensorBoard（与TensorFlow一起打包的单独程序）通过将<code>logdir</code>命令行参数设置为保存模型训练数据的目录（此处为<code>/tmp/iris_model</code>）来绘制这样的图。在命令行上运行以下命令：</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ tensorboard <span class="comment">--logdir=/tmp/iris_model/</span></div><div class="line">Starting TensorBoard <span class="number">39</span> <span class="keyword">on</span> port <span class="number">6006</span></div></pre></td></tr></table></figure>
<p>然后在你的浏览器中打开<code>http://0.0.0.0:&lt;port_number&gt;</code>，<code>&lt;port_number&gt;</code>是在命令行输出中指定的端口（此处为<code>6006</code>）。</p>
<p>如果单击accuracy(准确度)字段，您将看到类似以下的图像，其中显示了针对步数的精确度：</p>
<p><img src="/img/17_03_07/031.png" alt=""></p>
<p>有关使用TensorBoard的更多信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard:可视化学习</a>和<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-图的可视化/">TensorBoard:图的可视化</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:图的可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T22:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-图的可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>TensorFlow计算图是强大而复杂的。图形可视化可以帮助您理解和调试它们。这里有一个可视化工作的例子。</p>
<p><img src="/img/17_03_07/007.gif" alt=""></p>
<p><em>TensorFlow图的可视化。</em></p>
<p>如有想查看你的图，你需要运行TensorBoard并将其指向你的作业的日志目录，单击顶部窗格上的图形选项卡，然后使用左上角的菜单选择适当的运行。有关如何运行TensorBoard并确保您记录所有必要信息的深入信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard：可视化学习</a>。</p>
<h2 id="名称作用域和节点">名称作用域和节点</h2><p>典型的TensorFlow图可以有成千上万的节点 - 这个展示量太大了，以至于即使使用标准图工具来布局也太大了。为了简化显示，我们通过变量名指定其对应的作用域，通过使用这些信息来定义图中节点图层的可视化。默认情况下，只显示此层次结构的顶部部分。下面是一个使用<a href="https://www.tensorflow.org/api_docs/python/tf/name_scope" target="_blank" rel="external"><code>tf.name_scope</code></a>在隐藏名称范围下定义三个操作的示例：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">import tensorflow <span class="keyword">as</span> <span class="keyword">tf</span></div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'hidden'</span>) <span class="keyword">as</span> scope:</div><div class="line">  <span class="keyword">a</span> = <span class="keyword">tf</span>.constant(<span class="number">5</span>, name=<span class="string">'alpha'</span>)</div><div class="line">  W = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.random_uniform([<span class="number">1</span>, <span class="number">2</span>], -<span class="number">1.0</span>, <span class="number">1.0</span>), name=<span class="string">'weights'</span>)</div><div class="line">  <span class="keyword">b</span> = <span class="keyword">tf</span>.Variable(<span class="keyword">tf</span>.zeros([<span class="number">1</span>]), name=<span class="string">'biases'</span>)</div></pre></td></tr></table></figure>
<p>这将产生以下三个操作名称：</p>
<ul>
<li><code>hidden/alpha</code></li>
<li><code>hidden/weights</code></li>
<li><code>hidden/biases</code></li>
</ul>
<p>默认情况下，可视化将这三个操作压缩到标记为<code>hidden</code>的节点中。额外的细节不会丢失。您可以双击或单击右上角的橙色<code>+</code>号来展开节点，然后您将看到三个子节点的<code>alpha</code>，<code>weights</code>和<code>biases</code>。</p>
<p>这是一个在初始化和展开状态更复杂的真实例子：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/008.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/009.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">顶层名称作用域<strong>pool_1</strong>的初始化视图。单击右上角的橙色<code>+</code>按钮或双击节点本身将会展开它。</td>
<td style="text-align:left"><strong>pool_1</strong>名称作用域的展开视图。单击右上角的橙色按钮或双击节点本身将折叠名称作用域。</td>
</tr>
</tbody>
</table>
<p>按名称范围对节点分组对于创建清晰的图表至关重要。如果您正在构建模型，名称作用域可以控制生成的可视化。<strong>你的名字的作用域越好，可视化效果越好。</strong></p>
<p>上图说明了可视化的第二个方面。TensorFlow图有两种连接：数据依赖和控制依赖。数据依赖显示了两个操作之间的tensor流，并且示为实箭头，而控制依赖使用虚线。在扩展视图（上图右侧）中，所有连接都是数据依赖关系，但连接<code>CheckNumerics</code>和<code>control_dependency</code>的虚线除外。</p>
<p>还有第二种简化布局的小技巧。大多数TensorFlow图都存在几个与其他节点有很多连接的节点。例如，许多节点可能对初始化步骤具有控制依赖性。绘制<code>init</code>节点以及其依赖项之间的所有边将创建一个非常混乱的视图。</p>
<p>为了减少杂乱程度，可视化将所有高度节点分离到右侧的辅助区域，并且不绘制代表它们边缘的线。相对于用线来表示边缘来讲，这里我们绘制小节点图标以指示连接关系。分离出辅助节点通常不会移除关键信息，因为这些节点通常与记录方法相关。有关如何在主图和辅助区域之间移动节点，请参阅<a href="#交互">交互</a>部分。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/010.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/011.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点<strong>conv_1</strong>已被连接到<strong>save</strong>。注意它右边的小<strong>save</strong>节点图标。</td>
<td style="text-align:left"><strong>save</strong>有高度，并且将作为辅助节点出现。与<strong>conv_1</strong>的连接在其左侧显示为节点图标。为了进一步减少杂乱程度，由于<strong>save</strong>有很多连接，我们显示到第5个，其他缩写为<strong>… 12 more</strong>。</td>
</tr>
</tbody>
</table>
<p>最后一个结构简化是series collapsing(系列折叠)。有顺序的图案 - 也就是说，其名称与末尾的数字不同并且具有相同构结构的节点被折叠为单个节点堆叠，如下所示。对于具有长序列的网络，这极大地简化了视图的显示。与分层节点一样，双击也可以展开。有关如何为特定节点集禁用/启用系列折叠，请参阅<a href="#交互">交互</a>。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/012.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/013.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">节点序列的折叠视图。</td>
<td style="text-align:left">双击后的一个小块的展开视图。</td>
</tr>
</tbody>
</table>
<p>最后，作为可读性的最后一个辅助部分，可视化对常量和摘要节点使用一些特定的图标来。下面是一个节点符号对照表：</p>
<table>
<thead>
<tr>
<th style="text-align:left">符号</th>
<th style="text-align:left">含义</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/014.png" alt=""></td>
<td style="text-align:left">高级节点，代表名称作用域。双击展开高级节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/015.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们彼此没有连接</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/016.png" alt=""></td>
<td style="text-align:left">编号节点序列，它们是彼此连接的</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/017.png" alt=""></td>
<td style="text-align:left">单个操作节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/018.png" alt=""></td>
<td style="text-align:left">常数</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/019.png" alt=""></td>
<td style="text-align:left">摘要节点。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/020.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的数据流。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/021.png" alt=""></td>
<td style="text-align:left">边缘显示操作之间的控制依赖性。</td>
</tr>
<tr>
<td style="text-align:left"><img src="/img/17_03_07/022.png" alt=""></td>
<td style="text-align:left">表示输出操作节点可以变为输入张量的参考边。</td>
</tr>
</tbody>
</table>
<h2 id="交互">交互</h2><p>通过平移和缩放导航图。点击并拖动即可平移，并使用滚动手势进行缩放。双击一个节点，或单击其<code>+</code>按钮，可以展开一个表示一组操作的名称作用域。为了在缩放和平移时轻松跟踪当前视点，右下角有一个小地图。</p>
<p>要关闭打开的节点，请再次双击它，或单击它的 <code>-</code> 按钮。您也可以单击来选择某个节点。它将变成更暗的颜色，并且它的详细信息和它连接的节点将出现在可视化界面的右上角的信息卡中。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/023.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/024.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">显示<strong>conv2</strong>名称作用域的详细信息的信息卡。输入和输出从名称作用域内的操作节点的输入和输出组合。对于名称作用域，不显示属性。</td>
<td style="text-align:left">显示<code>DecodeRaw</code>操作节点的详细信息的信息卡。除了输入和输出之外，它还显示了设备和与当前操作相关的属性。</td>
</tr>
</tbody>
</table>
<p>TensorBoard提供了几种方法来更改图形的视觉布局。这些方法不改变图的计算语义，但它可以为网络的结构带来一些清晰度。通过右键单击节点或按下该节点信息卡底部的按钮，可以对其布局进行以下更改：</p>
<ul>
<li>节点可以在主图和辅助区域之间移动。</li>
<li>一系列节点可以取消分组，以便系列中的节点不会显示在一起。未分组的系列同样可以重新分组。</li>
</ul>
<p>选择也有助于理解高度节点。选择任何高级节点，并选择其他连接的相应节点图标。这使得某些操作变得很容易，例如，看到哪些节点被保存，哪些没有被保存。</p>
<p>单击信息卡中的节点名称将选择它。如果需要，视点将自动平移，以便节点可见。</p>
<p>最后，您可以使用图例上方的颜色菜单为图形选择两种颜色方案。默认结构视图显示结构：当两个高级节点具有相同的结构时，它们以彩虹的相同颜色显示。唯一结构化的节点是灰色的。还有一个显示了运行不同操作的设备第二个视图。名称作用域的颜色与其内部操作的设备分数成比例。</p>
<p>下面的图片给出了一幅实际场景中的插图。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/025.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/026.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">结构视图：灰色节点具有独特的结构。橙色<strong>conv1</strong>和<strong>conv2</strong>节点具有相同的结构，并且类似地用于具有其它颜色的节点。</td>
<td style="text-align:left">设备视图：名称范围与其中的操作节点的设备分数成比例地着色。这里，紫色表示GPU，绿色表示CPU。</td>
</tr>
</tbody>
</table>
<h2 id="Tensor形状信息">Tensor形状信息</h2><p>当序列化<code>GraphDef</code>引入tensor形状时，图形可视化器标记具有tensor维度的边缘，并且边缘厚度反映总张量大小。在<code>GraphDef</code>中引入tensor形状，将序列化图形时的实际图形对象（如<code>sess.graph</code>中所示）传递给<code>SummaryWriter</code>。下图显示了带有张量形状信息的CIFAR-10模型：</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/027.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CIFAR-10模型与张量形状信息。</td>
</tr>
</tbody>
</table>
<h2 id="运行时统计">运行时统计</h2><p>通常，收集运行的运行时元数据是有用的，例如节点的总内存使用，总计算时间和tensor形状。下面的代码示例是来自<a href="/2017/02/22/【Tensorflow%20r1.0%20文档翻译】机器学习的HelloWorld%20--%20MNIST手写数字识别/">简单MNIST教程</a>中的经过修改的训练和测试部分的代码片段，其中我们记录了摘要和运行时统计信息。有关如何记录摘要的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">摘要教程</a>。全部源代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">99</span>:  <span class="comment"># Record execution stats</span></div><div class="line">      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)</div><div class="line">      run_metadata = tf.RunMetadata()</div><div class="line">      summary, _ = sess.run([merged, train_step],</div><div class="line">                            feed_dict=feed_dict(<span class="keyword">True</span>),</div><div class="line">                            options=run_options,</div><div class="line">                            run_metadata=run_metadata)</div><div class="line">      train_writer.add_run_metadata(run_metadata, <span class="string">'step%d'</span> % i)</div><div class="line">      train_writer.add_summary(summary, i)</div><div class="line">      print(<span class="string">'Adding run metadata for'</span>, i)</div><div class="line">    <span class="keyword">else</span>:  <span class="comment"># Record a summary</span></div><div class="line">      summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">      train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>此代码将从步骤99开始每隔100步发出运行时统计信息。</p>
<p>当您启动tensorboard并转到图表选项卡，您现在将看到“Session runs”下的选项对应于添加运行元数据的步骤。选择其中一个运行将显示该步骤的网络快照，淡出未使用的节点。在左侧的控件中，您可以按总内存或总计算时间对节点进行着色。此外，单击节点将显示确切的总内存，计算时间和张量输出大小。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/028.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/029.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/030.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:嵌入可视化
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T21:07:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-嵌入可视化/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>嵌入在机器学习中无处不在，出现在推荐系统，NLP和许多其他应用程序中。事实上，在TensorFlow的上下文中，将tensor（或tensor切片）视为空间中的点是自然的，因此几乎任何TensorFlow系统将自然地产生各种嵌入。</p>
<p>要了解有关嵌入和如何训练它们的更多信息，请参阅<a href="https://www.tensorflow.org/tutorials/word2vec" target="_blank" rel="external">单词向量表示教程</a>。如果你对图像的嵌入感兴趣，请查看<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>，了解MNIST图像的有趣的可视化。另一方面，如果你对单词嵌入感兴趣，那么<a href="http://colah.github.io/posts/2014-10-Visualizing-MNIST/" target="_blank" rel="external">这篇文章</a>会给你一个很好的介绍。</p>
<p>TensorBoard有一个内置的可视化工具，称为嵌入投影仪，用于交互式可视化和分析高维数据，例如嵌入。这意味着对开发人员和研究人员同样有用。它从保存tensorflow变量的检查点文件读取。虽然它对嵌入最有用，它将加载任何2D tensor，可能包括您的训练权重。</p>
<video height="363" width="710" id="video" controls preload="none" poster="/img/17_03_07/002.png"><br>    <source id="mp4" src="/img/17_03_07/001.mp4" type="video/mp4"><br>    <p>Your user agent does not support the HTML5 Video element.</p><br></video>

<p>默认情况下，嵌入投影仪执行三维<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="external">主成分分析</a>，这意味着它接受你的高维数据，并试图找到一个结构保留投影到三维空间。基本上，它通过旋转你的数据，使前三个维度显示尽可能多的数据方差。<a href="http://setosa.io/ev/principal-component-analysis/" target="_blank" rel="external">这里</a>有一个很好的视觉解释。另一个非常有用的投影是<a href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" target="_blank" rel="external">t-SNE</a>。我们稍后在教程中讨论更多的t-SNE。</p>
<p>如果您使用嵌入，您可能需要将标签/图像附加到数据点，以告诉可视化器每个数据点对应的标签/图像。您可以通过生成元数据文件，使用我们的Python API将其附加到tensor，或将其上传到已经运行的TensorBoard来完成。</p>
<h2 id="构建">构建</h2><p>有关如何运行TensorBoard并确保您记录所有必要的信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-可视化学习/">TensorBoard-可视化学习/</a>。</p>
<p>要可视化您的嵌入，您需要做3件事：</p>
<p>1）设置一个二维tensor变量来保存你的嵌入。</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">embedding_var</span> = tf.Variable(....)</div></pre></td></tr></table></figure>
<p>2）定期将您的嵌入保存在<code>LOG_DIR</code>中。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">saver = tf<span class="selector-class">.train</span><span class="selector-class">.Saver</span>()</div><div class="line">saver.save(session, os<span class="selector-class">.path</span><span class="selector-class">.join</span>(LOG_DIR, <span class="string">"model.ckpt"</span>), step)</div></pre></td></tr></table></figure>
<p>以下步骤不是必要的，但是如果您有与嵌入相关联的任何元数据（标签，图像），则需要将它们链接到tensor上，以便TensorBoard知道它。</p>
<p>3）将元数据与嵌入关联。</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">from tensorflow.contrib.tensorboard.plugins <span class="built_in">import</span> projector</div><div class="line"><span class="comment"># Use the same LOG_DIR where you stored your checkpoint.</span></div><div class="line"><span class="attr">summary_writer</span> = tf.train.SummaryWriter(LOG_DIR)</div><div class="line"></div><div class="line"><span class="comment"># Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto</span></div><div class="line"><span class="attr">config</span> = projector.ProjectorConfig()</div><div class="line"></div><div class="line"><span class="comment"># You can add multiple embeddings. Here we add only one.</span></div><div class="line"><span class="attr">embedding</span> = config.embeddings.add()</div><div class="line">embedding.<span class="attr">tensor_name</span> = embedding_var.name</div><div class="line"><span class="comment"># Link this tensor to its metadata file (e.g. labels).</span></div><div class="line">embedding.<span class="attr">metadata_path</span> = os.path.join(LOG_DIR, 'metadata.tsv')</div><div class="line"></div><div class="line"><span class="comment"># Saves a configuration file that TensorBoard will read during startup.</span></div><div class="line">projector.visualize_embeddings(summary_writer, config)</div></pre></td></tr></table></figure>
<p>运行模型并训练嵌入后，运行TensorBoard并将其指向job的<code>LOG_DIR</code>。</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard <span class="comment">--logdir=LOG_DIR</span></div></pre></td></tr></table></figure>
<p>然后单击顶部窗格上的<em>Embeddings</em>选项卡，并选择适当的运行（如果有多个运行）。</p>
<h2 id="元数据（可选）">元数据（可选）</h2><p>通常嵌入具有与其相关联的元数据（例如，标签，图像）。元数据应存储在模型检查点之外的单独文件中，因为元数据不是模型的可训练参数。格式应为TSV文件，第一行包含列标题，后续行包含元数据值。这里有一个例子：</p>
<figure class="highlight taggerscript"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Name<span class="symbol">\t</span>Type<span class="symbol">\n</span></div><div class="line">Caterpie<span class="symbol">\t</span>Bug<span class="symbol">\n</span></div><div class="line">Charmeleon<span class="symbol">\t</span>Fire<span class="symbol">\n</span></div><div class="line">…</div></pre></td></tr></table></figure>
<p>没有与主数据文件共享的显式键;相反，假设元数据文件中的顺序与嵌入tensor中的顺序匹配。换句话说，第一行是头信息，元数据文件中的第(i+1)行对应于存储在检查点中的嵌入tensor的第i行。</p>
<blockquote>
<p><strong>注意：</strong>如果TSV元数据文件只有一个列，那么我们不需要一个标题行，并且假设每一行都是嵌入的标签。我们包含此异常，因为它匹配常用的“词汇文件”格式。</p>
</blockquote>
<h3 id="图">图</h3><p>如果您有与嵌入关联的图像，则需要生成包含每个数据点的小缩略图的单个图像。这被称为<a href="https://www.google.com/webhp#q=what+is+a+sprite+image" target="_blank" rel="external">精灵图像（sprite image）</a>。精灵应具有相同数目的行和列，缩略图按行首先顺序存储：第一个数据点放置在左上角，最后一个数据点在右下角：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
<th style="text-align:center"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">1</td>
<td style="text-align:center">2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">4</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">7</td>
</tr>
</tbody>
</table>
<p>请注意，在上面的示例中，最后一行不必填写。对于精灵的一个具体示例，请看这个<a href="https://www.tensorflow.org/images/mnist_10k_sprite.png" target="_blank" rel="external">精灵图像</a>的10,000 MNIST数字（100x100）。</p>
<blockquote>
<p><strong>注意：</strong>我们目前支持高达8192px X 8192px.的精灵。</p>
</blockquote>
<p>构造精灵后，您需要告诉嵌入投影机在哪里可以找到它：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">embedding.sprite.image_path = PATH_TO_SPRITE_IMAGE</div><div class="line"><span class="comment"># Specify the width and height of a single thumbnail.</span></div><div class="line">embedding.sprite.single_image_dim.<span class="keyword">extend</span>([w, h])</div></pre></td></tr></table></figure>
<h2 id="相互作用">相互作用</h2><p>嵌入式投影机有三个面板</p>
<ul>
<li>1.位于左上方的数据面板，你可以选择你指定的运行、嵌入tensor和数据列来着色和标记点。</li>
<li>2.位于左下方的预测面板，用于选择投影类型（例如PCA，t-SNE）。</li>
<li>3.位于右侧的监视面板，在那里你可以搜索特定的点，并查看最近的邻居列表。</li>
</ul>
<h3 id="预测">预测</h3><p>嵌入投影仪具有减少数据集的维度的三种方法：两个线性的和一个非线性的。每个方法可用于创建二维或三维视图。</p>
<p><strong>主成分分析（Principal Component Analysis）</strong>减少维度的主要技术是主成分分析（PCA）。嵌入投影仪计算前10个主要元素。该菜单允许您将这些元素投影到两个或三个任意组合。PCA是一个线性投影，通常用于检查全局几何。</p>
<p><strong>t-SNE</strong>一种流行的非线性降维技术是T-SNE。嵌入投影机提供二维和三维t-SNE视图。布局是在客户端对算法的每一步执行动画。因为t-SNE经常保留一些局部结构，所以它对于探索局部邻域和找到簇是有用的。虽然对于可视化高维数据非常有用，但t-SNE图有时可能会产生迷惑或者误导的作用。想要了解如何有效地使用t-SNE，可以看看这篇<a href="http://distill.pub/2016/misread-tsne/" target="_blank" rel="external">很棒的文章</a>。</p>
<p><strong>自定义（Custom）</strong>您还可以基于文本搜索来构造专门的线性投影，以在空间中找到有意义的方向。要定义投影轴，请输入两个搜索字符串或正则表达式。程序计算出其标签与这些搜索匹配的点集合的质心，并使用质心之间的差向量作为投影轴。</p>
<h3 id="导航">导航</h3><p>要探索数据集，您可以在2D或3D模式中浏览视图，使用自然的点击和拖动手势进行缩放，旋转和平移。单击一个点会使右窗格显示最近邻居的显式文本列表，以及到当前点的距离。最近邻点本身在投影上突出显示。</p>
<p>放大集群会提供一些信息，但有时更有帮助的是将视图限制为点的子集，并仅对这些点执行投影。为此，您可以通过多种方式选择点：</p>
<ul>
<li>1.点击一个点后，也选择其最近的邻居。</li>
<li>2.搜索后，选择与查询匹配的点。</li>
<li>3.启用选择，单击点并拖动定义选择球体。</li>
</ul>
<p>选择一组点后，您可以使用右侧“检查器”窗格中的“隔离点”按钮单独隔离这些点以进行进一步分析。</p>
<p><img src="/img/17_03_07/003.png" alt=""></p>
<p><em>在词嵌入数据集中选择“重要”的最近邻。</em></p>
<p>过滤与自定义投影的组合的功能是非常强大的。下面，我们过滤了“politics”的100个最接近的邻居，并将它们投影到“best” - “worst”向量作为x轴。 y轴是随机的。</p>
<p>你可以看到，在右边我们有“ideas”，“science”，“perspective”，“journalism”，而在左边我们有“crisis”，“violence”和“conflict”。</p>
<table>
<thead>
<tr>
<th style="text-align:left"><img src="/img/17_03_07/006.png" alt=""></th>
<th style="text-align:left"><img src="/img/17_03_07/004.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">自定义投影控件。</td>
<td style="text-align:left">将“politics”的邻居定义为“best” - “worst”向量。</td>
</tr>
</tbody>
</table>
<h3 id="共同特征">共同特征</h3><p>如果你想要分享您的发现，您可以使用右下角的书签面板，并将当前状态（包括任何投影的计算坐标）保存为小文件。投影仪可以同时打开并展示一个或多个这些小文件。这样一来，其他用户就可以浏览这些书签了。</p>
<p><img src="/img/17_03_07/005.png" alt=""></p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="url">
                【Tensorflow r1.0 文档翻译】TensorBoard:可视化学习
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-07T18:26:58+08:00" content="2017-03-07">
            2017-03-07
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/07/【Tensorflow r1.0 文档翻译】TensorBoard-可视化学习/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>你使用TensorFlow来进行的某些大规模深度神经网络，可能是很复杂，并且令人困惑的。为了使它更容易被理解、调试、并且优化TensorFlow程序，我们引入了一套可视化工具，它就是TensorBoard。你可以使用TensorBoard来可视化你的TensorFlow计算图，绘制关于图形执行的定量指标，以及显示其他数据的图像。</p>
<p>当TensorBoard完全配置好时，它看起来是这样的：</p>
<p><img src="/img/17_03_07/001.png" alt=""></p>
<p>本教程旨在帮助您学习TensorBoard的基本使用方式。当然，还有其他介绍资源！<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>有大量关于TensorBoard的信息，包括提示和技巧和调试信息。</p>
<h2 id="序列化数据">序列化数据</h2><p>TensorBoard通过读取TensorFlow事件文件进行操作，这些文件包含运行TensorFlow时可以生成的摘要数据。下面是TensorBoard中摘要数据的一般生命周期。</p>
<p>首先，创建要从其中收集摘要数据的TensorFlow图，并决定要使用<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">summary operations</a>注释哪些节点。</p>
<p>例如，假设你正在训练一个卷积神经网络来识别MNIST数字。你想记录学习速率随时间的变化，以及目标函数如何变化。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/scalar" target="_blank" rel="external"><code>tf.summary.scalar</code></a>操作分别附加到输出学习速率和损失的节点来收集这些信息。然后，给每个<code>scalar_summary</code>赋予有意义的<code>tag</code>，如<code>learning rate</code>或<code>loss function</code>。</p>
<p>也许你也想要可视化来自特定层的激活的分布，或梯度或权重的分布。通过将<a href="https://www.tensorflow.org/api_docs/python/tf/summary/histogram" target="_blank" rel="external"><code>tf.summary.histogram</code></a>操作附加到梯度输出和分别保存您的权重的变量来收集此数据。</p>
<p>有关所有可用摘要操作的详细信息，请查看<a href="https://www.tensorflow.org/api_guides/python/summary" target="_blank" rel="external">摘要操作的文档</a>。</p>
<p>在您运行TensorFlow中的操作之前，它们都不会被运行，依赖于它们的输出的操作也不会被执行。我们刚刚创建的汇总节点是图形的外设：您当前运行的任何操作都不依赖于它们。因此，要生成摘要，我们需要运行所有这些摘要节点。手动管理它们将是一项乏味的工作，因此我们使用<a href="https://www.tensorflow.org/api_docs/python/tf/summary/merge_all" target="_blank" rel="external"><code>tf.summary.merge_all</code></a>将它们组合到一个单独的操作中，生成所有的摘要数据。</p>
<p>然后，您可以运行合并的摘要操作，这将生成一个包含有所有给定步骤的摘要数据的序列化的<code>Summary</code>（摘要）protobuf对象。最后，要将此摘要数据写入磁盘，将摘要protobuf传递给<a href="https://www.tensorflow.org/api_docs/python/tf/summary/FileWriter" target="_blank" rel="external"><code>tf.summary.FileWriter</code></a>。</p>
<p><code>FileWriter</code>在它的构造函数中接受一个logdir - 这个logdir是非常重要的，它是所有事件将被写出的目标目录。此外，<code>FileWriter</code>可以选择在其构造函数中接受一个<code>Graph</code>。如果它接收到一个<code>Graph</code>对象，那么TensorBoard将与Tensor形状信息一起显示到界面上。这将使您更好地了解通过图形流动的信息：请参阅<a href="https://www.tensorflow.org/get_started/graph_viz#tensor_shape_information" target="_blank" rel="external">Tensor shape信息</a>。</p>
<p>现在，你已经修改好了你的图，并且有了一个<code>FileWriter</code>，并且做好了开始运行网络的准备!如果需要，您可以每一步运行一次摘要合并，并记录大量的训练数据。这可能会产生很多你不需要的数据。所以换一种方式，请考虑每n个步骤运行一次摘要合并操作。</p>
<p>下面的代码示例是一个<a href="https://www.tensorflow.org/get_started/mnist/beginners" target="_blank" rel="external">简单的MNIST教程</a>的修改，其中我们添加了一些摘要操作，并且每十步运行它们一次。如果你运行这个代码，然后启动<code>tensorboard --logdir=/tmp/mnist_logs</code>，你将能够可视化统计，例如权重或精度在训练期间如何变化。下面是部分代码，全部源码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py" target="_blank" rel="external">这里</a>。</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line">def variable_summaries(var):</div><div class="line">  <span class="string">""</span><span class="string">"Attach a lot of summaries to a Tensor (for TensorBoard visualization)."</span><span class="string">""</span></div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'summaries'</span>):</div><div class="line">    mean = <span class="keyword">tf</span>.reduce_mean(var)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'mean'</span>, mean)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'stddev'</span>):</div><div class="line">      stddev = <span class="keyword">tf</span>.<span class="built_in">sqrt</span>(<span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.square(var - mean)))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'stddev'</span>, stddev)</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'max'</span>, <span class="keyword">tf</span>.reduce_max(var))</div><div class="line">    <span class="keyword">tf</span>.summary.scalar(<span class="string">'min'</span>, <span class="keyword">tf</span>.reduce_min(var))</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'histogram'</span>, var)</div><div class="line"></div><div class="line">def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=<span class="keyword">tf</span>.<span class="keyword">nn</span>.relu):</div><div class="line">  <span class="string">""</span><span class="comment">"Reusable code for making a simple neural net layer.</span></div><div class="line"></div><div class="line">  It does <span class="keyword">a</span> matrix multiply, bias <span class="built_in">add</span>, <span class="built_in">and</span> then uses relu <span class="keyword">to</span> nonlinearize.</div><div class="line">  It also sets <span class="keyword">up</span> name scoping <span class="keyword">so</span> that the resultant graph <span class="keyword">is</span> easy <span class="keyword">to</span> <span class="keyword">read</span>,</div><div class="line">  <span class="built_in">and</span> adds <span class="keyword">a</span> <span class="keyword">number</span> of summary ops.</div><div class="line">  <span class="string">""</span><span class="comment">"</span></div><div class="line">  # Adding <span class="keyword">a</span> name scope ensures logical grouping of the layers in the graph.</div><div class="line">  with <span class="keyword">tf</span>.name_scope(layer_name):</div><div class="line">    # This Variable will hold the state of the weights <span class="keyword">for</span> the layer</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'weights'</span>):</div><div class="line">      weights = weight_variable([input_dim, output_dim])</div><div class="line">      variable_summaries(weights)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'biases'</span>):</div><div class="line">      biases = bias_variable([output_dim])</div><div class="line">      variable_summaries(biases)</div><div class="line">    with <span class="keyword">tf</span>.name_scope(<span class="string">'Wx_plus_b'</span>):</div><div class="line">      preactivate = <span class="keyword">tf</span>.matmul(input_tensor, weights) + biases</div><div class="line">      <span class="keyword">tf</span>.summary.histogram(<span class="string">'pre_activations'</span>, preactivate)</div><div class="line">    activations = act(preactivate, name=<span class="string">'activation'</span>)</div><div class="line">    <span class="keyword">tf</span>.summary.histogram(<span class="string">'activations'</span>, activations)</div><div class="line">    <span class="keyword">return</span> activations</div><div class="line"></div><div class="line">hidden1 = nn_layer(<span class="keyword">x</span>, <span class="number">784</span>, <span class="number">500</span>, <span class="string">'layer1'</span>)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'dropout'</span>):</div><div class="line">  keep_prob = <span class="keyword">tf</span>.placeholder(<span class="keyword">tf</span>.float32)</div><div class="line">  <span class="keyword">tf</span>.summary.scalar(<span class="string">'dropout_keep_probability'</span>, keep_prob)</div><div class="line">  dropped = <span class="keyword">tf</span>.<span class="keyword">nn</span>.dropout(hidden1, keep_prob)</div><div class="line"></div><div class="line"># Do not apply softmax activation yet, see below.</div><div class="line"><span class="keyword">y</span> = nn_layer(dropped, <span class="number">500</span>, <span class="number">10</span>, <span class="string">'layer2'</span>, act=<span class="keyword">tf</span>.identity)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'cross_entropy'</span>):</div><div class="line">  # The raw formulation of cross-entropy,</div><div class="line">  #</div><div class="line">  # <span class="keyword">tf</span>.reduce_mean(-<span class="keyword">tf</span>.reduce_sum(y_ * <span class="keyword">tf</span>.<span class="built_in">log</span>(<span class="keyword">tf</span>.softmax(<span class="keyword">y</span>)),</div><div class="line">  #                               reduction_indices=[<span class="number">1</span>]))</div><div class="line">  #</div><div class="line">  # can <span class="keyword">be</span> numerically unstable.</div><div class="line">  #</div><div class="line">  # So here we use <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits <span class="keyword">on</span> the</div><div class="line">  # raw outputs of the nn_layer above, <span class="built_in">and</span> then average across</div><div class="line">  # the batch.</div><div class="line">  diff = <span class="keyword">tf</span>.<span class="keyword">nn</span>.softmax_cross_entropy_with_logits(targets=y_, logits=<span class="keyword">y</span>)</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'total'</span>):</div><div class="line">    cross_entropy = <span class="keyword">tf</span>.reduce_mean(diff)</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'cross_entropy'</span>, cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'train'</span>):</div><div class="line">  train_step = <span class="keyword">tf</span>.train.AdamOptimizer(FLAGS.learning_rate).minimize(</div><div class="line">      cross_entropy)</div><div class="line"></div><div class="line">with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'correct_prediction'</span>):</div><div class="line">    correct_prediction = <span class="keyword">tf</span>.equal(<span class="keyword">tf</span>.argmax(<span class="keyword">y</span>, <span class="number">1</span>), <span class="keyword">tf</span>.argmax(y_, <span class="number">1</span>))</div><div class="line">  with <span class="keyword">tf</span>.name_scope(<span class="string">'accuracy'</span>):</div><div class="line">    accuracy = <span class="keyword">tf</span>.reduce_mean(<span class="keyword">tf</span>.cast(correct_prediction, <span class="keyword">tf</span>.float32))</div><div class="line"><span class="keyword">tf</span>.summary.scalar(<span class="string">'accuracy'</span>, accuracy)</div><div class="line"></div><div class="line"># Merge <span class="keyword">all</span> the summaries <span class="built_in">and</span> <span class="keyword">write</span> them out <span class="keyword">to</span> /tmp/mnist_logs (by default)</div><div class="line">merged = <span class="keyword">tf</span>.summary.merge_all()</div><div class="line">train_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/train'</span>,</div><div class="line">                                      sess.graph)</div><div class="line">test_writer = <span class="keyword">tf</span>.summary.FileWriter(FLAGS.summaries_dir + <span class="string">'/test'</span>)</div><div class="line"><span class="keyword">tf</span>.global_variables_initializer().run()</div></pre></td></tr></table></figure>
<p>在我们初始化<code>FileWriter</code>之后，我们在训练和测试模型时，必须向<code>FileWriter</code>添加摘要。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Train the model, and also write summaries.</span></div><div class="line"><span class="comment"># Every 10th step, measure test-set accuracy, and write test summaries</span></div><div class="line"><span class="comment"># All other steps, run train_step on training data, &amp; add training summaries</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_dict</span><span class="params">(train)</span>:</span></div><div class="line">  <span class="string">"""Make a TensorFlow feed_dict: maps data onto Tensor placeholders."""</span></div><div class="line">  <span class="keyword">if</span> train <span class="keyword">or</span> FLAGS.fake_data:</div><div class="line">    xs, ys = mnist.train.next_batch(<span class="number">100</span>, fake_data=FLAGS.fake_data)</div><div class="line">    k = FLAGS.dropout</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    xs, ys = mnist.test.images, mnist.test.labels</div><div class="line">    k = <span class="number">1.0</span></div><div class="line">  <span class="keyword">return</span> &#123;x: xs, y_: ys, keep_prob: k&#125;</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(FLAGS.max_steps):</div><div class="line">  <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment"># Record summaries and test-set accuracy</span></div><div class="line">    summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(<span class="keyword">False</span>))</div><div class="line">    test_writer.add_summary(summary, i)</div><div class="line">    print(<span class="string">'Accuracy at step %s: %s'</span> % (i, acc))</div><div class="line">  <span class="keyword">else</span>:  <span class="comment"># Record train set summaries, and train</span></div><div class="line">    summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(<span class="keyword">True</span>))</div><div class="line">    train_writer.add_summary(summary, i)</div></pre></td></tr></table></figure>
<p>现在，你就可以通过TensorBoard来可视化数据了。</p>
<h2 id="启动TensorBoard">启动TensorBoard</h2><p>要运行TensorBoard，请使用以下命令（或者<code>python -m tensorflow.tensorboard</code>）:</p>
<figure class="highlight autoit"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tensorboard --logdir=path/<span class="keyword">to</span>/<span class="built_in">log</span>-directory</div></pre></td></tr></table></figure>
<p>其中<code>logdir</code>指向<code>FileWriter</code>将其数据序列化的目录。如果此logdir目录包含包含单独运行的序列化数据的子目录，则TensorBoard将可视化所有这些运行的数据。TensorBoard开始运行之后，就可以打开您的Web浏览器到<code>localhost:6006</code>来查看TensorBoard了。</p>
<p>当你看着TensorBoard，你会看到在右上角的导航选项卡。每个选项卡表示可以可视化的一组序列化数据。</p>
<p>有关如何使用图形选项卡可视化图形的详细信息，请参阅<a href="/2017/03/07/【Tensorflow%20r1.0%20文档翻译】TensorBoard-图的可视化/">TensorBoard：图形可视化</a>。</p>
<p>有关TensorBoard的更多使用信息，请参阅<a href="https://www.tensorflow.org/code/tensorflow/tensorboard/README.md" target="_blank" rel="external">TensorBoard README</a>。</p>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <header class="post-header">

      
      
        <h1 class="post-title" itemprop="name headline">
          
          
            
              <a class="post-title-link" href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="url">
                【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数
              </a>
            
          
        </h1>
      

      <div class="post-meta">
        <span class="post-time">
          发表于
          <time itemprop="dateCreated" datetime="2017-03-06T22:24:58+08:00" content="2017-03-06">
            2017-03-06
          </time>
        </span>

        
          <span class="post-category" >
            &nbsp; | &nbsp; 分类于
            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/" itemprop="url" rel="index">
                  <span itemprop="name">机器学习</span>
                </a>
              </span>

              
              
                ， 
              

            
              <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                <a href="/categories/机器学习/Tensorflow/" itemprop="url" rel="index">
                  <span itemprop="name">Tensorflow</span>
                </a>
              </span>

              
              

            
          </span>
        

        
          
            <span class="post-comments-count">
              &nbsp; | &nbsp;
              <a href="/2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/#comments" itemprop="discussionUrl">
                <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/06/【Tensorflow r1.0 文档翻译】通过tf.contrib.learn来构建输入函数/" itemprop="commentsCount"></span>
              </a>
            </span>
          
        
      </div>
    </header>

    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody"><p>本教程将介绍如何在tf.contrib.learn中创建输入函数。您将对如何构造一个用于预处理并将数据反馈到你的模型的<code>input_fn</code>操作有一个大致的了解。然后，您将实现一个<code>input_fn</code>，它将训练，评估和预测数据提供给神经网络回归，并用于预测房屋数据的中位数值。</p>
<h2 id="使用input_fn的自定义输入管道">使用input_fn的自定义输入管道</h2><p>当通过使用tf.contrib.learn来训练一个神经网络时，可以将您的特征和目标数据直接传递到你的<code>fit</code>(拟合)、<code>evaluate</code>(评估)或<code>predict</code>(预测)操作中。下面是从<a href="/2017/03/05/【Tensorflow%20r1.0%20文档翻译】【tf.contrib.learn快速入门】/">tf.contrib.learn快速入门教程</a>中获取的示例：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">training_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TRAINING, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">test_set = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.datasets</span><span class="selector-class">.base</span><span class="selector-class">.load_csv_with_header</span>(</div><div class="line">    filename=IRIS_TEST, target_dtype=np<span class="selector-class">.int</span>, features_dtype=np.float32)</div><div class="line">...</div><div class="line"></div><div class="line">classifier.fit(x=training_set<span class="selector-class">.data</span>,</div><div class="line">               y=training_set<span class="selector-class">.target</span>,</div><div class="line">               steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>这种数据量不大的情况下，我们即使不处理数据源，也可好获得良好的效果。但是在需要更多特征工程的情况下，<code>tf.contrib.learn</code>支持使用自定义输入函数（<code>input_fn</code>），它可以将预处理和管道数据的逻辑封装到模型中。</p>
<h3 id="input_fn的剖析">input_fn的剖析</h3><p>以下代码说明了输入函数的基本框架：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_fn</span><span class="params">()</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># Preprocess your data here...</span></div><div class="line"></div><div class="line">    <span class="comment"># ...then return 1) a mapping of feature columns to Tensors with</span></div><div class="line">    <span class="comment"># the corresponding feature data, and 2) a Tensor containing labels</span></div><div class="line">    <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>输入函数的主体包含用于预处理输入数据的特定逻辑，例如<strong>擦除不良样本</strong>或<strong><a href="https://en.wikipedia.org/wiki/Feature_scaling" target="_blank" rel="external">特征缩放</a></strong>。</p>
<p>输入函数必须返回以下两个值，这两个值包含要输入到模型中的最终特征和标签数据（如上面的代码框架中所示）：</p>
<p><code>feature_cols</code></p>
<pre><code>包含将特征列名称映射到包含相应特征数据的<span class="escape">`T</span>ensor<span class="escape">`（</span>或<span class="escape">`S</span>parseTensor<span class="escape">`）</span>的键/值对的字典。
</code></pre><p><code>labels</code></p>
<pre><code>包含您的标签（目标）值的<span class="escape">`T</span>ensor<span class="escape">`：</span>你的模型的值的目的是用于预测。
</code></pre><h3 id="将特征数据转换为Tensor">将特征数据转换为Tensor</h3><p>如果你的特征/标签数据储存在<a href="http://pandas.pydata.org/" target="_blank" rel="external">pandas</a>数据帧中或<a href="http://www.numpy.org/" target="_blank" rel="external">numpy</a>数组中，那么你需要将其转换为<code>Tensor</code>，然后从您的<code>input_fn</code>中返回它。</p>
<p>对于连续数据，可以使用<code>tf.constant</code>创建和填充<code>Tensor</code>：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_column_data = [<span class="number">1</span>, <span class="number">2.4</span>, <span class="number">0</span>, <span class="number">9.9</span>, <span class="number">3</span>, <span class="number">120</span>]</div><div class="line">feature_tensor = tf.constant(feature_column_data)</div></pre></td></tr></table></figure>
<p>对于<a href="https://en.wikipedia.org/wiki/Sparse_matrix" target="_blank" rel="external">稀疏分类数据</a>（大多数值为0的数据），您应该替换为填充一个<code>SparseTensor</code>，它使用三个参数来实例化：</p>
<p><code>dense_shape</code></p>
<pre><code>tensor的形状。获取一个列表，指示每个维度中元素的数量。例如：`dense_shape=[<span class="number">3</span>,<span class="number">6</span>]`指定了一个二维的<span class="number">3</span>x6的tensor，`dense_shape=[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]`指定了一个三维的<span class="number">2</span>x3x4的tensor，`dense_shape=[<span class="number">9</span>]`指定了一个拥有<span class="number">9</span>个元素的一维tensor。
</code></pre><p><code>indices</code></p>
<pre><code>您的tensor中包含非零元素的索引。值为一个列表，其中每一项本身是包含非零元素的索引的列表。（元素是零索引的 - 即，`[<span class="number">0</span>,<span class="number">0</span>]`是二维张量中第一行的第一列中的元素的索引值）。例如：`indices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]`指定了索引为`[<span class="number">1</span>,<span class="number">3</span>]`和`[<span class="number">2</span>,<span class="number">4</span>]`的元素具有非零值。
</code></pre><p><code>values</code></p>
<pre><code>值为一维tensor。<span class="escape">`v</span>alues<span class="escape">`的</span>项<span class="escape">`i</span><span class="escape">`对</span>应于<span class="escape">`i</span>ndices<span class="escape">`中</span>的项<span class="escape">`i</span><span class="escape">`，</span>并且指定了它的值。例如，给定了<span class="escape">`i</span>ndices=[[<span class="number">1</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">4</span>]]<span class="escape">`，</span>那么参数<span class="escape">`v</span>alues=[<span class="number">18</span>, <span class="number">3.6</span>]<span class="escape">`就</span>指定了tensor的元素<span class="escape">`[</span><span class="number">1</span>,<span class="number">3</span>]<span class="escape">`的</span>值为<span class="number">18</span>，元素<span class="escape">`[</span><span class="number">2</span>,<span class="number">4</span>]<span class="escape">`的</span>值为<span class="number">3.6</span>。
</code></pre><p>以下代码定义了一个具有3行和5列的二维<code>SparseTensor</code>。具有索引<code>[0,1]</code>的元素的值为6，并且索引为<code>[2,4]</code>的元素值为0.5（所有其他值为0）：</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sparse_tensor = tf.SparseTensor(indices=[[<span class="number">0</span>,<span class="number">1</span>], [<span class="number">2</span>,<span class="number">4</span>]],</div><div class="line">                                values=[<span class="number">6</span>, <span class="number">0.5</span>],</div><div class="line">                                dense_shape=[<span class="number">3</span>, <span class="number">5</span>])</div></pre></td></tr></table></figure>
<p>这对应了下面的稠密tensor(dense tensor)：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[[<span class="number">0</span>, <span class="number">6</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</div><div class="line"> [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.5</span>]]</div></pre></td></tr></table></figure>
<p>更多关于<code>SparseTensor</code>的内容，请见<a href="https://www.tensorflow.org/api_docs/python/tf/SparseTensor" target="_blank" rel="external"><code>tf.SparseTensor</code></a></p>
<h3 id="将input_fn数据传递给您的模型">将input_fn数据传递给您的模型</h3><p>要将数据馈送到您的模型进行训练，您只需将创建的输入函数作为<code>input_fn</code>参数的值传递到<code>fit</code>运算即可，例如：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn,</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>请注意，<code>input_fn</code>负责将特征和标签数据提供给模型，并在<code>fit</code>(拟合)中替换<code>x</code>和<code>y</code>参数。如果为<code>fit</code>提供了一个不为空的<code>input_fn</code>值与不为<code>None</code>的<code>x</code>或<code>y</code>结合，它将抛出一个<code>ValueError</code>。</p>
<p>还要注意一点，<code>input_fn</code>参数必须接收一个函数对象（例如<code>input_fn = my_input_fn</code>），而不是函数调用的返回值（<code>input_fn = my_input_fn()</code>）。这意味着，如果您尝试在<code>fit</code>的调用中按照下面的方式，将参数传递给输入函数，则会导致TypeError：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.fit(<span class="attr">input_fn=my_input_fn(training_set),</span> <span class="attr">steps=2000)</span></div></pre></td></tr></table></figure>
<p>但是，如果你想要参数化你的输入函数，有一些其他的方法可以做到。您可以使用不带参数的包装函数作为<code>input_fn</code>，并使用它来调用具有所需参数的输入函数。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_input_function_training_set</span><span class="params">()</span>:</span></div><div class="line">  <span class="keyword">return</span> my_input_function(training_set)</div><div class="line"></div><div class="line">classifier.fit(input_fn=my_input_fn_training_set, steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>或者，你可以使用Python的<a href="https://docs.python.org/2/library/functools.html#functools.partial" target="_blank" rel="external"><code>functools.partial</code></a>方法来构造一个新的所有参数值固定的方法对象：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">classifier.fit(input_fn=functools.partial(my_input_<span class="keyword">function</span>,</div><div class="line">                                          data_<span class="built_in">set</span>=training_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>第三种方式是将<code>input_fn</code>调用包装在<a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" target="_blank" rel="external"><code>lambda</code></a>中，并将其传递给<code>input_fn</code>参数：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: my_input_fn(training_set), steps=<span class="number">2000</span>)</div></pre></td></tr></table></figure>
<p>构建您的输入管道的一个很大的优势如上所示 – 可以接受数据集的参数 – 是你只需修改数据集的参数，就可以传递相同的<code>input_fn</code>到<code>evaluate</code>和<code>predict</code>操作上。例如：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">classifier.evaluate(input_fn=lambda: my_input_fn(<span class="built_in">test</span>_<span class="built_in">set</span>), steps=2000)</div></pre></td></tr></table></figure>
<p>这种方法增强了代码的可维护性：不需要针对每种类型的操作捕获单独变量（例如，<code>x_train</code>，<code>x_test</code>，<code>y_train</code>，<code>y_test</code>）中的<code>x</code>和<code>y</code>值。</p>
<h3 id="一个用于波士顿房屋数据的神经网络">一个用于波士顿房屋数据的神经网络</h3><p>在本教程的剩余部分，您将编写一个输入函数，用于预处理从<a href="https://archive.ics.uci.edu/ml/datasets/Housing" target="_blank" rel="external">UCI住宅数据集</a>中提取的一组波士顿房屋数据，并使用它来将数据馈送到神经网络回归器，以预测房屋中值。</p>
<p>您将用于训练神经网络的<a href="https://www.tensorflow.org/get_started/input_fn#setup" target="_blank" rel="external">波士顿CSV数据集</a>包含以下波士顿郊区的<a href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.names" target="_blank" rel="external">特征数据</a>：</p>
<table>
<thead>
<tr>
<th style="text-align:left">特征</th>
<th style="text-align:left">描述</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CRIM</td>
<td style="text-align:left">人均犯罪率</td>
</tr>
<tr>
<td style="text-align:left">ZN</td>
<td style="text-align:left">超过25,000+平方呎地段的住宅用地的部分</td>
</tr>
<tr>
<td style="text-align:left">INDUS</td>
<td style="text-align:left">非零售业的土地部分</td>
</tr>
<tr>
<td style="text-align:left">NOX</td>
<td style="text-align:left">一氧化氮浓度 以百万分之一为单位</td>
</tr>
<tr>
<td style="text-align:left">RM</td>
<td style="text-align:left">每个住宅平均房间数</td>
</tr>
<tr>
<td style="text-align:left">AGE</td>
<td style="text-align:left">在1940年之前建造的自用住宅的部分</td>
</tr>
<tr>
<td style="text-align:left">DIS</td>
<td style="text-align:left">到波士顿地区就业中心的距离</td>
</tr>
<tr>
<td style="text-align:left">TAX</td>
<td style="text-align:left">每$10,000的房产税税率</td>
</tr>
<tr>
<td style="text-align:left">PTRATIO</td>
<td style="text-align:left">学生 - 教师比例</td>
</tr>
</tbody>
</table>
<p>你的模型预测的标签是MEDV，自用住宅的价格中值，以千美元计。</p>
<h2 id="构建">构建</h2><p>下载以下数据集：<a href="http://download.tensorflow.org/data/boston_train.csv" target="_blank" rel="external">boston_train.csv</a>, <a href="http://download.tensorflow.org/data/boston_test.csv" target="_blank" rel="external">boston_test.csv</a>, 和 <a href="http://download.tensorflow.org/data/boston_predict.csv" target="_blank" rel="external">boston_predict.csv</a>。</p>
<p>以下部分提供了如何创建输入函数的手把手的步骤，将这些数据集送入神经网络回归，训练和评估模型，并进行房屋价值预测。完整的最终代码在<a href="https://www.tensorflow.org/code/tensorflow/examples/tutorials/input_fn/boston.py" target="_blank" rel="external">这里</a>。</p>
<h3 id="输入房屋数据">输入房屋数据</h3><p>要开始，请设置导入所需的库（包括<code>pandas</code>和<code>tensorflow</code>），并将<a href="https://www.tensorflow.org/get_started/monitors#enabling_logging_with_tensorflow" target="_blank" rel="external">日志级别设置</a>为<code>INFO</code>以获取更详细的日志输出：</p>
<figure class="highlight elm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> absolute_import</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> division</div><div class="line"><span class="title">from</span> __future__ <span class="keyword">import</span> print_function</div><div class="line"></div><div class="line"><span class="keyword">import</span> itertools</div><div class="line"></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="title">tf</span>.logging.set_verbosity(tf.logging.<span class="type">INFO</span>)</div></pre></td></tr></table></figure>
<p>在<code>COLUMNS</code>中定义数据集的列名称。要区分特征和标签，还需要定义<code>FEATURES</code>和<code>LABEL</code>。然后将三个CSV（<code>tf.train</code>，<code>tf.test</code>和<code>predict</code>）读入pandas <code>DataFrame</code>s：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="attr">COLUMNS</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>, <span class="string">"age"</span>,</div><div class="line">           <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>, <span class="string">"medv"</span>]</div><div class="line"><span class="attr">FEATURES</span> = [<span class="string">"crim"</span>, <span class="string">"zn"</span>, <span class="string">"indus"</span>, <span class="string">"nox"</span>, <span class="string">"rm"</span>,</div><div class="line">            <span class="string">"age"</span>, <span class="string">"dis"</span>, <span class="string">"tax"</span>, <span class="string">"ptratio"</span>]</div><div class="line"><span class="attr">LABEL</span> = <span class="string">"medv"</span></div><div class="line"></div><div class="line"><span class="attr">training_set</span> = pd.read_csv(<span class="string">"boston_train.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                           <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">test_set</span> = pd.read_csv(<span class="string">"boston_test.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                       <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div><div class="line"><span class="attr">prediction_set</span> = pd.read_csv(<span class="string">"boston_predict.csv"</span>, <span class="attr">skipinitialspace=True,</span></div><div class="line">                             <span class="attr">skiprows=1,</span> <span class="attr">names=COLUMNS)</span></div></pre></td></tr></table></figure>
<h3 id="定义特征列并创建回归">定义特征列并创建回归</h3><p>接下来，为输入数据创建<code>FeatureColumn</code>list，正式指定要用于训练的特征集。由于房屋数据集中的所有特征都包含连续的值，因此可以使用<code>tf.contrib.layers.real_valued_column()</code>函数创建其<code>FeatureColumn</code>s：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">feature_cols = [tf<span class="selector-class">.contrib</span><span class="selector-class">.layers</span><span class="selector-class">.real_valued_column</span>(k)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES]</div></pre></td></tr></table></figure>
<p>注意：有关特征列的更深入的内容，请参阅此<a href="https://www.tensorflow.org/tutorials/linear#feature_columns_and_transformations" target="_blank" rel="external">简介</a>，以及说明如何为分类数据定义<code>FeatureColumns</code>的示例，请参阅线<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">性模型教程</a>。</p>
<p>现在，为神经网络回归模型实例化一个<code>DNNRegressor</code>。这里你需要提供两个参数：<code>hidden_units</code>，指定每个隐藏层中的节点数量的超参数(hyperparameter)（这里，有两个隐藏层，每个隐藏层都具有10个节点），以及<code>feature_columns</code>，包含您刚定义的<code>FeatureColumns</code>list：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">regressor = tf<span class="selector-class">.contrib</span><span class="selector-class">.learn</span><span class="selector-class">.DNNRegressor</span>(feature_columns=feature_cols,</div><div class="line">                                          hidden_units=[<span class="number">10</span>, <span class="number">10</span>],</div><div class="line">                                          model_dir=<span class="string">"/tmp/boston_model"</span>)</div></pre></td></tr></table></figure>
<h3 id="构建input_fn">构建input_fn</h3><p>要将输入数据传递到<code>regressor</code>，请创建一个输入函数，它将接受一个pandas <code>Dataframe</code>并返回特征列和标签值作为<code>Tensor</code>s：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">input_fn</span><span class="params">(data_set)</span>:</span></div><div class="line">  feature_cols = &#123;k: tf.constant(data_set[k].values)</div><div class="line">                  <span class="keyword">for</span> k <span class="keyword">in</span> FEATURES&#125;</div><div class="line">  labels = tf.constant(data_set[LABEL].values)</div><div class="line">  <span class="keyword">return</span> feature_cols, labels</div></pre></td></tr></table></figure>
<p>请注意，输入数据被传递到<code>data_set</code>参数中的<code>input_fn</code>中，这意味着该函数可以处理您导入的任何<code>DataFrames</code>：<code>training_set</code>，<code>test_set</code>和<code>prediction_set</code>。</p>
<h3 id="训练回归">训练回归</h3><p>要训​​练神经网络回归，运行指定了包含有<code>training_set</code>的<code>input_fn</code>的<code>fit</code>函数，如下：</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">regressor<span class="selector-class">.fit</span>(input_fn=<span class="attribute">lambda</span>: input_fn(training_set), steps=<span class="number">5000</span>)</div></pre></td></tr></table></figure>
<p>您应该能看到类似于以下内容的日志输出，它会报告每100步的训练loss值：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1</span>: loss = <span class="number">483.179</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">101</span>: loss = <span class="number">81.2072</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">201</span>: loss = <span class="number">72.4354</span></div><div class="line">...</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1801</span>: loss = <span class="number">33.4454</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">1901</span>: loss = <span class="number">32.3397</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">2001</span>: loss = <span class="number">32.0053</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4801</span>: loss = <span class="number">27.2791</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Step <span class="number">4901</span>: loss = <span class="number">27.2251</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving checkpoints <span class="keyword">for</span> <span class="number">5000</span> into <span class="regexp">/tmp/</span>boston_model/model.ckpt.</div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Loss <span class="keyword">for</span> <span class="keyword">final</span> <span class="string">step:</span> <span class="number">27.1674</span>.</div></pre></td></tr></table></figure>
<h3 id="评估模型">评估模型</h3><p>接下来，看看训练模型如何针对测试数据集执行。运行<code>evaluate</code>，这次将<code>test_set</code>传递给<code>input_fn</code>：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="attr">ev</span> = regressor.evaluate(<span class="attr">input_fn=lambda:</span> input_fn(test_set), <span class="attr">steps=1)</span></div></pre></td></tr></table></figure>
<p>从<code>ev</code>的结果中检索损失并将其打印到输出：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">loss_score = ev[<span class="string">"loss"</span>]</div><div class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">"Loss: &#123;0:f&#125;"</span>.format(loss_score)</span></span>)</div></pre></td></tr></table></figure>
<p>您应该会看到类似以下的结果：</p>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Eval steps [<span class="number">0</span>,<span class="number">1</span>) <span class="keyword">for</span> training step <span class="number">5000.</span></div><div class="line"><span class="string">INFO:</span><span class="string">tensorflow:</span>Saving evaluation summary <span class="keyword">for</span> <span class="number">5000</span> <span class="string">step:</span> loss = <span class="number">11.9221</span></div><div class="line"><span class="string">Loss:</span> <span class="number">11.922098</span></div></pre></td></tr></table></figure>
<h3 id="进行预测">进行预测</h3><p>最后，您可以使用模型预测<code>prediction_set</code>中的房屋中值，其中包含特征数据，但没有六个样本的标签：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">y = regressor.<span class="keyword">predict</span>(input_fn=lambda: input_fn(prediction_set))</div><div class="line"># .<span class="keyword">predict</span>() returns <span class="keyword">an</span> iterator; convert to a <span class="keyword">list</span> and <span class="keyword">print</span> predictions</div><div class="line">predictions = <span class="keyword">list</span>(itertools.islice(y, 6))</div><div class="line"><span class="keyword">print</span> (<span class="string">"Predictions: &#123;&#125;"</span>.<span class="keyword">format</span>(str(predictions)))</div></pre></td></tr></table></figure>
<p>您的结果应包含以 $1000 计的六次房价预测，例如：</p>
<figure class="highlight dns"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Predictions: [ <span class="number">33.30348587</span>  <span class="number">17.04452896</span>  <span class="number">22.56370163</span>  <span class="number">34.74345398</span>  <span class="number">14.55953979</span></div><div class="line">  <span class="number">19.58005714</span>]</div></pre></td></tr></table></figure>
<h2 id="其他资源">其他资源</h2><p>本教程专注于为神经网络回归创建一个<code>input_fn</code>。要了解更多有关对其他类型模型使用<code>input_fn</code>的信息，请查看以下资源：</p>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/linear" target="_blank" rel="external">TensorFlow的大尺寸线性模型</a>：这种对TensorFlow中的线性模型的介绍提供了用于变换输入数据的特征列和技术的高级概述。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>：本教程包括为线性分类模型创建<code>FeatureColumn</code>s和<code>input_fn</code>，该模型根据人口普查数据预测收入范围。</li>
<li><a href="https://www.tensorflow.org/tutorials/wide_and_deep" target="_blank" rel="external">TensorFlow宽＆深学习教程</a>：基于<a href="https://www.tensorflow.org/tutorials/wide" target="_blank" rel="external">TensorFlow线性模型教程</a>，本教程涵盖了使用<code>DNNLinearCombinedClassifier</code>组合线性模型和神经网络的“宽和深”模型的<code>FeatureColumn</code>和<code>input_fn</code>创建。</li>
</ul>
</span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/2/">&raquo;</a>
  </nav>

 </div>

        

        
      </div>

      
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      <section class="site-overview">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="http://dannylee1991.github.io/images/avatar.jpg" alt="DannyLee佳楠" itemprop="image"/>
          <p class="site-author-name" itemprop="name">DannyLee佳楠</p>
        </div>
        <p class="site-description motion-element" itemprop="description">一只在迈向机器学习道路上狂奔的程序猿.</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">107</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">16</span>
              <span class="site-state-item-name">分类</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">19</span>
              <span class="site-state-item-name">标签</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/DannyLee1991" target="_blank">GitHub</a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="http://creativecommons.org/licenses/by-nc-sa/4.0" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; &nbsp; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="icon-next-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">DannyLee佳楠</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>


 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  
  
    

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"dannylee1991"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>
    
     
  	<script src="/js/ua-parser.min.js"></script>
  	<script src="/js/hook-duoshuo.js"></script>
  

    
  
  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.1"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.1"></script>
  

  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.1" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.1"></script>
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  

  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }
    });
  </script>

  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
</html>
